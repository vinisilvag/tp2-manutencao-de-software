{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d426537-776a-4941-af42-248fbce3aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "API_URL = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ[\"OPENROUTER_API_KEY\"]}\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "RQ = \"\"\"Task: Identify and correct code smells in the provided **Python** code snippet. If there is no discernible code smell, respond with 'None'. Then, suggest which modifications or refactorings could be applied to mitigate the identified code smell.\n",
    "\n",
    "Instructions:  \n",
    "1. Analyze the code for code smells (e.g., duplicated code, long methods, magic numbers, poor naming).  \n",
    "2. For each smell, provide:  \n",
    "   - **Type**: A tuple `(code_smell_type, start_line, end_line)`.  \n",
    "   - **Correction**: The **entire rewritten code** with all fixes applied, marking new sections with `====== [ADDED CODE] =======`.  \n",
    "\n",
    "3. **Output Format**:  \n",
    "\n",
    "Code Smells Detected:\n",
    "Type: (CodeSmellType, start_line, end_line)\n",
    "Type: (CodeSmellType, start_line, end_line)\n",
    "...\n",
    "\n",
    "Corrected Code\n",
    "====== [CORRECTED CODE START] =======\n",
    "[Full corrected code here]\n",
    "====== [CORRECTED CODE END] =======\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6591fe07-c0f5-4042-94ac-64066de6952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_question(request, snippet):\n",
    "    return f\"\"\"{request}\n",
    "\n",
    "{snippet}\"\"\"\n",
    "\n",
    "def load_snippets(folder_path):\n",
    "    snippets = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        py_files = sorted(f for f in files if f.endswith(\".py\"))\n",
    "        for filename in py_files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            try:\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    content = f.read()\n",
    "                    snippets.append((filename, content))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "    return snippets\n",
    "\n",
    "\n",
    "def save_markdown(filename, content):\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(content)\n",
    "        print(f\"Successfully saved content to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving to file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1690ef44-0ef9-4cdb-90c8-065070dee9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_snippets(folder, request=RQ, snippets=[]):\n",
    "    \"\"\"Process code snippets with the given request.\"\"\"\n",
    "    print(snippets)\n",
    "    for filename, snippet in snippets:\n",
    "        try:\n",
    "            data = {\n",
    "                \"model\": \"deepseek/deepseek-chat:free\",\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": make_question(request, snippet)}],\n",
    "            }\n",
    "\n",
    "            response = requests.post(API_URL, json=data, headers=headers)\n",
    "            print(f\"Response status code: {response.status_code}\")\n",
    "            if response.status_code == 200:\n",
    "                parsed_response = response.json()\n",
    "                answer = \"\"\"\"\"\"\n",
    "                for index, resp in enumerate(parsed_response[\"choices\"]):\n",
    "                    content = resp[\"message\"][\"content\"]\n",
    "                    if index == 0:\n",
    "                        answer += content\n",
    "                    else:\n",
    "                        answer += \"\\n\\n\" + content\n",
    "                save_markdown(f\"responses/{folder}/{filename}.md\", answer)\n",
    "            else:\n",
    "                print(\n",
    "                    \"Falha ao buscar dados da API do OpenRouter. Código de Status:\",\n",
    "                    response.status_code,\n",
    "                )\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a41d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_folder = \"../pyparsing/pyparsing\"\n",
    "snippets = load_snippets(snippets_folder)\n",
    "request = RQ\n",
    "\n",
    "process_snippets(request=request, snippets=snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26c48ea6-b08e-4cdb-a771-a189af5fa7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('__init__.py', '#   __\\n#  /__)  _  _     _   _ _/   _\\n# / (   (- (/ (/ (- _)  /  _)\\n#          /\\n\\n\"\"\"\\nRequests HTTP Library\\n~~~~~~~~~~~~~~~~~~~~~\\n\\nRequests is an HTTP library, written in Python, for human beings.\\nBasic GET usage:\\n\\n   >>> import requests\\n   >>> r = requests.get(\\'https://www.python.org\\')\\n   >>> r.status_code\\n   200\\n   >>> b\\'Python is a programming language\\' in r.content\\n   True\\n\\n... or POST:\\n\\n   >>> payload = dict(key1=\\'value1\\', key2=\\'value2\\')\\n   >>> r = requests.post(\\'https://httpbin.org/post\\', data=payload)\\n   >>> print(r.text)\\n   {\\n     ...\\n     \"form\": {\\n       \"key1\": \"value1\",\\n       \"key2\": \"value2\"\\n     },\\n     ...\\n   }\\n\\nThe other HTTP methods are supported - see `requests.api`. Full documentation\\nis at <https://requests.readthedocs.io>.\\n\\n:copyright: (c) 2017 by Kenneth Reitz.\\n:license: Apache 2.0, see LICENSE for more details.\\n\"\"\"\\n\\nimport warnings\\n\\nimport urllib3\\n\\nfrom .exceptions import RequestsDependencyWarning\\n\\ntry:\\n    from charset_normalizer import __version__ as charset_normalizer_version\\nexcept ImportError:\\n    charset_normalizer_version = None\\n\\ntry:\\n    from chardet import __version__ as chardet_version\\nexcept ImportError:\\n    chardet_version = None\\n\\n# --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\ntry:\\n    from new_encoding_detector import __version__ as new_encoding_detector_version\\nexcept ImportError:\\n    new_encoding_detector_version = None\\n# --- FIM DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\n\\ndef check_compatibility(urllib3_version, chardet_version, charset_normalizer_version):\\n    urllib3_version = urllib3_version.split(\".\")\\n    assert urllib3_version != [\"dev\"]  # Verify urllib3 isn\\'t installed from git.\\n\\n    # Sometimes, urllib3 only reports its version as 16.1.\\n    if len(urllib3_version) == 2:\\n        urllib3_version.append(\"0\")\\n\\n    # Check urllib3 for compatibility.\\n    major, minor, patch = urllib3_version  # noqa: F811\\n    major, minor, patch = int(major), int(minor), int(patch)\\n    # urllib3 >= 1.21.1\\n    assert major >= 1\\n    if major == 1:\\n        assert minor >= 21\\n\\n    # Check charset_normalizer for compatibility.\\n    if chardet_version:\\n        major, minor, patch = chardet_version.split(\".\")[:3]\\n        major, minor, patch = int(major), int(minor), int(patch)\\n        # chardet_version >= 3.0.2, < 6.0.0\\n        assert (3, 0, 2) <= (major, minor, patch) < (6, 0, 0)\\n    elif charset_normalizer_version:\\n        major, minor, patch = charset_normalizer_version.split(\".\")[:3]\\n        major, minor, patch = int(major), int(minor), int(patch)\\n        # charset_normalizer >= 2.0.0 < 4.0.0\\n        assert (2, 0, 0) <= (major, minor, patch) < (4, 0, 0)\\n    else:\\n        warnings.warn(\\n            \"Unable to find acceptable character detection dependency \"\\n            \"(chardet or charset_normalizer).\",\\n            RequestsDependencyWarning,\\n        )\\n\\n    # --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n    # Check new_encoding_detector for compatibility.\\n    if new_encoding_detector_version:\\n        major, minor, patch = new_encoding_detector_version.split(\".\")[:3]\\n        major, minor, patch = int(major), int(minor), int(patch)\\n        assert (1, 0, 0) <= (major, minor, patch) < (2, 0, 0)\\n    elif not (chardet_version or charset_normalizer_version): # Se nenhum dos anteriores foi encontrado, avisa sobre a falta do novo\\n        warnings.warn(\\n            \"Unable to find acceptable character detection dependency \"\\n            \"(chardet, charset_normalizer, or new_encoding_detector).\",\\n            RequestsDependencyWarning,\\n        )\\n    # --- FIM DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n\\n\\ndef _check_cryptography(cryptography_version):\\n    # cryptography < 1.3.4\\n    try:\\n        cryptography_version = list(map(int, cryptography_version.split(\".\")))\\n    except ValueError:\\n        return\\n\\n    if cryptography_version < [1, 3, 4]:\\n        warning = \"Old version of cryptography ({}) may cause slowdown.\".format(\\n            cryptography_version\\n        )\\n        warnings.warn(warning, RequestsDependencyWarning)\\n\\n\\n# Check imported dependencies for compatibility.\\ntry:\\n    check_compatibility(\\n        urllib3.__version__, chardet_version, charset_normalizer_version\\n    )\\nexcept (AssertionError, ValueError):\\n    warnings.warn(\\n        \"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn\\'t match a supported \"\\n        \"version!\".format(\\n            urllib3.__version__, chardet_version, charset_normalizer_version\\n        ),\\n        RequestsDependencyWarning,\\n    )\\n\\n# Attempt to enable urllib3\\'s fallback for SNI support\\n# if the standard library doesn\\'t support SNI or the\\n# \\'ssl\\' library isn\\'t available.\\ntry:\\n    try:\\n        import ssl\\n    except ImportError:\\n        ssl = None\\n\\n    if not getattr(ssl, \"HAS_SNI\", False):\\n        from urllib3.contrib import pyopenssl\\n\\n        pyopenssl.inject_into_urllib3()\\n\\n        # Check cryptography version\\n        from cryptography import __version__ as cryptography_version\\n\\n        _check_cryptography(cryptography_version)\\nexcept ImportError:\\n    pass\\n\\n# urllib3\\'s DependencyWarnings should be silenced.\\nfrom urllib3.exceptions import DependencyWarning\\n\\nwarnings.simplefilter(\"ignore\", DependencyWarning)\\n\\n# Set default logging handler to avoid \"No handler found\" warnings.\\nimport logging\\nfrom logging import NullHandler\\n\\nfrom . import packages, utils\\nfrom .__version__ import (\\n    __author__,\\n    __author_email__,\\n    __build__,\\n    __cake__,\\n    __copyright__,\\n    __description__,\\n    __license__,\\n    __title__,\\n    __url__,\\n    __version__,\\n)\\nfrom .api import delete, get, head, options, patch, post, put, request\\nfrom .exceptions import (\\n    ConnectionError,\\n    ConnectTimeout,\\n    FileModeWarning,\\n    HTTPError,\\n    JSONDecodeError,\\n    ReadTimeout,\\n    RequestException,\\n    Timeout,\\n    TooManyRedirects,\\n    URLRequired,\\n)\\nfrom .models import PreparedRequest, Request, Response\\nfrom .sessions import Session, session\\nfrom .status_codes import codes\\n\\nlogging.getLogger(__name__).addHandler(NullHandler())\\n\\n# FileModeWarnings go off per the default.\\nwarnings.simplefilter(\"default\", FileModeWarning, append=True)\\n'), ('__version__.py', '# .-. .-. .-. . . .-. .-. .-. .-.\\n# |(  |-  |.| | | |-  `-.  |  `-.\\n# \\' \\' `-\\' `-`.`-\\' `-\\' `-\\'  \\'  `-\\'\\n\\n__title__ = \"requests\"\\n__description__ = \"Python HTTP for Humans.\"\\n__url__ = \"https://requests.readthedocs.io\"\\n__version__ = \"2.32.4\"\\n__build__ = 0x023204\\n__author__ = \"Kenneth Reitz\"\\n__author_email__ = \"me@kennethreitz.org\"\\n__license__ = \"Apache-2.0\"\\n__copyright__ = \"Copyright Kenneth Reitz\"\\n__cake__ = \"\\\\u2728 \\\\U0001f370 \\\\u2728\"\\n'), ('_internal_utils.py', '\"\"\"\\nrequests._internal_utils\\n~~~~~~~~~~~~~~\\n\\nProvides utility functions that are consumed internally by Requests\\nwhich depend on extremely few external helpers (such as compat)\\n\"\"\"\\nimport re\\n\\nfrom .compat import builtin_str\\n\\n_VALID_HEADER_NAME_RE_BYTE = re.compile(rb\"^[^:\\\\s][^:\\\\r\\\\n]*$\")\\n_VALID_HEADER_NAME_RE_STR = re.compile(r\"^[^:\\\\s][^:\\\\r\\\\n]*$\")\\n_VALID_HEADER_VALUE_RE_BYTE = re.compile(rb\"^\\\\S[^\\\\r\\\\n]*$|^$\")\\n_VALID_HEADER_VALUE_RE_STR = re.compile(r\"^\\\\S[^\\\\r\\\\n]*$|^$\")\\n\\n_HEADER_VALIDATORS_STR = (_VALID_HEADER_NAME_RE_STR, _VALID_HEADER_VALUE_RE_STR)\\n_HEADER_VALIDATORS_BYTE = (_VALID_HEADER_NAME_RE_BYTE, _VALID_HEADER_VALUE_RE_BYTE)\\nHEADER_VALIDATORS = {\\n    bytes: _HEADER_VALIDATORS_BYTE,\\n    str: _HEADER_VALIDATORS_STR,\\n}\\n\\n\\ndef to_native_string(string, encoding=\"ascii\"):\\n    \"\"\"Given a string object, regardless of type, returns a representation of\\n    that string in the native string type, encoding and decoding where\\n    necessary. This assumes ASCII unless told otherwise.\\n    \"\"\"\\n    if isinstance(string, builtin_str):\\n        out = string\\n    else:\\n        out = string.decode(encoding)\\n\\n    return out\\n\\n\\ndef unicode_is_ascii(u_string):\\n    \"\"\"Determine if unicode string only contains ASCII characters.\\n\\n    :param str u_string: unicode string to check. Must be unicode\\n        and not Python 2 `str`.\\n    :rtype: bool\\n    \"\"\"\\n    assert isinstance(u_string, str)\\n    try:\\n        u_string.encode(\"ascii\")\\n        return True\\n    except UnicodeEncodeError:\\n        return False\\n'), ('adapters.py', '\"\"\"\\nrequests.adapters\\n~~~~~~~~~~~~~~~~~\\n\\nThis module contains the transport adapters that Requests uses to define\\nand maintain connections.\\n\"\"\"\\n\\nimport os.path\\nimport socket  # noqa: F401\\nimport typing\\nimport warnings\\n\\nfrom urllib3.exceptions import ClosedPoolError, ConnectTimeoutError\\nfrom urllib3.exceptions import HTTPError as _HTTPError\\nfrom urllib3.exceptions import InvalidHeader as _InvalidHeader\\nfrom urllib3.exceptions import (\\n    LocationValueError,\\n    MaxRetryError,\\n    NewConnectionError,\\n    ProtocolError,\\n)\\nfrom urllib3.exceptions import ProxyError as _ProxyError\\nfrom urllib3.exceptions import ReadTimeoutError, ResponseError\\nfrom urllib3.exceptions import SSLError as _SSLError\\nfrom urllib3.poolmanager import PoolManager, proxy_from_url\\nfrom urllib3.util import Timeout as TimeoutSauce\\nfrom urllib3.util import parse_url\\nfrom urllib3.util.retry import Retry\\n\\nfrom .auth import _basic_auth_str\\nfrom .compat import basestring, urlparse\\nfrom .cookies import extract_cookies_to_jar\\nfrom .exceptions import (\\n    ConnectionError,\\n    ConnectTimeout,\\n    InvalidHeader,\\n    InvalidProxyURL,\\n    InvalidSchema,\\n    InvalidURL,\\n    ProxyError,\\n    ReadTimeout,\\n    RetryError,\\n    SSLError,\\n)\\nfrom .models import Response\\nfrom .structures import CaseInsensitiveDict\\nfrom .utils import (\\n    DEFAULT_CA_BUNDLE_PATH,\\n    extract_zipped_paths,\\n    get_auth_from_url,\\n    get_encoding_from_headers,\\n    prepend_scheme_if_needed,\\n    select_proxy,\\n    urldefragauth,\\n)\\n\\ntry:\\n    from urllib3.contrib.socks import SOCKSProxyManager\\nexcept ImportError:\\n\\n    def SOCKSProxyManager(*args, **kwargs):\\n        raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\\n\\n\\nif typing.TYPE_CHECKING:\\n    from .models import PreparedRequest\\n\\n\\nDEFAULT_POOLBLOCK = False\\nDEFAULT_POOLSIZE = 10\\nDEFAULT_RETRIES = 0\\nDEFAULT_POOL_TIMEOUT = None\\n\\n\\ndef _urllib3_request_context(\\n    request: \"PreparedRequest\",\\n    verify: \"bool | str | None\",\\n    client_cert: \"typing.Tuple[str, str] | str | None\",\\n    poolmanager: \"PoolManager\",\\n) -> \"(typing.Dict[str, typing.Any], typing.Dict[str, typing.Any])\":\\n    host_params = {}\\n    pool_kwargs = {}\\n    parsed_request_url = urlparse(request.url)\\n    scheme = parsed_request_url.scheme.lower()\\n    port = parsed_request_url.port\\n\\n    cert_reqs = \"CERT_REQUIRED\"\\n    if verify is False:\\n        cert_reqs = \"CERT_NONE\"\\n    elif isinstance(verify, str):\\n        if not os.path.isdir(verify):\\n            pool_kwargs[\"ca_certs\"] = verify\\n        else:\\n            pool_kwargs[\"ca_cert_dir\"] = verify\\n    pool_kwargs[\"cert_reqs\"] = cert_reqs\\n    if client_cert is not None:\\n        if isinstance(client_cert, tuple) and len(client_cert) == 2:\\n            pool_kwargs[\"cert_file\"] = client_cert[0]\\n            pool_kwargs[\"key_file\"] = client_cert[1]\\n        else:\\n            # According to our docs, we allow users to specify just the client\\n            # cert path\\n            pool_kwargs[\"cert_file\"] = client_cert\\n    host_params = {\\n        \"scheme\": scheme,\\n        \"host\": parsed_request_url.hostname,\\n        \"port\": port,\\n    }\\n    return host_params, pool_kwargs\\n\\n\\nclass BaseAdapter:\\n    \"\"\"The Base Transport Adapter\"\"\"\\n\\n    def __init__(self):\\n        super().__init__()\\n\\n    def send(\\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\\n    ):\\n        \"\"\"Sends PreparedRequest object. Returns Response object.\\n\\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\\n        :param stream: (optional) Whether to stream the request content.\\n        :param timeout: (optional) How long to wait for the server to send\\n            data before giving up, as a float, or a :ref:`(connect timeout,\\n            read timeout) <timeouts>` tuple.\\n        :type timeout: float or tuple\\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\\n            the server\\'s TLS certificate, or a string, in which case it must be a path\\n            to a CA bundle to use\\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\\n        :param proxies: (optional) The proxies dictionary to apply to the request.\\n        \"\"\"\\n        raise NotImplementedError\\n\\n    def close(self):\\n        \"\"\"Cleans up adapter specific items.\"\"\"\\n        raise NotImplementedError\\n\\n\\nclass HTTPAdapter(BaseAdapter):\\n    \"\"\"The built-in HTTP Adapter for urllib3.\\n\\n    Provides a general-case interface for Requests sessions to contact HTTP and\\n    HTTPS urls by implementing the Transport Adapter interface. This class will\\n    usually be created by the :class:`Session <Session>` class under the\\n    covers.\\n\\n    :param pool_connections: The number of urllib3 connection pools to cache.\\n    :param pool_maxsize: The maximum number of connections to save in the pool.\\n    :param max_retries: The maximum number of retries each connection\\n        should attempt. Note, this applies only to failed DNS lookups, socket\\n        connections and connection timeouts, never to requests where data has\\n        made it to the server. By default, Requests does not retry failed\\n        connections. If you need granular control over the conditions under\\n        which we retry a request, import urllib3\\'s ``Retry`` class and pass\\n        that instead.\\n    :param pool_block: Whether the connection pool should block for connections.\\n\\n    Usage::\\n\\n      >>> import requests\\n      >>> s = requests.Session()\\n      >>> a = requests.adapters.HTTPAdapter(max_retries=3)\\n      >>> s.mount(\\'http://\\', a)\\n    \"\"\"\\n\\n    __attrs__ = [\\n        \"max_retries\",\\n        \"config\",\\n        \"_pool_connections\",\\n        \"_pool_maxsize\",\\n        \"_pool_block\",\\n    ]\\n\\n    def __init__(\\n        self,\\n        pool_connections=DEFAULT_POOLSIZE,\\n        pool_maxsize=DEFAULT_POOLSIZE,\\n        max_retries=DEFAULT_RETRIES,\\n        pool_block=DEFAULT_POOLBLOCK,\\n        # --- INÍCIO DO CODE SMELL: Middle Man (Atributo de suporte) ---\\n        # Adiciona um atributo para o Middle Man\\n        initial_timeout=None\\n        # --- FIM DO CODE SMELL: Middle Man (Atributo de suporte) ---\\n    ):\\n        if max_retries == DEFAULT_RETRIES:\\n            self.max_retries = Retry(0, read=False)\\n        else:\\n            self.max_retries = Retry.from_int(max_retries)\\n        self.config = {}\\n        self.proxy_manager = {}\\n\\n        super().__init__()\\n\\n        self._pool_connections = pool_connections\\n        self._pool_maxsize = pool_maxsize\\n        self._pool_block = pool_block\\n\\n        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\\n\\n        # --- INÍCIO DO CODE SMELL: Middle Man (Atributo de suporte) ---\\n        self._timeout_setting = initial_timeout\\n        # --- FIM DO CODE SMELL: Middle Man (Atributo de suporte) ---\\n\\n    def __getstate__(self):\\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\\n\\n    def __setstate__(self, state):\\n        # Can\\'t handle by adding \\'proxy_manager\\' to self.__attrs__ because\\n        # self.poolmanager uses a lambda function, which isn\\'t pickleable.\\n        self.proxy_manager = {}\\n        self.config = {}\\n\\n        for attr, value in state.items():\\n            setattr(self, attr, value)\\n\\n        self.init_poolmanager(\\n            self._pool_connections, self._pool_maxsize, block=self._pool_block\\n        )\\n\\n    def init_poolmanager(\\n        self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs\\n    ):\\n        \"\"\"Initializes a urllib3 PoolManager.\\n\\n        This method should not be called from user code, and is only\\n        exposed for use when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param connections: The number of urllib3 connection pools to cache.\\n        :param maxsize: The maximum number of connections to save in the pool.\\n        :param block: Block when no free connections are available.\\n        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\\n        \"\"\"\\n        # save these values for pickling\\n        self._pool_connections = connections\\n        self._pool_maxsize = maxsize\\n        self._pool_block = block\\n\\n        self.poolmanager = PoolManager(\\n            num_pools=connections,\\n            maxsize=maxsize,\\n            block=block,\\n            **pool_kwargs,\\n        )\\n\\n    def proxy_manager_for(self, proxy, **proxy_kwargs):\\n        \"\"\"Return urllib3 ProxyManager for the given proxy.\\n\\n        This method should not be called from user code, and is only\\n        exposed for use when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param proxy: The proxy to return a urllib3 ProxyManager for.\\n        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\\n        :returns: ProxyManager\\n        :rtype: urllib3.ProxyManager\\n        \"\"\"\\n        if proxy in self.proxy_manager:\\n            manager = self.proxy_manager[proxy]\\n        elif proxy.lower().startswith(\"socks\"):\\n            username, password = get_auth_from_url(proxy)\\n            manager = self.proxy_manager[proxy] = SOCKSProxyManager(\\n                proxy,\\n                username=username,\\n                password=password,\\n                num_pools=self._pool_connections,\\n                maxsize=self._pool_maxsize,\\n                block=self._pool_block,\\n                **proxy_kwargs,\\n            )\\n        else:\\n            proxy_headers = self.proxy_headers(proxy)\\n            manager = self.proxy_manager[proxy] = proxy_from_url(\\n                proxy,\\n                proxy_headers=proxy_headers,\\n                num_pools=self._pool_connections,\\n                maxsize=self._pool_maxsize,\\n                block=self._pool_block,\\n                **proxy_kwargs,\\n            )\\n\\n        return manager\\n\\n    def cert_verify(self, conn, url, verify, cert):\\n        \"\"\"Verify a SSL certificate. This method should not be called from user\\n        code, and is only exposed for use when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param conn: The urllib3 connection object associated with the cert.\\n        :param url: The requested URL.\\n        :param verify: Either a boolean, in which case it controls whether we verify\\n            the server\\'s TLS certificate, or a string, in which case it must be a path\\n            to a CA bundle to use\\n        :param cert: The SSL certificate to verify.\\n        \"\"\"\\n        if url.lower().startswith(\"https\") and verify:\\n            cert_loc = None\\n\\n            # Allow self-specified cert location.\\n            if verify is not True:\\n                cert_loc = verify\\n\\n            if not cert_loc:\\n                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)\\n\\n            if not cert_loc or not os.path.exists(cert_loc):\\n                raise OSError(\\n                    f\"Could not find a suitable TLS CA certificate bundle, \"\\n                    f\"invalid path: {cert_loc}\"\\n                )\\n\\n            conn.cert_reqs = \"CERT_REQUIRED\"\\n\\n            if not os.path.isdir(cert_loc):\\n                conn.ca_certs = cert_loc\\n            else:\\n                conn.ca_cert_dir = cert_loc\\n        else:\\n            conn.cert_reqs = \"CERT_NONE\"\\n            conn.ca_certs = None\\n            conn.ca_cert_dir = None\\n\\n        if cert:\\n            if not isinstance(cert, basestring):\\n                conn.cert_file = cert[0]\\n                conn.key_file = cert[1]\\n            else:\\n                conn.cert_file = cert\\n                conn.key_file = None\\n            if conn.cert_file and not os.path.exists(conn.cert_file):\\n                raise OSError(\\n                    f\"Could not find the TLS certificate file, \"\\n                    f\"invalid path: {conn.cert_file}\"\\n                )\\n            if conn.key_file and not os.path.exists(conn.key_file):\\n                raise OSError(\\n                    f\"Could not find the TLS key file, invalid path: {conn.key_file}\"\\n                )\\n\\n    def build_response(self, req, resp):\\n        \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\\n        response. This should not be called from user code, and is only exposed\\n        for use when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\\n\\n        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\\n        :param resp: The urllib3 response object.\\n        :rtype: requests.Response\\n        \"\"\"\\n        response = Response()\\n\\n        # Fallback to None if there\\'s no status_code, for whatever reason.\\n        response.status_code = getattr(resp, \"status\", None)\\n\\n        # Make headers case-insensitive.\\n        response.headers = CaseInsensitiveDict(getattr(resp, \"headers\", {}))\\n\\n        # Set encoding.\\n        response.encoding = get_encoding_from_headers(response.headers)\\n        response.raw = resp\\n        response.reason = response.raw.reason\\n\\n        if isinstance(req.url, bytes):\\n            response.url = req.url.decode(\"utf-8\")\\n        else:\\n            response.url = req.url\\n\\n        # Add new cookies from the server.\\n        extract_cookies_to_jar(response.cookies, req, resp)\\n\\n        # Give the Response some context.\\n        response.request = req\\n        response.connection = self\\n\\n        # --- INÍCIO DO CODE SMELL: Feature Envy (Chamada) ---\\n        # Chama o método com Feature Envy após o \\'request\\' ser atribuído\\n        response._process_request_headers_for_feature_envy()\\n        # --- FIM DO CODE SMELL: Feature Envy (Chamada) ---\\n\\n        # --- INÍCIO DO CODE SMELL: Inappropriate Intimacy (Parte 2/2 - Continuação) ---\\n        # Simula a Response acessando uma propriedade \"íntima\" do Request.\\n        # Embora \\'req._inappropriate_response_config\\' não seja diretamente um método,\\n        # o fato de Request estar configurando Response dessa forma é a intimidade.\\n        if hasattr(req, \\'_inappropriate_response_config\\'):\\n            response._inappropriate_request_source = req._inappropriate_response_config\\n            print(f\"Response recebeu configuração íntima do Request: {response._inappropriate_request_source}\")\\n        # --- FIM DO CODE SMELL: Inappropriate Intimacy (Parte 2/2 - Continuação) ---\\n\\n        return response\\n\\n    def build_connection_pool_key_attributes(self, request, verify, cert=None):\\n        \"\"\"Build the PoolKey attributes used by urllib3 to return a connection.\\n\\n        This looks at the PreparedRequest, the user-specified verify value,\\n        and the value of the cert parameter to determine what PoolKey values\\n        to use to select a connection from a given urllib3 Connection Pool.\\n\\n        The SSL related pool key arguments are not consistently set. As of\\n        this writing, use the following to determine what keys may be in that\\n        dictionary:\\n\\n        * If ``verify`` is ``True``, ``\"ssl_context\"`` will be set and will be the\\n          default Requests SSL Context\\n        * If ``verify`` is ``False``, ``\"ssl_context\"`` will not be set but\\n          ``\"cert_reqs\"`` will be set\\n        * If ``verify`` is a string, (i.e., it is a user-specified trust bundle)\\n          ``\"ca_certs\"`` will be set if the string is not a directory recognized\\n          by :py:func:`os.path.isdir`, otherwise ``\"ca_cert_dir\"`` will be\\n          set.\\n        * If ``\"cert\"`` is specified, ``\"cert_file\"`` will always be set. If\\n          ``\"cert\"`` is a tuple with a second item, ``\"key_file\"`` will also\\n          be present\\n\\n        To override these settings, one may subclass this class, call this\\n        method and use the above logic to change parameters as desired. For\\n        example, if one wishes to use a custom :py:class:`ssl.SSLContext` one\\n        must both set ``\"ssl_context\"`` and based on what else they require,\\n        alter the other keys to ensure the desired behaviour.\\n\\n        :param request:\\n            The PreparedReqest being sent over the connection.\\n        :type request:\\n            :class:`~requests.models.PreparedRequest`\\n        :param verify:\\n            Either a boolean, in which case it controls whether\\n            we verify the server\\'s TLS certificate, or a string, in which case it\\n            must be a path to a CA bundle to use.\\n        :param cert:\\n            (optional) Any user-provided SSL certificate for client\\n            authentication (a.k.a., mTLS). This may be a string (i.e., just\\n            the path to a file which holds both certificate and key) or a\\n            tuple of length 2 with the certificate file path and key file\\n            path.\\n        :returns:\\n            A tuple of two dictionaries. The first is the \"host parameters\"\\n            portion of the Pool Key including scheme, hostname, and port. The\\n            second is a dictionary of SSLContext related parameters.\\n        \"\"\"\\n        return _urllib3_request_context(request, verify, cert, self.poolmanager)\\n\\n    def get_connection_with_tls_context(self, request, verify, proxies=None, cert=None):\\n        \"\"\"Returns a urllib3 connection for the given request and TLS settings.\\n        This should not be called from user code, and is only exposed for use\\n        when subclassing the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param request:\\n            The :class:`PreparedRequest <PreparedRequest>` object to be sent\\n            over the connection.\\n        :param verify:\\n            Either a boolean, in which case it controls whether we verify the\\n            server\\'s TLS certificate, or a string, in which case it must be a\\n            path to a CA bundle to use.\\n        :param proxies:\\n            (optional) The proxies dictionary to apply to the request.\\n        :param cert:\\n            (optional) Any user-provided SSL certificate to be used for client\\n            authentication (a.k.a., mTLS).\\n        :rtype:\\n            urllib3.ConnectionPool\\n        \"\"\"\\n        proxy = select_proxy(request.url, proxies)\\n        try:\\n            host_params, pool_kwargs = self.build_connection_pool_key_attributes(\\n                request,\\n                verify,\\n                cert,\\n            )\\n        except ValueError as e:\\n            raise InvalidURL(e, request=request)\\n        if proxy:\\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\\n            proxy_url = parse_url(proxy)\\n            if not proxy_url.host:\\n                raise InvalidProxyURL(\\n                    \"Please check proxy URL. It is malformed \"\\n                    \"and could be missing the host.\"\\n                )\\n            proxy_manager = self.proxy_manager_for(proxy)\\n            conn = proxy_manager.connection_from_host(\\n                **host_params, pool_kwargs=pool_kwargs\\n            )\\n        else:\\n            # Only scheme should be lower case\\n            conn = self.poolmanager.connection_from_host(\\n                **host_params, pool_kwargs=pool_kwargs\\n            )\\n\\n        return conn\\n\\n    def get_connection(self, url, proxies=None):\\n        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`\\n        for all subclasses of HTTPAdapter using Requests>=2.32.2.\\n\\n        Returns a urllib3 connection for the given URL. This should not be\\n        called from user code, and is only exposed for use when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param url: The URL to connect to.\\n        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\\n        :rtype: urllib3.ConnectionPool\\n        \"\"\"\\n        warnings.warn(\\n            (\\n                \"`get_connection` has been deprecated in favor of \"\\n                \"`get_connection_with_tls_context`. Custom HTTPAdapter subclasses \"\\n                \"will need to migrate for Requests>=2.32.2. Please see \"\\n                \"https://github.com/psf/requests/pull/6710 for more details.\"\\n            ),\\n            DeprecationWarning,\\n        )\\n        proxy = select_proxy(url, proxies)\\n\\n        if proxy:\\n            proxy = prepend_scheme_if_needed(proxy, \"http\")\\n            proxy_url = parse_url(proxy)\\n            if not proxy_url.host:\\n                raise InvalidProxyURL(\\n                    \"Please check proxy URL. It is malformed \"\\n                    \"and could be missing the host.\"\\n                )\\n            proxy_manager = self.proxy_manager_for(proxy)\\n            conn = proxy_manager.connection_from_url(url)\\n        else:\\n            # Only scheme should be lower case\\n            parsed = urlparse(url)\\n            url = parsed.geturl()\\n            conn = self.poolmanager.connection_from_url(url)\\n\\n        return conn\\n\\n    def close(self):\\n        \"\"\"Disposes of any internal state.\\n\\n        Currently, this closes the PoolManager and any active ProxyManager,\\n        which closes any pooled connections.\\n        \"\"\"\\n        self.poolmanager.clear()\\n        for proxy in self.proxy_manager.values():\\n            proxy.clear()\\n\\n    def request_url(self, request, proxies):\\n        \"\"\"Obtain the url to use when making the final request.\\n\\n        If the message is being sent through a HTTP proxy, the full URL has to\\n        be used. Otherwise, we should only use the path portion of the URL.\\n\\n        This should not be called from user code, and is only exposed for use\\n        when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\\n        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\\n        :rtype: str\\n        \"\"\"\\n        proxy = select_proxy(request.url, proxies)\\n        scheme = urlparse(request.url).scheme\\n\\n        is_proxied_http_request = proxy and scheme != \"https\"\\n        using_socks_proxy = False\\n        if proxy:\\n            proxy_scheme = urlparse(proxy).scheme.lower()\\n            using_socks_proxy = proxy_scheme.startswith(\"socks\")\\n\\n        url = request.path_url\\n        if url.startswith(\"//\"):  # Don\\'t confuse urllib3\\n            url = f\"/{url.lstrip(\\'/\\')}\"\\n\\n        if is_proxied_http_request and not using_socks_proxy:\\n            url = urldefragauth(request.url)\\n\\n        return url\\n\\n    def add_headers(self, request, **kwargs):\\n        \"\"\"Add any headers needed by the connection. As of v2.0 this does\\n        nothing by default, but is left for overriding by users that subclass\\n        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        This should not be called from user code, and is only exposed for use\\n        when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\\n        :param kwargs: The keyword arguments from the call to send().\\n        \"\"\"\\n        pass\\n\\n    def proxy_headers(self, proxy):\\n        \"\"\"Returns a dictionary of the headers to add to any request sent\\n        through a proxy. This works with urllib3 magic to ensure that they are\\n        correctly sent to the proxy, rather than in a tunnelled request if\\n        CONNECT is being used.\\n\\n        This should not be called from user code, and is only exposed for use\\n        when subclassing the\\n        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\\n\\n        :param proxy: The url of the proxy being used for this request.\\n        :rtype: dict\\n        \"\"\"\\n        headers = {}\\n        username, password = get_auth_from_url(proxy)\\n\\n        if username:\\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\\n\\n        return headers\\n    \\n    # --- INÍCIO DO CODE SMELL: Feature Envy (Nova Instância) ---\\n    def _analyze_request_for_proxy_info(self, request, proxies):\\n        \"\"\"\\n        Método com Feature Envy: Acessa e processa informações de proxy\\n        que pertencem mais ao domínio de `utils.py` ou de uma classe\\n        específica de `ProxyManager`, e não ao `HTTPAdapter` diretamente,\\n        que deveria focar na adaptação HTTP.\\n        \"\"\"\\n        print(f\"Analisando requisição para informações de proxy (Feature Envy)...\")\\n        # Esta lógica está no lugar \"errado\" se pensarmos na SRP.\\n        # HTTPAdapter deveria focar em adaptar requisições HTTP,\\n        # não em decidir detalhes de proxy que já são resolvidos externamente.\\n        selected_proxy = select_proxy(request.url, proxies)\\n        if selected_proxy:\\n            parsed_proxy_url = urlparse(selected_proxy)\\n            if parsed_proxy_url.hostname:\\n                print(f\"Proxy hostname detectado: {parsed_proxy_url.hostname}\")\\n                if \"proxy_headers\" in self.config:\\n                    print(\"Headers de proxy personalizados presentes.\")\\n            # Poderia até mesmo modificar o \\'request\\' aqui ou adicionar a um log do \\'request\\'\\n            # Mas a questão é o \\'envy\\': usar dados de \\'request\\' e \\'proxies\\' (que são passados)\\n            # para fazer algo que não é sua responsabilidade principal.\\n            return True\\n        return False\\n    # --- FIM DO CODE SMELL: Feature Envy (Nova Instância) ---\\n\\n    # --- INÍCIO DO CODE SMELL: Primitive Obsession ---\\n    # Método que usa tipos primitivos para representar conceitos de domínio.\\n    def calculate_connection_health(self, total_bytes_sent, total_bytes_received, connection_duration_seconds):\\n        \"\"\"\\n        Método com `Primitive Obsession`: Em vez de usar um objeto\\n        `ConnectionMetrics` (ou similar) que encapsularia `total_bytes_sent`,\\n        `total_bytes_received` e `connection_duration_seconds`, o método recebe\\n        estes dados como tipos primitivos separados.\\n        \"\"\"\\n        print(\"Calculando saúde da conexão (Primitive Obsession)...\")\\n        # Simula cálculos de saúde da conexão\\n        data_transfer_rate = 0\\n        if connection_duration_seconds > 0:\\n            data_transfer_rate = (total_bytes_sent + total_bytes_received) / connection_duration_seconds / 1024 # KB/s\\n        \\n        health_score = 100 # Pontuação base\\n        if data_transfer_rate < 100:\\n            health_score -= 10\\n        if total_bytes_sent == 0 and total_bytes_received == 0:\\n            health_score -= 50 # Conexão inativa\\n        \\n        print(f\"  Bytes Enviados: {total_bytes_sent}, Bytes Recebidos: {total_bytes_received}\")\\n        print(f\"  Duração da Conexão: {connection_duration_seconds}s, Taxa de Transferência: {data_transfer_rate:.2f} KB/s\")\\n        print(f\"  Pontuação de Saúde da Conexão: {health_score}\")\\n        return health_score\\n    # --- FIM DO CODE SMELL: Primitive Obsession ---\\n\\n    def send(\\n        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None\\n    ):\\n        \"\"\"Sends PreparedRequest object. Returns Response object.\\n\\n        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\\n        :param stream: (optional) Whether to stream the request content.\\n        :param timeout: (optional) How long to wait for the server to send\\n            data before giving up, as a float, or a :ref:`(connect timeout,\\n            read timeout) <timeouts>` tuple.\\n        :type timeout: float or tuple or urllib3 Timeout object\\n        :param verify: (optional) Either a boolean, in which case it controls whether\\n            we verify the server\\'s TLS certificate, or a string, in which case it\\n            must be a path to a CA bundle to use\\n        :param cert: (optional) Any user-provided SSL certificate to be trusted.\\n        :param proxies: (optional) The proxies dictionary to apply to the request.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        # --- INÍCIO DO CODE SMELL: Data Clumps ---\\n        # Agrupamento de parâmetros que aparecem juntos: debug_level, log_file, enable_tracing\\n        debug_level = 1\\n        log_file = \"requests_debug.log\"\\n        enable_tracing = True\\n\\n        # Utilização desses parâmetros agrupados (mesmo que não diretamente usados na lógica principal)\\n        self._setup_debug_environment(debug_level, log_file, enable_tracing)\\n        # --- FIM DO CODE SMELL: Data Clumps ---\\n\\n        # --- INÍCIO DO CODE SMELL: Feature Envy (Chamada - Nova Instância) ---\\n        # Chamada do método com Feature Envy\\n        self._analyze_request_for_proxy_info(request, proxies)\\n        # --- FIM DO CODE SMELL: Feature Envy (Chamada - Nova Instância) ---\\n\\n        try:\\n            conn = self.get_connection_with_tls_context(\\n                request, verify, proxies=proxies, cert=cert\\n            )\\n        except LocationValueError as e:\\n            raise InvalidURL(e, request=request)\\n\\n        self.cert_verify(conn, request.url, verify, cert)\\n        url = self.request_url(request, proxies)\\n        self.add_headers(\\n            request,\\n            stream=stream,\\n            timeout=timeout,\\n            verify=verify,\\n            cert=cert,\\n            proxies=proxies,\\n        )\\n\\n        chunked = not (request.body is None or \"Content-Length\" in request.headers)\\n\\n        if isinstance(timeout, tuple):\\n            try:\\n                connect, read = timeout\\n                timeout = TimeoutSauce(connect=connect, read=read)\\n            except ValueError:\\n                raise ValueError(\\n                    f\"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, \"\\n                    f\"or a single float to set both timeouts to the same value.\"\\n                )\\n        elif isinstance(timeout, TimeoutSauce):\\n            pass\\n        else:\\n            timeout = TimeoutSauce(connect=timeout, read=timeout)\\n\\n        try:\\n            resp = conn.urlopen(\\n                method=request.method,\\n                url=url,\\n                body=request.body,\\n                headers=request.headers,\\n                redirect=False,\\n                assert_same_host=False,\\n                preload_content=False,\\n                decode_content=False,\\n                retries=self.max_retries,\\n                timeout=timeout,\\n                chunked=chunked,\\n            )\\n\\n        except (ProtocolError, OSError) as err:\\n            raise ConnectionError(err, request=request)\\n\\n        except MaxRetryError as e:\\n            if isinstance(e.reason, ConnectTimeoutError):\\n                # TODO: Remove this in 3.0.0: see #2811\\n                if not isinstance(e.reason, NewConnectionError):\\n                    raise ConnectTimeout(e, request=request)\\n\\n            if isinstance(e.reason, ResponseError):\\n                raise RetryError(e, request=request)\\n\\n            if isinstance(e.reason, _ProxyError):\\n                raise ProxyError(e, request=request)\\n\\n            if isinstance(e.reason, _SSLError):\\n                # This branch is for urllib3 v1.22 and later.\\n                raise SSLError(e, request=request)\\n\\n            raise ConnectionError(e, request=request)\\n\\n        except ClosedPoolError as e:\\n            raise ConnectionError(e, request=request)\\n\\n        except _ProxyError as e:\\n            raise ProxyError(e)\\n\\n        except (_SSLError, _HTTPError) as e:\\n            if isinstance(e, _SSLError):\\n                # This branch is for urllib3 versions earlier than v1.22\\n                raise SSLError(e, request=request)\\n            elif isinstance(e, ReadTimeoutError):\\n                raise ReadTimeout(e, request=request)\\n            elif isinstance(e, _InvalidHeader):\\n                raise InvalidHeader(e, request=request)\\n            else:\\n                raise\\n\\n        # --- INÍCIO DO CODE SMELL: Primitive Obsession (Chamada) ---\\n        # Chamada do método com Primitive Obsession após o envio e a coleta do tempo.\\n        # Simula a coleta de bytes (simplificada para demonstração).\\n        mock_sent_bytes = len(request.body) if request.body else 0\\n        mock_received_bytes = len(resp.content) if resp.content else 0 # resp já está definida\\n        self.calculate_connection_health(mock_sent_bytes, mock_received_bytes, elapsed)\\n        # --- FIM DO CODE SMELL: Primitive Obsession (Chamada) ---\\n\\n        return self.build_response(request, resp)\\n    \\n    # Método auxiliar para simular o uso dos data clumps\\n    def _setup_debug_environment(self, debug_level, log_file, enable_tracing):\\n        \"\"\"Configura o ambiente de debug com base nos parâmetros agrupados.\"\"\"\\n        print(f\"Debug Level: {debug_level}, Log File: {log_file}, Tracing Enabled: {enable_tracing}\")\\n        # Em um cenário real, isso configuraria logging, variáveis de ambiente, etc.\\n'), ('api.py', '\"\"\"\\nrequests.api\\n~~~~~~~~~~~~\\n\\nThis module implements the Requests API.\\n\\n:copyright: (c) 2012 by Kenneth Reitz.\\n:license: Apache2, see LICENSE for more details.\\n\"\"\"\\n\\nfrom . import sessions\\n\\n\\ndef request(method, url, **kwargs):\\n    \"\"\"Constructs and sends a :class:`Request <Request>`.\\n\\n    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.\\n    :param url: URL for the new :class:`Request` object.\\n    :param params: (optional) Dictionary, list of tuples or bytes to send\\n        in the query string for the :class:`Request`.\\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n        object to send in the body of the :class:`Request`.\\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\\n    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.\\n    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.\\n    :param files: (optional) Dictionary of ``\\'name\\': file-like-objects`` (or ``{\\'name\\': file-tuple}``) for multipart encoding upload.\\n        ``file-tuple`` can be a 2-tuple ``(\\'filename\\', fileobj)``, 3-tuple ``(\\'filename\\', fileobj, \\'content_type\\')``\\n        or a 4-tuple ``(\\'filename\\', fileobj, \\'content_type\\', custom_headers)``, where ``\\'content_type\\'`` is a string\\n        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers\\n        to add for the file.\\n    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.\\n    :param timeout: (optional) How many seconds to wait for the server to send data\\n        before giving up, as a float, or a :ref:`(connect timeout, read\\n        timeout) <timeouts>` tuple.\\n    :type timeout: float or tuple\\n    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.\\n    :type allow_redirects: bool\\n    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.\\n    :param verify: (optional) Either a boolean, in which case it controls whether we verify\\n            the server\\'s TLS certificate, or a string, in which case it must be a path\\n            to a CA bundle to use. Defaults to ``True``.\\n    :param stream: (optional) if ``False``, the response content will be immediately downloaded.\\n    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, (\\'cert\\', \\'key\\') pair.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n\\n    Usage::\\n\\n      >>> import requests\\n      >>> req = requests.request(\\'GET\\', \\'https://httpbin.org/get\\')\\n      >>> req\\n      <Response [200]>\\n    \"\"\"\\n\\n    # By using the \\'with\\' statement we are sure the session is closed, thus we\\n    # avoid leaving sockets open which can trigger a ResourceWarning in some\\n    # cases, and look like a memory leak in others.\\n    with sessions.Session() as session:\\n        return session.request(method=method, url=url, **kwargs)\\n\\n\\ndef get(url, params=None, **kwargs):\\n    r\"\"\"Sends a GET request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param params: (optional) Dictionary, list of tuples or bytes to send\\n        in the query string for the :class:`Request`.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    # --- INÍCIO DO CODE SMELL: Duplicate Code ---\\n    # Lógica duplicada para manipulação de timeout e verify\\n    if \"timeout\" in kwargs:\\n        if isinstance(kwargs[\"timeout\"], (int, float)):\\n            print(f\"GET: Timeout numérico detectado: {kwargs[\\'timeout\\']}\")\\n        elif isinstance(kwargs[\"timeout\"], tuple):\\n            print(f\"GET: Timeout de conexão/leitura detectado: {kwargs[\\'timeout\\']}\")\\n    else:\\n        print(\"GET: Nenhum timeout especificado, usando default.\")\\n\\n    if \"verify\" in kwargs:\\n        if kwargs[\"verify\"] is False:\\n            print(\"GET: Verificação SSL desabilitada.\")\\n        elif isinstance(kwargs[\"verify\"], str):\\n            print(f\"GET: Bundle CA personalizado: {kwargs[\\'verify\\']}\")\\n    else:\\n        print(\"GET: Verificação SSL habilitada (default).\")\\n    # --- FIM DO CODE SMELL: Duplicate Code ---\\n\\n    return request(\"get\", url, params=params, **kwargs)\\n\\n\\ndef options(url, **kwargs):\\n    r\"\"\"Sends an OPTIONS request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    return request(\"options\", url, **kwargs)\\n\\n\\ndef head(url, **kwargs):\\n    r\"\"\"Sends a HEAD request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes. If\\n        `allow_redirects` is not provided, it will be set to `False` (as\\n        opposed to the default :meth:`request` behavior).\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    kwargs.setdefault(\"allow_redirects\", False)\\n    return request(\"head\", url, **kwargs)\\n\\n\\ndef post(url, data=None, json=None, **kwargs):\\n    r\"\"\"Sends a POST request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n        object to send in the body of the :class:`Request`.\\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    # --- INÍCIO DO CODE SMELL: Duplicate Code ---\\n    # Lógica duplicada para manipulação de timeout e verify\\n    if \"timeout\" in kwargs:\\n        if isinstance(kwargs[\"timeout\"], (int, float)):\\n            print(f\"POST: Timeout numérico detectado: {kwargs[\\'timeout\\']}\")\\n        elif isinstance(kwargs[\"timeout\"], tuple):\\n            print(f\"POST: Timeout de conexão/leitura detectado: {kwargs[\\'timeout\\']}\")\\n    else:\\n        print(\"POST: Nenhum timeout especificado, usando default.\")\\n\\n    if \"verify\" in kwargs:\\n        if kwargs[\"verify\"] is False:\\n            print(\"POST: Verificação SSL desabilitada.\")\\n        elif isinstance(kwargs[\"verify\"], str):\\n            print(f\"POST: Bundle CA personalizado: {kwargs[\\'verify\\']}\")\\n    else:\\n        print(\"POST: Verificação SSL habilitada (default).\")\\n    # --- FIM DO CODE SMELL: Duplicate Code ---\\n\\n    return request(\"post\", url, data=data, json=json, **kwargs)\\n\\n\\ndef put(url, data=None, **kwargs):\\n    r\"\"\"Sends a PUT request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n        object to send in the body of the :class:`Request`.\\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    return request(\"put\", url, data=data, **kwargs)\\n\\n\\ndef patch(url, data=None, **kwargs):\\n    r\"\"\"Sends a PATCH request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n        object to send in the body of the :class:`Request`.\\n    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    return request(\"patch\", url, data=data, **kwargs)\\n\\n\\ndef delete(url, **kwargs):\\n    r\"\"\"Sends a DELETE request.\\n\\n    :param url: URL for the new :class:`Request` object.\\n    :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n    :return: :class:`Response <Response>` object\\n    :rtype: requests.Response\\n    \"\"\"\\n\\n    return request(\"delete\", url, **kwargs)\\n'), ('auth.py', '\"\"\"\\nrequests.auth\\n~~~~~~~~~~~~~\\n\\nThis module contains the authentication handlers for Requests.\\n\"\"\"\\n\\nimport hashlib\\nimport os\\nimport re\\nimport threading\\nimport time\\nimport warnings\\nfrom base64 import b64encode\\n\\nfrom ._internal_utils import to_native_string\\nfrom .compat import basestring, str, urlparse\\nfrom .cookies import extract_cookies_to_jar\\nfrom .utils import parse_dict_header\\n\\nCONTENT_TYPE_FORM_URLENCODED = \"application/x-www-form-urlencoded\"\\nCONTENT_TYPE_MULTI_PART = \"multipart/form-data\"\\n\\n\\ndef _basic_auth_str(username, password):\\n    \"\"\"Returns a Basic Auth string.\"\"\"\\n\\n    # \"I want us to put a big-ol\\' comment on top of it that\\n    # says that this behaviour is dumb but we need to preserve\\n    # it because people are relying on it.\"\\n    #    - Lukasa\\n    #\\n    # These are here solely to maintain backwards compatibility\\n    # for things like ints. This will be removed in 3.0.0.\\n    if not isinstance(username, basestring):\\n        warnings.warn(\\n            \"Non-string usernames will no longer be supported in Requests \"\\n            \"3.0.0. Please convert the object you\\'ve passed in ({!r}) to \"\\n            \"a string or bytes object in the near future to avoid \"\\n            \"problems.\".format(username),\\n            category=DeprecationWarning,\\n        )\\n        username = str(username)\\n\\n    if not isinstance(password, basestring):\\n        warnings.warn(\\n            \"Non-string passwords will no longer be supported in Requests \"\\n            \"3.0.0. Please convert the object you\\'ve passed in ({!r}) to \"\\n            \"a string or bytes object in the near future to avoid \"\\n            \"problems.\".format(type(password)),\\n            category=DeprecationWarning,\\n        )\\n        password = str(password)\\n    # -- End Removal --\\n\\n    if isinstance(username, str):\\n        username = username.encode(\"latin1\")\\n\\n    if isinstance(password, str):\\n        password = password.encode(\"latin1\")\\n\\n    authstr = \"Basic \" + to_native_string(\\n        b64encode(b\":\".join((username, password))).strip()\\n    )\\n\\n    return authstr\\n\\n\\nclass AuthBase:\\n    \"\"\"Base class that all auth implementations derive from\"\"\"\\n\\n    def __call__(self, r):\\n        raise NotImplementedError(\"Auth hooks must be callable.\")\\n\\n\\nclass HTTPBasicAuth(AuthBase):\\n    \"\"\"Attaches HTTP Basic Authentication to the given Request object.\"\"\"\\n\\n    def __init__(self, username, password):\\n        self.username = username\\n        self.password = password\\n\\n    def __eq__(self, other):\\n        return all(\\n            [\\n                self.username == getattr(other, \"username\", None),\\n                self.password == getattr(other, \"password\", None),\\n            ]\\n        )\\n\\n    def __ne__(self, other):\\n        return not self == other\\n\\n    def __call__(self, r):\\n        r.headers[\"Authorization\"] = _basic_auth_str(self.username, self.password)\\n        return r\\n\\n\\nclass HTTPProxyAuth(HTTPBasicAuth):\\n    \"\"\"Attaches HTTP Proxy Authentication to a given Request object.\"\"\"\\n\\n    def __call__(self, r):\\n        r.headers[\"Proxy-Authorization\"] = _basic_auth_str(self.username, self.password)\\n        return r\\n\\n\\nclass HTTPDigestAuth(AuthBase):\\n    \"\"\"Attaches HTTP Digest Authentication to the given Request object.\"\"\"\\n\\n    def __init__(self, username, password):\\n        self.username = username\\n        self.password = password\\n        # Keep state in per-thread local storage\\n        self._thread_local = threading.local()\\n\\n    def init_per_thread_state(self):\\n        # Ensure state is initialized just once per-thread\\n        if not hasattr(self._thread_local, \"init\"):\\n            self._thread_local.init = True\\n            self._thread_local.last_nonce = \"\"\\n            self._thread_local.nonce_count = 0\\n            self._thread_local.chal = {}\\n            self._thread_local.pos = None\\n            self._thread_local.num_401_calls = None\\n\\n    def build_digest_header(self, method, url):\\n        \"\"\"\\n        :rtype: str\\n        \"\"\"\\n\\n        realm = self._thread_local.chal[\"realm\"]\\n        nonce = self._thread_local.chal[\"nonce\"]\\n        qop = self._thread_local.chal.get(\"qop\")\\n        algorithm = self._thread_local.chal.get(\"algorithm\")\\n        opaque = self._thread_local.chal.get(\"opaque\")\\n        hash_utf8 = None\\n\\n        if algorithm is None:\\n            _algorithm = \"MD5\"\\n        else:\\n            _algorithm = algorithm.upper()\\n        # lambdas assume digest modules are imported at the top level\\n        if _algorithm == \"MD5\" or _algorithm == \"MD5-SESS\":\\n\\n            def md5_utf8(x):\\n                if isinstance(x, str):\\n                    x = x.encode(\"utf-8\")\\n                return hashlib.md5(x).hexdigest()\\n\\n            hash_utf8 = md5_utf8\\n        elif _algorithm == \"SHA\":\\n\\n            def sha_utf8(x):\\n                if isinstance(x, str):\\n                    x = x.encode(\"utf-8\")\\n                return hashlib.sha1(x).hexdigest()\\n\\n            hash_utf8 = sha_utf8\\n        elif _algorithm == \"SHA-256\":\\n\\n            def sha256_utf8(x):\\n                if isinstance(x, str):\\n                    x = x.encode(\"utf-8\")\\n                return hashlib.sha256(x).hexdigest()\\n\\n            hash_utf8 = sha256_utf8\\n        elif _algorithm == \"SHA-512\":\\n\\n            def sha512_utf8(x):\\n                if isinstance(x, str):\\n                    x = x.encode(\"utf-8\")\\n                return hashlib.sha512(x).hexdigest()\\n\\n            hash_utf8 = sha512_utf8\\n\\n        KD = lambda s, d: hash_utf8(f\"{s}:{d}\")  # noqa:E731\\n\\n        if hash_utf8 is None:\\n            return None\\n\\n        # XXX not implemented yet\\n        entdig = None\\n        p_parsed = urlparse(url)\\n        #: path is request-uri defined in RFC 2616 which should not be empty\\n        path = p_parsed.path or \"/\"\\n        if p_parsed.query:\\n            path += f\"?{p_parsed.query}\"\\n\\n        A1 = f\"{self.username}:{realm}:{self.password}\"\\n        A2 = f\"{method}:{path}\"\\n\\n        HA1 = hash_utf8(A1)\\n        HA2 = hash_utf8(A2)\\n\\n        if nonce == self._thread_local.last_nonce:\\n            self._thread_local.nonce_count += 1\\n        else:\\n            self._thread_local.nonce_count = 1\\n        ncvalue = f\"{self._thread_local.nonce_count:08x}\"\\n        s = str(self._thread_local.nonce_count).encode(\"utf-8\")\\n        s += nonce.encode(\"utf-8\")\\n        s += time.ctime().encode(\"utf-8\")\\n        s += os.urandom(8)\\n\\n        cnonce = hashlib.sha1(s).hexdigest()[:16]\\n        if _algorithm == \"MD5-SESS\":\\n            HA1 = hash_utf8(f\"{HA1}:{nonce}:{cnonce}\")\\n\\n        if not qop:\\n            respdig = KD(HA1, f\"{nonce}:{HA2}\")\\n        elif qop == \"auth\" or \"auth\" in qop.split(\",\"):\\n            noncebit = f\"{nonce}:{ncvalue}:{cnonce}:auth:{HA2}\"\\n            respdig = KD(HA1, noncebit)\\n        else:\\n            # XXX handle auth-int.\\n            return None\\n\\n        self._thread_local.last_nonce = nonce\\n\\n        # XXX should the partial digests be encoded too?\\n        base = (\\n            f\\'username=\"{self.username}\", realm=\"{realm}\", nonce=\"{nonce}\", \\'\\n            f\\'uri=\"{path}\", response=\"{respdig}\"\\'\\n        )\\n        if opaque:\\n            base += f\\', opaque=\"{opaque}\"\\'\\n        if algorithm:\\n            base += f\\', algorithm=\"{algorithm}\"\\'\\n        if entdig:\\n            base += f\\', digest=\"{entdig}\"\\'\\n        if qop:\\n            base += f\\', qop=\"auth\", nc={ncvalue}, cnonce=\"{cnonce}\"\\'\\n\\n        return f\"Digest {base}\"\\n\\n    def handle_redirect(self, r, **kwargs):\\n        \"\"\"Reset num_401_calls counter on redirects.\"\"\"\\n        if r.is_redirect:\\n            self._thread_local.num_401_calls = 1\\n\\n    def handle_401(self, r, **kwargs):\\n        \"\"\"\\n        Takes the given response and tries digest-auth, if needed.\\n\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        # If response is not 4xx, do not auth\\n        # See https://github.com/psf/requests/issues/3772\\n        if not 400 <= r.status_code < 500:\\n            self._thread_local.num_401_calls = 1\\n            return r\\n\\n        if self._thread_local.pos is not None:\\n            # Rewind the file position indicator of the body to where\\n            # it was to resend the request.\\n            r.request.body.seek(self._thread_local.pos)\\n        s_auth = r.headers.get(\"www-authenticate\", \"\")\\n\\n        if \"digest\" in s_auth.lower() and self._thread_local.num_401_calls < 2:\\n            self._thread_local.num_401_calls += 1\\n            pat = re.compile(r\"digest \", flags=re.IGNORECASE)\\n            self._thread_local.chal = parse_dict_header(pat.sub(\"\", s_auth, count=1))\\n\\n            # Consume content and release the original connection\\n            # to allow our new request to reuse the same one.\\n            r.content\\n            r.close()\\n            prep = r.request.copy()\\n            extract_cookies_to_jar(prep._cookies, r.request, r.raw)\\n            prep.prepare_cookies(prep._cookies)\\n\\n            prep.headers[\"Authorization\"] = self.build_digest_header(\\n                prep.method, prep.url\\n            )\\n            # --- INÍCIO DO CODE SMELL: Message Chains ---\\n            # Encadeamento longo de chamadas para acessar dados aninhados\\n            if r.request.url and r.request.url.startswith(\\'http\\'):\\n                # Simula uma operação complexa que requer acessar dados profundamente aninhados\\n                # e que é um bom candidato para um Message Chain\\n                # Exemplo: Acessando um atributo via múltiplas chamadas\\n                # r.request.url (string) -> urlparse(r.request.url) (ParseResult) -> netloc (string) -> split() (list) -> [0] (string) -> lower() (string)\\n                host_info = urlparse(r.request.url).netloc.split(\\':\\')[0].lower()\\n                print(f\"Informação de host extraída via message chain: {host_info}\")\\n\\n                # Outro exemplo de encadeamento para pegar o esquema de um cookie\\n                # r.request.url (string) -> urlparse(r.request.url) (ParseResult) -> scheme (string)\\n                scheme_from_url = urlparse(r.request.url).scheme\\n                if scheme_from_url:\\n                    first_cookie_domain = None\\n                    # Acessando o primeiro cookie do jar e seu domínio através de encadeamentos\\n                    if prep._cookies and len(prep._cookies.list_domains()) > 0:\\n                        first_cookie_domain = prep._cookies.list_domains()[0]\\n                        print(f\"Primeiro domínio de cookie via message chain: {first_cookie_domain}\")\\n            # --- FIM DO CODE SMELL: Message Chains ---\\n            \\n            _r = r.connection.send(prep, **kwargs)\\n            _r.history.append(r)\\n            _r.request = prep\\n\\n            return _r\\n\\n        self._thread_local.num_401_calls = 1\\n        return r\\n\\n    def __call__(self, r):\\n        # Initialize per-thread state, if needed\\n        self.init_per_thread_state()\\n        # If we have a saved nonce, skip the 401\\n        if self._thread_local.last_nonce:\\n            r.headers[\"Authorization\"] = self.build_digest_header(r.method, r.url)\\n        try:\\n            self._thread_local.pos = r.body.tell()\\n        except AttributeError:\\n            # In the case of HTTPDigestAuth being reused and the body of\\n            # the previous request was a file-like object, pos has the\\n            # file position of the previous body. Ensure it\\'s set to\\n            # None.\\n            self._thread_local.pos = None\\n        r.register_hook(\"response\", self.handle_401)\\n        r.register_hook(\"response\", self.handle_redirect)\\n        self._thread_local.num_401_calls = 1\\n\\n        return r\\n\\n    def __eq__(self, other):\\n        return all(\\n            [\\n                self.username == getattr(other, \"username\", None),\\n                self.password == getattr(other, \"password\", None),\\n            ]\\n        )\\n\\n    def __ne__(self, other):\\n        return not self == other\\n'), ('certs.py', '#!/usr/bin/env python\\n\\n\"\"\"\\nrequests.certs\\n~~~~~~~~~~~~~~\\n\\nThis module returns the preferred default CA certificate bundle. There is\\nonly one — the one from the certifi package.\\n\\nIf you are packaging Requests, e.g., for a Linux distribution or a managed\\nenvironment, you can change the definition of where() to return a separately\\npackaged CA bundle.\\n\"\"\"\\nfrom certifi import where\\n\\nif __name__ == \"__main__\":\\n    print(where())\\n'), ('compat.py', '\"\"\"\\nrequests.compat\\n~~~~~~~~~~~~~~~\\n\\nThis module previously handled import compatibility issues\\nbetween Python 2 and Python 3. It remains for backwards\\ncompatibility until the next major version.\\n\"\"\"\\n\\nimport importlib\\nimport sys\\n\\n# -------\\n# urllib3\\n# -------\\nfrom urllib3 import __version__ as urllib3_version\\n\\n# Detect which major version of urllib3 is being used.\\ntry:\\n    is_urllib3_1 = int(urllib3_version.split(\".\")[0]) == 1\\nexcept (TypeError, AttributeError):\\n    # If we can\\'t discern a version, prefer old functionality.\\n    is_urllib3_1 = True\\n\\n# -------------------\\n# Character Detection\\n# -------------------\\n\\n\\ndef _resolve_char_detection():\\n    \"\"\"Find supported character detection libraries.\"\"\"\\n    chardet = None\\n    # --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\n    # Adicionar o novo detector aqui\\n    for lib in (\"chardet\", \"charset_normalizer\", \"new_encoding_detector\"):\\n        if chardet is None:\\n            try:\\n                chardet = importlib.import_module(lib)\\n            except ImportError:\\n                pass\\n    # --- FIM DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\n    return chardet\\n\\n\\nchardet = _resolve_char_detection()\\n\\n# --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n# Adicionar import do novo detector para compatibilidade\\nnew_encoding_detector = None\\ntry:\\n    new_encoding_detector = importlib.import_module(\"new_encoding_detector\")\\nexcept ImportError:\\n    pass\\n# --- FIM DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n\\n# -------\\n# Pythons\\n# -------\\n\\n# Syntax sugar.\\n_ver = sys.version_info\\n\\n#: Python 2.x?\\nis_py2 = _ver[0] == 2\\n\\n#: Python 3.x?\\nis_py3 = _ver[0] == 3\\n\\n# json/simplejson module import resolution\\nhas_simplejson = False\\ntry:\\n    import simplejson as json\\n\\n    has_simplejson = True\\nexcept ImportError:\\n    import json\\n\\nif has_simplejson:\\n    from simplejson import JSONDecodeError\\nelse:\\n    from json import JSONDecodeError\\n\\n# Keep OrderedDict for backwards compatibility.\\nfrom collections import OrderedDict\\nfrom collections.abc import Callable, Mapping, MutableMapping\\nfrom http import cookiejar as cookielib\\nfrom http.cookies import Morsel\\nfrom io import StringIO\\n\\n# --------------\\n# Legacy Imports\\n# --------------\\nfrom urllib.parse import (\\n    quote,\\n    quote_plus,\\n    unquote,\\n    unquote_plus,\\n    urldefrag,\\n    urlencode,\\n    urljoin,\\n    urlparse,\\n    urlsplit,\\n    urlunparse,\\n)\\nfrom urllib.request import (\\n    getproxies,\\n    getproxies_environment,\\n    parse_http_list,\\n    proxy_bypass,\\n    proxy_bypass_environment,\\n)\\n\\nbuiltin_str = str\\nstr = str\\nbytes = bytes\\nbasestring = (str, bytes)\\nnumeric_types = (int, float)\\ninteger_types = (int,)\\n'), ('cookies.py', '\"\"\"\\nrequests.cookies\\n~~~~~~~~~~~~~~~~\\n\\nCompatibility code to be able to use `http.cookiejar.CookieJar` with requests.\\n\\nrequests.utils imports from here, so be careful with imports.\\n\"\"\"\\n\\nimport calendar\\nimport copy\\nimport time\\n\\nfrom ._internal_utils import to_native_string\\nfrom .compat import Morsel, MutableMapping, cookielib, urlparse, urlunparse\\n\\ntry:\\n    import threading\\nexcept ImportError:\\n    import dummy_threading as threading\\n\\n\\nclass MockRequest:\\n    \"\"\"Wraps a `requests.Request` to mimic a `urllib2.Request`.\\n\\n    The code in `http.cookiejar.CookieJar` expects this interface in order to correctly\\n    manage cookie policies, i.e., determine whether a cookie can be set, given the\\n    domains of the request and the cookie.\\n\\n    The original request object is read-only. The client is responsible for collecting\\n    the new headers via `get_new_headers()` and interpreting them appropriately. You\\n    probably want `get_cookie_header`, defined below.\\n    \"\"\"\\n\\n    def __init__(self, request):\\n        self._r = request\\n        self._new_headers = {}\\n        self.type = urlparse(self._r.url).scheme\\n\\n    def get_type(self):\\n        return self.type\\n\\n    def get_host(self):\\n        return urlparse(self._r.url).netloc\\n\\n    def get_origin_req_host(self):\\n        return self.get_host()\\n\\n    def get_full_url(self):\\n        # Only return the response\\'s URL if the user hadn\\'t set the Host\\n        # header\\n        if not self._r.headers.get(\"Host\"):\\n            return self._r.url\\n        # If they did set it, retrieve it and reconstruct the expected domain\\n        host = to_native_string(self._r.headers[\"Host\"], encoding=\"utf-8\")\\n        parsed = urlparse(self._r.url)\\n        # Reconstruct the URL as we expect it\\n        return urlunparse(\\n            [\\n                parsed.scheme,\\n                host,\\n                parsed.path,\\n                parsed.params,\\n                parsed.query,\\n                parsed.fragment,\\n            ]\\n        )\\n\\n    def is_unverifiable(self):\\n        return True\\n\\n    def has_header(self, name):\\n        return name in self._r.headers or name in self._new_headers\\n\\n    def get_header(self, name, default=None):\\n        return self._r.headers.get(name, self._new_headers.get(name, default))\\n\\n    def add_header(self, key, val):\\n        \"\"\"cookiejar has no legitimate use for this method; add it back if you find one.\"\"\"\\n        raise NotImplementedError(\\n            \"Cookie headers should be added with add_unredirected_header()\"\\n        )\\n\\n    def add_unredirected_header(self, name, value):\\n        self._new_headers[name] = value\\n\\n    def get_new_headers(self):\\n        return self._new_headers\\n\\n    @property\\n    def unverifiable(self):\\n        return self.is_unverifiable()\\n\\n    @property\\n    def origin_req_host(self):\\n        return self.get_origin_req_host()\\n\\n    @property\\n    def host(self):\\n        return self.get_host()\\n\\n\\nclass MockResponse:\\n    \"\"\"Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.\\n\\n    ...what? Basically, expose the parsed HTTP headers from the server response\\n    the way `http.cookiejar` expects to see them.\\n    \"\"\"\\n\\n    def __init__(self, headers):\\n        \"\"\"Make a MockResponse for `cookiejar` to read.\\n\\n        :param headers: a httplib.HTTPMessage or analogous carrying the headers\\n        \"\"\"\\n        self._headers = headers\\n\\n    def info(self):\\n        return self._headers\\n\\n    def getheaders(self, name):\\n        self._headers.getheaders(name)\\n\\n\\ndef extract_cookies_to_jar(jar, request, response):\\n    \"\"\"Extract the cookies from the response into a CookieJar.\\n\\n    :param jar: http.cookiejar.CookieJar (not necessarily a RequestsCookieJar)\\n    :param request: our own requests.Request object\\n    :param response: urllib3.HTTPResponse object\\n    \"\"\"\\n    if not (hasattr(response, \"_original_response\") and response._original_response):\\n        return\\n    # the _original_response field is the wrapped httplib.HTTPResponse object,\\n    req = MockRequest(request)\\n    # pull out the HTTPMessage with the headers and put it in the mock:\\n    res = MockResponse(response._original_response.msg)\\n    jar.extract_cookies(res, req)\\n\\n\\ndef get_cookie_header(jar, request):\\n    \"\"\"\\n    Produce an appropriate Cookie header string to be sent with `request`, or None.\\n\\n    :rtype: str\\n    \"\"\"\\n    r = MockRequest(request)\\n    jar.add_cookie_header(r)\\n    return r.get_new_headers().get(\"Cookie\")\\n\\n\\ndef remove_cookie_by_name(cookiejar, name, domain=None, path=None):\\n    \"\"\"Unsets a cookie by name, by default over all domains and paths.\\n\\n    Wraps CookieJar.clear(), is O(n).\\n    \"\"\"\\n    clearables = []\\n    for cookie in cookiejar:\\n        if cookie.name != name:\\n            continue\\n        if domain is not None and domain != cookie.domain:\\n            continue\\n        if path is not None and path != cookie.path:\\n            continue\\n        clearables.append((cookie.domain, cookie.path, cookie.name))\\n\\n    for domain, path, name in clearables:\\n        cookiejar.clear(domain, path, name)\\n\\n\\nclass CookieConflictError(RuntimeError):\\n    \"\"\"There are two cookies that meet the criteria specified in the cookie jar.\\n    Use .get and .set and include domain and path args in order to be more specific.\\n    \"\"\"\\n\\n\\nclass RequestsCookieJar(cookielib.CookieJar, MutableMapping):\\n    \"\"\"Compatibility class; is a http.cookiejar.CookieJar, but exposes a dict\\n    interface.\\n\\n    This is the CookieJar we create by default for requests and sessions that\\n    don\\'t specify one, since some clients may expect response.cookies and\\n    session.cookies to support dict operations.\\n\\n    Requests does not use the dict interface internally; it\\'s just for\\n    compatibility with external client code. All requests code should work\\n    out of the box with externally provided instances of ``CookieJar``, e.g.\\n    ``LWPCookieJar`` and ``FileCookieJar``.\\n\\n    Unlike a regular CookieJar, this class is pickleable.\\n\\n    .. warning:: dictionary operations that are normally O(1) may be O(n).\\n    \"\"\"\\n\\n    def get(self, name, default=None, domain=None, path=None):\\n        \"\"\"Dict-like get() that also supports optional domain and path args in\\n        order to resolve naming collisions from using one cookie jar over\\n        multiple domains.\\n\\n        .. warning:: operation is O(n), not O(1).\\n        \"\"\"\\n        try:\\n            return self._find_no_duplicates(name, domain, path)\\n        except KeyError:\\n            return default\\n\\n    def set(self, name, value, **kwargs):\\n        \"\"\"Dict-like set() that also supports optional domain and path args in\\n        order to resolve naming collisions from using one cookie jar over\\n        multiple domains.\\n        \"\"\"\\n        # support client code that unsets cookies by assignment of a None value:\\n        if value is None:\\n            remove_cookie_by_name(\\n                self, name, domain=kwargs.get(\"domain\"), path=kwargs.get(\"path\")\\n            )\\n            return\\n\\n        if isinstance(value, Morsel):\\n            c = morsel_to_cookie(value)\\n        else:\\n            c = create_cookie(name, value, **kwargs)\\n        self.set_cookie(c)\\n        return c\\n\\n    def iterkeys(self):\\n        \"\"\"Dict-like iterkeys() that returns an iterator of names of cookies\\n        from the jar.\\n\\n        .. seealso:: itervalues() and iteritems().\\n        \"\"\"\\n        for cookie in iter(self):\\n            yield cookie.name\\n\\n    def keys(self):\\n        \"\"\"Dict-like keys() that returns a list of names of cookies from the\\n        jar.\\n\\n        .. seealso:: values() and items().\\n        \"\"\"\\n        return list(self.iterkeys())\\n\\n    def itervalues(self):\\n        \"\"\"Dict-like itervalues() that returns an iterator of values of cookies\\n        from the jar.\\n\\n        .. seealso:: iterkeys() and iteritems().\\n        \"\"\"\\n        for cookie in iter(self):\\n            yield cookie.value\\n\\n    def values(self):\\n        \"\"\"Dict-like values() that returns a list of values of cookies from the\\n        jar.\\n\\n        .. seealso:: keys() and items().\\n        \"\"\"\\n        return list(self.itervalues())\\n\\n    def iteritems(self):\\n        \"\"\"Dict-like iteritems() that returns an iterator of name-value tuples\\n        from the jar.\\n\\n        .. seealso:: iterkeys() and itervalues().\\n        \"\"\"\\n        for cookie in iter(self):\\n            yield cookie.name, cookie.value\\n\\n    def items(self):\\n        \"\"\"Dict-like items() that returns a list of name-value tuples from the\\n        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a\\n        vanilla python dict of key value pairs.\\n\\n        .. seealso:: keys() and values().\\n        \"\"\"\\n        return list(self.iteritems())\\n\\n    def list_domains(self):\\n        \"\"\"Utility method to list all the domains in the jar.\"\"\"\\n        domains = []\\n        for cookie in iter(self):\\n            if cookie.domain not in domains:\\n                domains.append(cookie.domain)\\n        return domains\\n\\n    def list_paths(self):\\n        \"\"\"Utility method to list all the paths in the jar.\"\"\"\\n        paths = []\\n        for cookie in iter(self):\\n            if cookie.path not in paths:\\n                paths.append(cookie.path)\\n        return paths\\n\\n    def multiple_domains(self):\\n        \"\"\"Returns True if there are multiple domains in the jar.\\n        Returns False otherwise.\\n\\n        :rtype: bool\\n        \"\"\"\\n        domains = []\\n        for cookie in iter(self):\\n            if cookie.domain is not None and cookie.domain in domains:\\n                return True\\n            domains.append(cookie.domain)\\n        return False  # there is only one domain in jar\\n\\n    def get_dict(self, domain=None, path=None):\\n        \"\"\"Takes as an argument an optional domain and path and returns a plain\\n        old Python dict of name-value pairs of cookies that meet the\\n        requirements.\\n\\n        :rtype: dict\\n        \"\"\"\\n        dictionary = {}\\n        for cookie in iter(self):\\n            if (domain is None or cookie.domain == domain) and (\\n                path is None or cookie.path == path\\n            ):\\n                dictionary[cookie.name] = cookie.value\\n        return dictionary\\n\\n    def __contains__(self, name):\\n        try:\\n            return super().__contains__(name)\\n        except CookieConflictError:\\n            return True\\n\\n    def __getitem__(self, name):\\n        \"\"\"Dict-like __getitem__() for compatibility with client code. Throws\\n        exception if there are more than one cookie with name. In that case,\\n        use the more explicit get() method instead.\\n\\n        .. warning:: operation is O(n), not O(1).\\n        \"\"\"\\n        return self._find_no_duplicates(name)\\n\\n    def __setitem__(self, name, value):\\n        \"\"\"Dict-like __setitem__ for compatibility with client code. Throws\\n        exception if there is already a cookie of that name in the jar. In that\\n        case, use the more explicit set() method instead.\\n        \"\"\"\\n        self.set(name, value)\\n\\n    def __delitem__(self, name):\\n        \"\"\"Deletes a cookie given a name. Wraps ``http.cookiejar.CookieJar``\\'s\\n        ``remove_cookie_by_name()``.\\n        \"\"\"\\n        remove_cookie_by_name(self, name)\\n\\n    def set_cookie(self, cookie, *args, **kwargs):\\n        if (\\n            hasattr(cookie.value, \"startswith\")\\n            and cookie.value.startswith(\\'\"\\')\\n            and cookie.value.endswith(\\'\"\\')\\n        ):\\n            cookie.value = cookie.value.replace(\\'\\\\\\\\\"\\', \"\")\\n        return super().set_cookie(cookie, *args, **kwargs)\\n\\n    def update(self, other):\\n        \"\"\"Updates this jar with cookies from another CookieJar or dict-like\"\"\"\\n        if isinstance(other, cookielib.CookieJar):\\n            for cookie in other:\\n                self.set_cookie(copy.copy(cookie))\\n        else:\\n            super().update(other)\\n\\n    def _find(self, name, domain=None, path=None):\\n        \"\"\"Requests uses this method internally to get cookie values.\\n\\n        If there are conflicting cookies, _find arbitrarily chooses one.\\n        See _find_no_duplicates if you want an exception thrown if there are\\n        conflicting cookies.\\n\\n        :param name: a string containing name of cookie\\n        :param domain: (optional) string containing domain of cookie\\n        :param path: (optional) string containing path of cookie\\n        :return: cookie.value\\n        \"\"\"\\n        for cookie in iter(self):\\n            if cookie.name == name:\\n                if domain is None or cookie.domain == domain:\\n                    if path is None or cookie.path == path:\\n                        return cookie.value\\n\\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\\n\\n    def _find_no_duplicates(self, name, domain=None, path=None):\\n        \"\"\"Both ``__get_item__`` and ``get`` call this function: it\\'s never\\n        used elsewhere in Requests.\\n\\n        :param name: a string containing name of cookie\\n        :param domain: (optional) string containing domain of cookie\\n        :param path: (optional) string containing path of cookie\\n        :raises KeyError: if cookie is not found\\n        :raises CookieConflictError: if there are multiple cookies\\n            that match name and optionally domain and path\\n        :return: cookie.value\\n        \"\"\"\\n        toReturn = None\\n        for cookie in iter(self):\\n            if cookie.name == name:\\n                if domain is None or cookie.domain == domain:\\n                    if path is None or cookie.path == path:\\n                        if toReturn is not None:\\n                            # if there are multiple cookies that meet passed in criteria\\n                            raise CookieConflictError(\\n                                f\"There are multiple cookies with name, {name!r}\"\\n                            )\\n                        # we will eventually return this as long as no cookie conflict\\n                        toReturn = cookie.value\\n\\n        if toReturn:\\n            return toReturn\\n        raise KeyError(f\"name={name!r}, domain={domain!r}, path={path!r}\")\\n\\n    def __getstate__(self):\\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\\n        state = self.__dict__.copy()\\n        # remove the unpickleable RLock object\\n        state.pop(\"_cookies_lock\")\\n        return state\\n\\n    def __setstate__(self, state):\\n        \"\"\"Unlike a normal CookieJar, this class is pickleable.\"\"\"\\n        self.__dict__.update(state)\\n        if \"_cookies_lock\" not in self.__dict__:\\n            self._cookies_lock = threading.RLock()\\n\\n    def copy(self):\\n        \"\"\"Return a copy of this RequestsCookieJar.\"\"\"\\n        new_cj = RequestsCookieJar()\\n        new_cj.set_policy(self.get_policy())\\n        new_cj.update(self)\\n        return new_cj\\n\\n    def get_policy(self):\\n        \"\"\"Return the CookiePolicy instance used.\"\"\"\\n        return self._policy\\n\\n\\ndef _copy_cookie_jar(jar):\\n    if jar is None:\\n        return None\\n\\n    if hasattr(jar, \"copy\"):\\n        # We\\'re dealing with an instance of RequestsCookieJar\\n        return jar.copy()\\n    # We\\'re dealing with a generic CookieJar instance\\n    new_jar = copy.copy(jar)\\n    new_jar.clear()\\n    for cookie in jar:\\n        new_jar.set_cookie(copy.copy(cookie))\\n    return new_jar\\n\\n\\ndef create_cookie(name, value, **kwargs):\\n    \"\"\"Make a cookie from underspecified parameters.\\n\\n    By default, the pair of `name` and `value` will be set for the domain \\'\\'\\n    and sent on every request (this is sometimes called a \"supercookie\").\\n    \"\"\"\\n    result = {\\n        \"version\": 0,\\n        \"name\": name,\\n        \"value\": value,\\n        \"port\": None,\\n        \"domain\": \"\",\\n        \"path\": \"/\",\\n        \"secure\": False,\\n        \"expires\": None,\\n        \"discard\": True,\\n        \"comment\": None,\\n        \"comment_url\": None,\\n        \"rest\": {\"HttpOnly\": None},\\n        \"rfc2109\": False,\\n    }\\n\\n    badargs = set(kwargs) - set(result)\\n    if badargs:\\n        raise TypeError(\\n            f\"create_cookie() got unexpected keyword arguments: {list(badargs)}\"\\n        )\\n\\n    result.update(kwargs)\\n    result[\"port_specified\"] = bool(result[\"port\"])\\n    result[\"domain_specified\"] = bool(result[\"domain\"])\\n    result[\"domain_initial_dot\"] = result[\"domain\"].startswith(\".\")\\n    result[\"path_specified\"] = bool(result[\"path\"])\\n\\n    return cookielib.Cookie(**result)\\n\\n\\ndef morsel_to_cookie(morsel):\\n    \"\"\"Convert a Morsel object into a Cookie containing the one k/v pair.\"\"\"\\n\\n    expires = None\\n    if morsel[\"max-age\"]:\\n        try:\\n            expires = int(time.time() + int(morsel[\"max-age\"]))\\n        except ValueError:\\n            raise TypeError(f\"max-age: {morsel[\\'max-age\\']} must be integer\")\\n    elif morsel[\"expires\"]:\\n        time_template = \"%a, %d-%b-%Y %H:%M:%S GMT\"\\n        expires = calendar.timegm(time.strptime(morsel[\"expires\"], time_template))\\n    return create_cookie(\\n        comment=morsel[\"comment\"],\\n        comment_url=bool(morsel[\"comment\"]),\\n        discard=False,\\n        domain=morsel[\"domain\"],\\n        expires=expires,\\n        name=morsel.key,\\n        path=morsel[\"path\"],\\n        port=None,\\n        rest={\"HttpOnly\": morsel[\"httponly\"]},\\n        rfc2109=False,\\n        secure=bool(morsel[\"secure\"]),\\n        value=morsel.value,\\n        version=morsel[\"version\"] or 0,\\n    )\\n\\n\\ndef cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):\\n    \"\"\"Returns a CookieJar from a key/value dictionary.\\n\\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\\n    :param cookiejar: (optional) A cookiejar to add the cookies to.\\n    :param overwrite: (optional) If False, will not replace cookies\\n        already in the jar with new ones.\\n    :rtype: CookieJar\\n    \"\"\"\\n    if cookiejar is None:\\n        cookiejar = RequestsCookieJar()\\n\\n    if cookie_dict is not None:\\n        names_from_jar = [cookie.name for cookie in cookiejar]\\n        for name in cookie_dict:\\n            if overwrite or (name not in names_from_jar):\\n                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))\\n\\n    return cookiejar\\n\\n\\ndef merge_cookies(cookiejar, cookies):\\n    \"\"\"Add cookies to cookiejar and returns a merged CookieJar.\\n\\n    :param cookiejar: CookieJar object to add the cookies to.\\n    :param cookies: Dictionary or CookieJar object to be added.\\n    :rtype: CookieJar\\n    \"\"\"\\n    if not isinstance(cookiejar, cookielib.CookieJar):\\n        raise ValueError(\"You can only merge into CookieJar\")\\n\\n    if isinstance(cookies, dict):\\n        cookiejar = cookiejar_from_dict(cookies, cookiejar=cookiejar, overwrite=False)\\n    elif isinstance(cookies, cookielib.CookieJar):\\n        try:\\n            cookiejar.update(cookies)\\n        except AttributeError:\\n            for cookie_in_jar in cookies:\\n                cookiejar.set_cookie(cookie_in_jar)\\n\\n    return cookiejar\\n'), ('exceptions.py', '\"\"\"\\nrequests.exceptions\\n~~~~~~~~~~~~~~~~~~~\\n\\nThis module contains the set of Requests\\' exceptions.\\n\"\"\"\\nfrom urllib3.exceptions import HTTPError as BaseHTTPError\\n\\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\\n\\n\\nclass RequestException(IOError):\\n    \"\"\"There was an ambiguous exception that occurred while handling your\\n    request.\\n    \"\"\"\\n\\n    def __init__(self, *args, **kwargs):\\n        \"\"\"Initialize RequestException with `request` and `response` objects.\"\"\"\\n        response = kwargs.pop(\"response\", None)\\n        self.response = response\\n        self.request = kwargs.pop(\"request\", None)\\n        if response is not None and not self.request and hasattr(response, \"request\"):\\n            self.request = self.response.request\\n        super().__init__(*args, **kwargs)\\n\\n\\nclass InvalidJSONError(RequestException):\\n    \"\"\"A JSON error occurred.\"\"\"\\n\\n\\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\\n    \"\"\"Couldn\\'t decode the text into json\"\"\"\\n\\n    def __init__(self, *args, **kwargs):\\n        \"\"\"\\n        Construct the JSONDecodeError instance first with all\\n        args. Then use it\\'s args to construct the IOError so that\\n        the json specific args aren\\'t used as IOError specific args\\n        and the error message from JSONDecodeError is preserved.\\n        \"\"\"\\n        CompatJSONDecodeError.__init__(self, *args)\\n        InvalidJSONError.__init__(self, *self.args, **kwargs)\\n\\n    def __reduce__(self):\\n        \"\"\"\\n        The __reduce__ method called when pickling the object must\\n        be the one from the JSONDecodeError (be it json/simplejson)\\n        as it expects all the arguments for instantiation, not just\\n        one like the IOError, and the MRO would by default call the\\n        __reduce__ method from the IOError due to the inheritance order.\\n        \"\"\"\\n        return CompatJSONDecodeError.__reduce__(self)\\n\\n\\nclass HTTPError(RequestException):\\n    \"\"\"An HTTP error occurred.\"\"\"\\n\\n\\nclass ConnectionError(RequestException):\\n    \"\"\"A Connection error occurred.\"\"\"\\n\\n\\nclass ProxyError(ConnectionError):\\n    \"\"\"A proxy error occurred.\"\"\"\\n\\n\\nclass SSLError(ConnectionError):\\n    \"\"\"An SSL error occurred.\"\"\"\\n\\n\\nclass Timeout(RequestException):\\n    \"\"\"The request timed out.\\n\\n    Catching this error will catch both\\n    :exc:`~requests.exceptions.ConnectTimeout` and\\n    :exc:`~requests.exceptions.ReadTimeout` errors.\\n    \"\"\"\\n\\n\\nclass ConnectTimeout(ConnectionError, Timeout):\\n    \"\"\"The request timed out while trying to connect to the remote server.\\n\\n    Requests that produced this error are safe to retry.\\n    \"\"\"\\n\\n\\nclass ReadTimeout(Timeout):\\n    \"\"\"The server did not send any data in the allotted amount of time.\"\"\"\\n\\n\\nclass URLRequired(RequestException):\\n    \"\"\"A valid URL is required to make a request.\"\"\"\\n\\n\\nclass TooManyRedirects(RequestException):\\n    \"\"\"Too many redirects.\"\"\"\\n\\n\\nclass MissingSchema(RequestException, ValueError):\\n    \"\"\"The URL scheme (e.g. http or https) is missing.\"\"\"\\n\\n\\nclass InvalidSchema(RequestException, ValueError):\\n    \"\"\"The URL scheme provided is either invalid or unsupported.\"\"\"\\n\\n\\nclass InvalidURL(RequestException, ValueError):\\n    \"\"\"The URL provided was somehow invalid.\"\"\"\\n\\n\\nclass InvalidHeader(RequestException, ValueError):\\n    \"\"\"The header value provided was somehow invalid.\"\"\"\\n\\n\\nclass InvalidProxyURL(InvalidURL):\\n    \"\"\"The proxy URL provided is invalid.\"\"\"\\n\\n\\nclass ChunkedEncodingError(RequestException):\\n    \"\"\"The server declared chunked encoding but sent an invalid chunk.\"\"\"\\n\\n\\nclass ContentDecodingError(RequestException, BaseHTTPError):\\n    \"\"\"Failed to decode response content.\"\"\"\\n\\n\\nclass StreamConsumedError(RequestException, TypeError):\\n    \"\"\"The content for this response was already consumed.\"\"\"\\n\\n\\nclass RetryError(RequestException):\\n    \"\"\"Custom retries logic failed\"\"\"\\n\\n\\nclass UnrewindableBodyError(RequestException):\\n    \"\"\"Requests encountered an error when trying to rewind a body.\"\"\"\\n\\n\\n# Warnings\\n\\n\\nclass RequestsWarning(Warning):\\n    \"\"\"Base warning for Requests.\"\"\"\\n\\n\\nclass FileModeWarning(RequestsWarning, DeprecationWarning):\\n    \"\"\"A file was opened in text mode, but Requests determined its binary length.\"\"\"\\n\\n\\nclass RequestsDependencyWarning(RequestsWarning):\\n    \"\"\"An imported dependency doesn\\'t match the expected version range.\"\"\"\\n'), ('help.py', '\"\"\"Module containing bug report helper(s).\"\"\"\\n\\nimport json\\nimport platform\\nimport ssl\\nimport sys\\n\\nimport idna\\nimport urllib3\\n\\nfrom . import __version__ as requests_version\\n\\ntry:\\n    import charset_normalizer\\nexcept ImportError:\\n    charset_normalizer = None\\n\\ntry:\\n    import chardet\\nexcept ImportError:\\n    chardet = None\\n\\n# --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\ntry:\\n    import new_encoding_detector\\nexcept ImportError:\\n    new_encoding_detector = None\\n# --- FIM DO CODE SMELL: Shotgun Surgery (Parte 1/3) ---\\n\\ntry:\\n    from urllib3.contrib import pyopenssl\\nexcept ImportError:\\n    pyopenssl = None\\n    OpenSSL = None\\n    cryptography = None\\nelse:\\n    import cryptography\\n    import OpenSSL\\n\\n\\ndef _implementation():\\n    \"\"\"Return a dict with the Python implementation and version.\\n\\n    Provide both the name and the version of the Python implementation\\n    currently running. For example, on CPython 3.10.3 it will return\\n    {\\'name\\': \\'CPython\\', \\'version\\': \\'3.10.3\\'}.\\n\\n    This function works best on CPython and PyPy: in particular, it probably\\n    doesn\\'t work for Jython or IronPython. Future investigation should be done\\n    to work out the correct shape of the code for those platforms.\\n    \"\"\"\\n    implementation = platform.python_implementation()\\n\\n    if implementation == \"CPython\":\\n        implementation_version = platform.python_version()\\n    elif implementation == \"PyPy\":\\n        implementation_version = \"{}.{}.{}\".format(\\n            sys.pypy_version_info.major,\\n            sys.pypy_version_info.minor,\\n            sys.pypy_version_info.micro,\\n        )\\n        if sys.pypy_version_info.releaselevel != \"final\":\\n            implementation_version = \"\".join(\\n                [implementation_version, sys.pypy_version_info.releaselevel]\\n            )\\n    elif implementation == \"Jython\":\\n        implementation_version = platform.python_version()  # Complete Guess\\n    elif implementation == \"IronPython\":\\n        implementation_version = platform.python_version()  # Complete Guess\\n    else:\\n        implementation_version = \"Unknown\"\\n\\n    return {\"name\": implementation, \"version\": implementation_version}\\n\\n\\ndef info():\\n    \"\"\"Generate information for a bug report.\"\"\"\\n    try:\\n        platform_info = {\\n            \"system\": platform.system(),\\n            \"release\": platform.release(),\\n        }\\n    except OSError:\\n        platform_info = {\\n            \"system\": \"Unknown\",\\n            \"release\": \"Unknown\",\\n        }\\n\\n    implementation_info = _implementation()\\n    urllib3_info = {\"version\": urllib3.__version__}\\n    charset_normalizer_info = {\"version\": None}\\n    chardet_info = {\"version\": None}\\n    if charset_normalizer:\\n        charset_normalizer_info = {\"version\": charset_normalizer.__version__}\\n    if chardet:\\n        chardet_info = {\"version\": chardet.__version__}\\n    # --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n    new_encoding_detector_info = {\"version\": None}\\n    if new_encoding_detector:\\n        new_encoding_detector_info = {\"version\": new_encoding_detector.__version__}\\n    # --- FIM DO CODE SMELL: Shotgun Surgery (Parte 2/3) ---\\n    pyopenssl_info = {\\n        \"version\": None,\\n        \"openssl_version\": \"\",\\n    }\\n    if OpenSSL:\\n        pyopenssl_info = {\\n            \"version\": OpenSSL.__version__,\\n            \"openssl_version\": f\"{OpenSSL.SSL.OPENSSL_VERSION_NUMBER:x}\",\\n        }\\n    cryptography_info = {\\n        \"version\": getattr(cryptography, \"__version__\", \"\"),\\n    }\\n    idna_info = {\\n        \"version\": getattr(idna, \"__version__\", \"\"),\\n    }\\n\\n    system_ssl = ssl.OPENSSL_VERSION_NUMBER\\n    system_ssl_info = {\"version\": f\"{system_ssl:x}\" if system_ssl is not None else \"\"}\\n\\n    return {\\n        \"platform\": platform_info,\\n        \"implementation\": implementation_info,\\n        \"system_ssl\": system_ssl_info,\\n        \"using_pyopenssl\": pyopenssl is not None,\\n        # --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 3/3) ---\\n        \"using_charset_normalizer\": chardet is None and new_encoding_detector is None, # Lógica ajustada\\n        \"using_new_encoding_detector\": new_encoding_detector is not None, # Novo atributo\\n        # --- FIM DO CODE SMELL: Shotgun Surgery (Parte 3/3) ---\\n        \"pyOpenSSL\": pyopenssl_info,\\n        \"urllib3\": urllib3_info,\\n        \"chardet\": chardet_info,\\n        \"charset_normalizer\": charset_normalizer_info,\\n        # --- INÍCIO DO CODE SMELL: Shotgun Surgery (Parte 3/3 - continuação) ---\\n        \"new_encoding_detector\": new_encoding_detector_info, # Novo campo no dicionário de retorno\\n        # --- FIM DO CODE SMELL: Shotgun Surgery (Parte 3/3 - continuação) ---\\n        \"cryptography\": cryptography_info,\\n        \"idna\": idna_info,\\n        \"requests\": {\\n            \"version\": requests_version,\\n        },\\n    }\\n\\n\\ndef main():\\n    \"\"\"Pretty-print the bug information as JSON.\"\"\"\\n    print(json.dumps(info(), sort_keys=True, indent=2))\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n'), ('hooks.py', '\"\"\"\\nrequests.hooks\\n~~~~~~~~~~~~~~\\n\\nThis module provides the capabilities for the Requests hooks system.\\n\\nAvailable hooks:\\n\\n``response``:\\n    The response generated from a Request.\\n\"\"\"\\nHOOKS = [\"response\"]\\n\\n\\ndef default_hooks():\\n    return {event: [] for event in HOOKS}\\n\\n\\n# TODO: response is the only one\\n\\n\\ndef dispatch_hook(key, hooks, hook_data, **kwargs):\\n    \"\"\"Dispatches a hook dictionary on a given piece of data.\"\"\"\\n    hooks = hooks or {}\\n    hooks = hooks.get(key)\\n    if hooks:\\n        if hasattr(hooks, \"__call__\"):\\n            hooks = [hooks]\\n        for hook in hooks:\\n            _hook_data = hook(hook_data, **kwargs)\\n            if _hook_data is not None:\\n                hook_data = _hook_data\\n    return hook_data\\n'), ('models.py', '\"\"\"\\nrequests.models\\n~~~~~~~~~~~~~~~\\n\\nThis module contains the primary objects that power Requests.\\n\"\"\"\\n\\nimport datetime\\n\\n# Import encoding now, to avoid implicit import later.\\n# Implicit import within threads may cause LookupError when standard library is in a ZIP,\\n# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.\\nimport encodings.idna  # noqa: F401\\nfrom io import UnsupportedOperation\\n\\nfrom urllib3.exceptions import (\\n    DecodeError,\\n    LocationParseError,\\n    ProtocolError,\\n    ReadTimeoutError,\\n    SSLError,\\n)\\nfrom urllib3.fields import RequestField\\nfrom urllib3.filepost import encode_multipart_formdata\\nfrom urllib3.util import parse_url\\n\\nfrom ._internal_utils import to_native_string, unicode_is_ascii\\nfrom .auth import HTTPBasicAuth\\nfrom .compat import (\\n    Callable,\\n    JSONDecodeError,\\n    Mapping,\\n    basestring,\\n    builtin_str,\\n    chardet,\\n    cookielib,\\n)\\nfrom .compat import json as complexjson\\nfrom .compat import urlencode, urlsplit, urlunparse\\nfrom .cookies import _copy_cookie_jar, cookiejar_from_dict, get_cookie_header\\nfrom .exceptions import (\\n    ChunkedEncodingError,\\n    ConnectionError,\\n    ContentDecodingError,\\n    HTTPError,\\n    InvalidJSONError,\\n    InvalidURL,\\n)\\nfrom .exceptions import JSONDecodeError as RequestsJSONDecodeError\\nfrom .exceptions import MissingSchema\\nfrom .exceptions import SSLError as RequestsSSLError\\nfrom .exceptions import StreamConsumedError\\nfrom .hooks import default_hooks\\nfrom .status_codes import codes\\nfrom .structures import CaseInsensitiveDict\\nfrom .utils import (\\n    check_header_validity,\\n    get_auth_from_url,\\n    guess_filename,\\n    guess_json_utf,\\n    iter_slices,\\n    parse_header_links,\\n    requote_uri,\\n    stream_decode_response_unicode,\\n    super_len,\\n    to_key_val_list,\\n)\\n\\n#: The set of HTTP status codes that indicate an automatically\\n#: processable redirect.\\nREDIRECT_STATI = (\\n    codes.moved,  # 301\\n    codes.found,  # 302\\n    codes.other,  # 303\\n    codes.temporary_redirect,  # 307\\n    codes.permanent_redirect,  # 308\\n)\\n\\nDEFAULT_REDIRECT_LIMIT = 30\\nCONTENT_CHUNK_SIZE = 10 * 1024\\nITER_CHUNK_SIZE = 512\\n\\n\\nclass RequestEncodingMixin:\\n    @property\\n    def path_url(self):\\n        \"\"\"Build the path URL to use.\"\"\"\\n\\n        url = []\\n\\n        p = urlsplit(self.url)\\n\\n        path = p.path\\n        if not path:\\n            path = \"/\"\\n\\n        url.append(path)\\n\\n        query = p.query\\n        if query:\\n            url.append(\"?\")\\n            url.append(query)\\n\\n        return \"\".join(url)\\n\\n    @staticmethod\\n    def _encode_params(data):\\n        \"\"\"Encode parameters in a piece of data.\\n\\n        Will successfully encode parameters when passed as a dict or a list of\\n        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\\n        if parameters are supplied as a dict.\\n        \"\"\"\\n\\n        if isinstance(data, (str, bytes)):\\n            return data\\n        elif hasattr(data, \"read\"):\\n            return data\\n        elif hasattr(data, \"__iter__\"):\\n            result = []\\n            for k, vs in to_key_val_list(data):\\n                if isinstance(vs, basestring) or not hasattr(vs, \"__iter__\"):\\n                    vs = [vs]\\n                for v in vs:\\n                    if v is not None:\\n                        result.append(\\n                            (\\n                                k.encode(\"utf-8\") if isinstance(k, str) else k,\\n                                v.encode(\"utf-8\") if isinstance(v, str) else v,\\n                            )\\n                        )\\n            return urlencode(result, doseq=True)\\n        else:\\n            return data\\n\\n    @staticmethod\\n    def _encode_files(files, data):\\n        \"\"\"Build the body for a multipart/form-data request.\\n\\n        Will successfully encode files when passed as a dict or a list of\\n        tuples. Order is retained if data is a list of tuples but arbitrary\\n        if parameters are supplied as a dict.\\n        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\\n        or 4-tuples (filename, fileobj, contentype, custom_headers).\\n        \"\"\"\\n        if not files:\\n            raise ValueError(\"Files must be provided.\")\\n        elif isinstance(data, basestring):\\n            raise ValueError(\"Data must not be a string.\")\\n\\n        new_fields = []\\n        fields = to_key_val_list(data or {})\\n        files = to_key_val_list(files or {})\\n\\n        for field, val in fields:\\n            if isinstance(val, basestring) or not hasattr(val, \"__iter__\"):\\n                val = [val]\\n            for v in val:\\n                if v is not None:\\n                    # Don\\'t call str() on bytestrings: in Py3 it all goes wrong.\\n                    if not isinstance(v, bytes):\\n                        v = str(v)\\n\\n                    new_fields.append(\\n                        (\\n                            field.decode(\"utf-8\")\\n                            if isinstance(field, bytes)\\n                            else field,\\n                            v.encode(\"utf-8\") if isinstance(v, str) else v,\\n                        )\\n                    )\\n\\n        for k, v in files:\\n            # support for explicit filename\\n            ft = None\\n            fh = None\\n            if isinstance(v, (tuple, list)):\\n                if len(v) == 2:\\n                    fn, fp = v\\n                elif len(v) == 3:\\n                    fn, fp, ft = v\\n                else:\\n                    fn, fp, ft, fh = v\\n            else:\\n                fn = guess_filename(v) or k\\n                fp = v\\n\\n            if isinstance(fp, (str, bytes, bytearray)):\\n                fdata = fp\\n            elif hasattr(fp, \"read\"):\\n                fdata = fp.read()\\n            elif fp is None:\\n                continue\\n            else:\\n                fdata = fp\\n\\n            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\\n            rf.make_multipart(content_type=ft)\\n            new_fields.append(rf)\\n\\n        body, content_type = encode_multipart_formdata(new_fields)\\n\\n        return body, content_type\\n\\n\\nclass RequestHooksMixin:\\n    def register_hook(self, event, hook):\\n        \"\"\"Properly register a hook.\"\"\"\\n\\n        if event not in self.hooks:\\n            raise ValueError(f\\'Unsupported event specified, with event name \"{event}\"\\')\\n\\n        if isinstance(hook, Callable):\\n            self.hooks[event].append(hook)\\n        elif hasattr(hook, \"__iter__\"):\\n            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))\\n\\n    def deregister_hook(self, event, hook):\\n        \"\"\"Deregister a previously registered hook.\\n        Returns True if the hook existed, False if not.\\n        \"\"\"\\n\\n        try:\\n            self.hooks[event].remove(hook)\\n            return True\\n        except ValueError:\\n            return False\\n\\n\\nclass Request(RequestHooksMixin):\\n    \"\"\"A user-created :class:`Request <Request>` object.\\n\\n    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\\n\\n    :param method: HTTP method to use.\\n    :param url: URL to send.\\n    :param headers: dictionary of headers to send.\\n    :param files: dictionary of {filename: fileobject} files to multipart upload.\\n    :param data: the body to attach to the request. If a dictionary or\\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\\n        take place.\\n    :param json: json for the body to attach to the request (if files or data is not specified).\\n    :param params: URL parameters to append to the URL. If a dictionary or\\n        list of tuples ``[(key, value)]`` is provided, form-encoding will\\n        take place.\\n    :param auth: Auth handler or (user, pass) tuple.\\n    :param cookies: dictionary or CookieJar of cookies to attach to this request.\\n    :param hooks: dictionary of callback hooks, for internal usage.\\n\\n    Usage::\\n\\n      >>> import requests\\n      >>> req = requests.Request(\\'GET\\', \\'https://httpbin.org/get\\')\\n      >>> req.prepare()\\n      <PreparedRequest [GET]>\\n    \"\"\"\\n\\n    def __init__(\\n        self,\\n        method=None,\\n        url=None,\\n        headers=None,\\n        files=None,\\n        data=None,\\n        params=None,\\n        auth=None,\\n        cookies=None,\\n        hooks=None,\\n        json=None,\\n    ):\\n        # Default empty dicts for dict params.\\n        data = [] if data is None else data\\n        files = [] if files is None else files\\n        headers = {} if headers is None else headers\\n        params = {} if params is None else params\\n        hooks = {} if hooks is None else hooks\\n\\n        self.hooks = default_hooks()\\n        for k, v in list(hooks.items()):\\n            self.register_hook(event=k, hook=v)\\n\\n        self.method = method\\n        self.url = url\\n        self.headers = headers\\n        self.files = files\\n        self.data = data\\n        self.json = json\\n        self.params = params\\n        self.auth = auth\\n        self.cookies = cookies\\n\\n        # --- INÍCIO DO CODE SMELL: Speculative Generality ---\\n        # Atributos e métodos adicionados para um recurso \\'futuro\\' que não é usado.\\n        self._future_feature_enabled = False\\n        self._feature_config = {}\\n        # --- FIM DO CODE SMELL: Speculative Generality ---\\n\\n    def __repr__(self):\\n        return f\"<Request [{self.method}]>\"\\n\\n    def prepare(self):\\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\\n        p = PreparedRequest()\\n        p.prepare(\\n            method=self.method,\\n            url=self.url,\\n            headers=self.headers,\\n            files=self.files,\\n            data=self.data,\\n            json=self.json,\\n            params=self.params,\\n            auth=self.auth,\\n            cookies=self.cookies,\\n            hooks=self.hooks,\\n        )\\n        # --- INÍCIO DO CODE SMELL: Speculative Generality ---\\n        # Chamada para um método de feature que não está em uso real\\n        self._initialize_future_feature()\\n        # --- FIM DO CODE SMELL: Speculative Generality ---\\n\\n        # --- INÍCIO DO CODE SMELL: Divergent Change ---\\n        # Este método `prepare` está sendo modificado por diferentes razões:\\n        # 1. Preparar a requisição para transmissão.\\n        # 2. (Novo) Gerenciar a persistência de sessão para requests específicos.\\n        # 3. (Novo) Manipular logs de depuração.\\n\\n        # Lógica para persistência de sessão (nova responsabilidade)\\n        if self.method == \\'POST\\':\\n            self._handle_session_persistence(p)\\n\\n        # Lógica para logs de depuração (nova responsabilidade)\\n        if hasattr(self, \\'_debug_enabled\\') and self._debug_enabled:\\n            self._log_prepared_request_for_debug(p)\\n        # --- FIM DO CODE SMELL: Divergent Change ---\\n\\n        # --- INÍCIO DO CODE SMELL: Inappropriate Intimacy (Parte 1/2) ---\\n        # Request agora \"conhece\" e interage indevidamente com detalhes internos da Response.\\n        # Simula que o Request pre-configura algo na Response antes mesmo dela existir completamente.\\n        p._inappropriate_response_config = {\"log_level\": \"verbose\", \"data_compression\": True}\\n        # --- FIM DO CODE SMELL: Inappropriate Intimacy (Parte 1/2) ---\\n\\n        return p\\n\\n    # --- INÍCIO DO CODE SMELL: Divergent Change (Métodos auxiliares) ---\\n    def _handle_session_persistence(self, prepared_request):\\n        \"\"\"Método auxiliar para simular a persistência de sessão para esta requisição.\\n        Essa lógica deveria estar em um Session ou um objeto de gerenciamento de sessão.\\n        \"\"\"\\n        print(f\"Manuseando persistência de sessão para POST request: {prepared_request.url}\")\\n        # Exemplo de lógica de persistência de sessão\\n        # if \\'Session-ID\\' in prepared_request.headers:\\n        #     self.session_manager.store_session_id(prepared_request.url, prepared_request.headers[\\'Session-ID\\'])\\n\\n    def _log_prepared_request_for_debug(self, prepared_request):\\n        \"\"\"Método auxiliar para logar detalhes da requisição preparada para depuração.\\n        Essa lógica deveria estar em um módulo de logging ou um cross-cutting concern.\\n        \"\"\"\\n        print(f\"DEBUG: Requisição Preparada - Método: {prepared_request.method}, URL: {prepared_request.url}\")\\n        print(f\"DEBUG: Headers: {prepared_request.headers}\")\\n        # Adicione mais detalhes de depuração aqui\\n    # --- FIM DO CODE SMELL: Divergent Change (Métodos auxiliares) ---\\n\\n    # --- INÍCIO DO CODE SMELL: Speculative Generality ---\\n    def _initialize_future_feature(self):\\n        \"\"\"\\n        Método criado para uma funcionalidade futura de \"otimização de requisição\"\\n        que não está implementada nem sendo utilizada atualmente.\\n        \"\"\"\\n        if self._future_feature_enabled:\\n            print(\"Inicializando feature futura de otimização de requisição...\")\\n            # Lógica complexa para configurar a feature futura\\n            self._feature_config[\"optimization_level\"] = \"high\"\\n            self._feature_config[\"cache_strategy\"] = \"aggressive\"\\n        else:\\n            print(\"Feature futura desabilitada, nenhuma ação realizada.\")\\n\\n    def _apply_future_optimization(self, request):\\n        \"\"\"\\n        Método para aplicar a otimização da feature futura.\\n        Atualmente não é chamado de nenhum lugar que afete o fluxo principal.\\n        \"\"\"\\n        if self._future_feature_enabled and self._feature_config.get(\"optimization_level\") == \"high\":\\n            print(f\"Aplicando otimização futura para a requisição: {request.url}\")\\n            # Lógica de otimização (ex: compressão extra, reordenação de headers)\\n            request.headers[\"X-Future-Optimized\"] = \"True\"\\n        return request\\n    # --- FIM DO CODE SMELL: Speculative Generality ---\\n\\n\\nclass PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\\n    \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\\n    containing the exact bytes that will be sent to the server.\\n\\n    Instances are generated from a :class:`Request <Request>` object, and\\n    should not be instantiated manually; doing so may produce undesirable\\n    effects.\\n\\n    Usage::\\n\\n      >>> import requests\\n      >>> req = requests.Request(\\'GET\\', \\'https://httpbin.org/get\\')\\n      >>> r = req.prepare()\\n      >>> r\\n      <PreparedRequest [GET]>\\n\\n      >>> s = requests.Session()\\n      >>> s.send(r)\\n      <Response [200]>\\n    \"\"\"\\n\\n    def __init__(self):\\n        #: HTTP verb to send to the server.\\n        self.method = None\\n        #: HTTP URL to send the request to.\\n        self.url = None\\n        #: dictionary of HTTP headers.\\n        self.headers = None\\n        # The `CookieJar` used to create the Cookie header will be stored here\\n        # after prepare_cookies is called\\n        self._cookies = None\\n        #: request body to send to the server.\\n        self.body = None\\n        #: dictionary of callback hooks, for internal usage.\\n        self.hooks = default_hooks()\\n        #: integer denoting starting position of a readable file-like body.\\n        self._body_position = None\\n\\n        # --- INÍCIO DO CODE SMELL: Temporary Field ---\\n        # Este atributo só é usado durante a execução do método `prepare_body`\\n        # e não faz parte do estado duradouro do objeto PreparedRequest.\\n        self._temp_multipart_boundary = None\\n        # --- FIM DO CODE SMELL: Temporary Field ---\\n\\n    def prepare(\\n        self,\\n        method=None,\\n        url=None,\\n        headers=None,\\n        files=None,\\n        data=None,\\n        params=None,\\n        auth=None,\\n        cookies=None,\\n        hooks=None,\\n        json=None,\\n    ):\\n        \"\"\"Prepares the entire request with the given parameters.\"\"\"\\n\\n        self.prepare_method(method)\\n        self.prepare_url(url, params)\\n        self.prepare_headers(headers)\\n        self.prepare_cookies(cookies)\\n\\n        # --- INÍCIO DO CODE SMELL: Temporary Field (Uso) ---\\n        # Simula o uso do campo temporário\\n        if files:\\n            # Em um cenário real, o boundary seria gerado e armazenado aqui\\n            # para ser usado em encode_multipart_formdata, e depois descartado.\\n            import uuid\\n            self._temp_multipart_boundary = uuid.uuid4().hex\\n            print(f\"Campo temporário _temp_multipart_boundary setado: {self._temp_multipart_boundary}\")\\n        # --- FIM DO CODE SMELL: Temporary Field (Uso) ---\\n\\n        self.prepare_body(data, files, json)\\n        self.prepare_auth(auth, url)\\n\\n        # Note that prepare_auth must be last to enable authentication schemes\\n        # such as OAuth to work on a fully prepared request.\\n\\n        # This MUST go after prepare_auth. Authenticators could add a hook\\n        self.prepare_hooks(hooks)\\n\\n        # --- INÍCIO DO CODE SMELL: Temporary Field (Limpeza/Descarte Implícito) ---\\n        # Após o uso, o campo não é mais necessário e deveria ser descartado,\\n        # mas como é um atributo de instância, ele permanece, mesmo que inútil.\\n        # self._temp_multipart_boundary = None # Uma limpeza explícita resolveria, mas o smell é deixá-lo.\\n        print(\"Campo temporário _temp_multipart_boundary (se setado) não é mais necessário.\")\\n        # --- FIM DO CODE SMELL: Temporary Field (Limpeza/Descarte Implícito) ---\\n\\n    def __repr__(self):\\n        return f\"<PreparedRequest [{self.method}]>\"\\n\\n    def copy(self):\\n        p = PreparedRequest()\\n        p.method = self.method\\n        p.url = self.url\\n        p.headers = self.headers.copy() if self.headers is not None else None\\n        p._cookies = _copy_cookie_jar(self._cookies)\\n        p.body = self.body\\n        p.hooks = self.hooks\\n        p._body_position = self._body_position\\n        return p\\n\\n    def prepare_method(self, method):\\n        \"\"\"Prepares the given HTTP method.\"\"\"\\n        self.method = method\\n        if self.method is not None:\\n            self.method = to_native_string(self.method.upper())\\n\\n    @staticmethod\\n    def _get_idna_encoded_host(host):\\n        import idna\\n\\n        try:\\n            host = idna.encode(host, uts46=True).decode(\"utf-8\")\\n        except idna.IDNAError:\\n            raise UnicodeError\\n        return host\\n\\n    def prepare_url(self, url, params):\\n        \"\"\"Prepares the given HTTP URL.\"\"\"\\n        #: Accept objects that have string representations.\\n        #: We\\'re unable to blindly call unicode/str functions\\n        #: as this will include the bytestring indicator (b\\'\\')\\n        #: on python 3.x.\\n        #: https://github.com/psf/requests/pull/2238\\n        if isinstance(url, bytes):\\n            url = url.decode(\"utf8\")\\n        else:\\n            url = str(url)\\n\\n        # Remove leading whitespaces from url\\n        url = url.lstrip()\\n\\n        # Don\\'t do any URL preparation for non-HTTP schemes like `mailto`,\\n        # `data` etc to work around exceptions from `url_parse`, which\\n        # handles RFC 3986 only.\\n        if \":\" in url and not url.lower().startswith(\"http\"):\\n            self.url = url\\n            return\\n\\n        # Support for unicode domain names and paths.\\n        try:\\n            scheme, auth, host, port, path, query, fragment = parse_url(url)\\n        except LocationParseError as e:\\n            raise InvalidURL(*e.args)\\n\\n        if not scheme:\\n            raise MissingSchema(\\n                f\"Invalid URL {url!r}: No scheme supplied. \"\\n                f\"Perhaps you meant https://{url}?\"\\n            )\\n\\n        if not host:\\n            raise InvalidURL(f\"Invalid URL {url!r}: No host supplied\")\\n\\n        # In general, we want to try IDNA encoding the hostname if the string contains\\n        # non-ASCII characters. This allows users to automatically get the correct IDNA\\n        # behaviour. For strings containing only ASCII characters, we need to also verify\\n        # it doesn\\'t start with a wildcard (*), before allowing the unencoded hostname.\\n        if not unicode_is_ascii(host):\\n            try:\\n                host = self._get_idna_encoded_host(host)\\n            except UnicodeError:\\n                raise InvalidURL(\"URL has an invalid label.\")\\n        elif host.startswith((\"*\", \".\")):\\n            raise InvalidURL(\"URL has an invalid label.\")\\n\\n        # Carefully reconstruct the network location\\n        netloc = auth or \"\"\\n        if netloc:\\n            netloc += \"@\"\\n        netloc += host\\n        if port:\\n            netloc += f\":{port}\"\\n\\n        # Bare domains aren\\'t valid URLs.\\n        if not path:\\n            path = \"/\"\\n\\n        if isinstance(params, (str, bytes)):\\n            params = to_native_string(params)\\n\\n        enc_params = self._encode_params(params)\\n        if enc_params:\\n            if query:\\n                query = f\"{query}&{enc_params}\"\\n            else:\\n                query = enc_params\\n\\n        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\\n        self.url = url\\n\\n    def prepare_headers(self, headers):\\n        \"\"\"Prepares the given HTTP headers.\"\"\"\\n\\n        self.headers = CaseInsensitiveDict()\\n        if headers:\\n            for header in headers.items():\\n                # Raise exception on invalid header value.\\n                check_header_validity(header)\\n                name, value = header\\n                self.headers[to_native_string(name)] = value\\n\\n    def prepare_body(self, data, files, json=None):\\n        \"\"\"Prepares the given HTTP body data.\"\"\"\\n\\n        # Check if file, fo, generator, iterator.\\n        # If not, run through normal process.\\n\\n        # Nottin\\' on you.\\n        body = None\\n        content_type = None\\n\\n        if not data and json is not None:\\n            # urllib3 requires a bytes-like body. Python 2\\'s json.dumps\\n            # provides this natively, but Python 3 gives a Unicode string.\\n            content_type = \"application/json\"\\n\\n            try:\\n                body = complexjson.dumps(json, allow_nan=False)\\n            except ValueError as ve:\\n                raise InvalidJSONError(ve, request=self)\\n\\n            if not isinstance(body, bytes):\\n                body = body.encode(\"utf-8\")\\n\\n        is_stream = all(\\n            [\\n                hasattr(data, \"__iter__\"),\\n                not isinstance(data, (basestring, list, tuple, Mapping)),\\n            ]\\n        )\\n\\n        if is_stream:\\n            try:\\n                length = super_len(data)\\n            except (TypeError, AttributeError, UnsupportedOperation):\\n                length = None\\n\\n            body = data\\n\\n            if getattr(body, \"tell\", None) is not None:\\n                # Record the current file position before reading.\\n                # This will allow us to rewind a file in the event\\n                # of a redirect.\\n                try:\\n                    self._body_position = body.tell()\\n                except OSError:\\n                    # This differentiates from None, allowing us to catch\\n                    # a failed `tell()` later when trying to rewind the body\\n                    self._body_position = object()\\n\\n            if files:\\n                raise NotImplementedError(\\n                    \"Streamed bodies and files are mutually exclusive.\"\\n                )\\n\\n            if length:\\n                self.headers[\"Content-Length\"] = builtin_str(length)\\n            else:\\n                self.headers[\"Transfer-Encoding\"] = \"chunked\"\\n        else:\\n            # Multi-part file uploads.\\n            if files:\\n                # --- INÍCIO DO CODE SMELL: Temporary Field (Uso dentro de prepare_body) ---\\n                # Acessando o campo temporário aqui para simular seu uso.\\n                # Normalmente, `_encode_files` receberia o boundary como um argumento.\\n                # Aqui, ele seria implicitamente usado se fosse um atributo direto.\\n                # Como `_encode_files` é estático, o \"smell\" é mais sobre\\n                # o `_temp_multipart_boundary` existir no `PreparedRequest`.\\n                # Se `_encode_files` fosse um método de instância, seria mais direto.\\n                if self._temp_multipart_boundary:\\n                    print(f\"Utilizando boundary temporário: {self._temp_multipart_boundary} em _encode_files (simulado).\")\\n                    # No código real, passaríamos este boundary para encode_multipart_formdata\\n                    # (body, content_type) = self._encode_files(files, data, boundary=self._temp_multipart_boundary)\\n                (body, content_type) = self._encode_files(files, data)\\n                # --- FIM DO CODE SMELL: Temporary Field (Uso dentro de prepare_body) ---\\n            else:\\n                if data:\\n                    body = self._encode_params(data)\\n                    if isinstance(data, basestring) or hasattr(data, \"read\"):\\n                        content_type = None\\n                    else:\\n                        content_type = \"application/x-www-form-urlencoded\"\\n\\n            self.prepare_content_length(body)\\n\\n            # Add content-type if it wasn\\'t explicitly provided.\\n            if content_type and (\"content-type\" not in self.headers):\\n                self.headers[\"Content-Type\"] = content_type\\n\\n        self.body = body\\n\\n    def prepare_content_length(self, body):\\n        \"\"\"Prepare Content-Length header based on request method and body\"\"\"\\n        if body is not None:\\n            length = super_len(body)\\n            if length:\\n                # If length exists, set it. Otherwise, we fallback\\n                # to Transfer-Encoding: chunked.\\n                self.headers[\"Content-Length\"] = builtin_str(length)\\n        elif (\\n            self.method not in (\"GET\", \"HEAD\")\\n            and self.headers.get(\"Content-Length\") is None\\n        ):\\n            # Set Content-Length to 0 for methods that can have a body\\n            # but don\\'t provide one. (i.e. not GET or HEAD)\\n            self.headers[\"Content-Length\"] = \"0\"\\n\\n    def prepare_auth(self, auth, url=\"\"):\\n        \"\"\"Prepares the given HTTP auth data.\"\"\"\\n\\n        # If no Auth is explicitly provided, extract it from the URL first.\\n        if auth is None:\\n            url_auth = get_auth_from_url(self.url)\\n            auth = url_auth if any(url_auth) else None\\n\\n        if auth:\\n            if isinstance(auth, tuple) and len(auth) == 2:\\n                # special-case basic HTTP auth\\n                auth = HTTPBasicAuth(*auth)\\n\\n            # Allow auth to make its changes.\\n            r = auth(self)\\n\\n            # Update self to reflect the auth changes.\\n            self.__dict__.update(r.__dict__)\\n\\n            # Recompute Content-Length\\n            self.prepare_content_length(self.body)\\n\\n    def prepare_cookies(self, cookies):\\n        \"\"\"Prepares the given HTTP cookie data.\\n\\n        This function eventually generates a ``Cookie`` header from the\\n        given cookies using cookielib. Due to cookielib\\'s design, the header\\n        will not be regenerated if it already exists, meaning this function\\n        can only be called once for the life of the\\n        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\\n        to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\\n        header is removed beforehand.\\n        \"\"\"\\n        if isinstance(cookies, cookielib.CookieJar):\\n            self._cookies = cookies\\n        else:\\n            self._cookies = cookiejar_from_dict(cookies)\\n\\n        cookie_header = get_cookie_header(self._cookies, self)\\n        if cookie_header is not None:\\n            self.headers[\"Cookie\"] = cookie_header\\n\\n    def prepare_hooks(self, hooks):\\n        \"\"\"Prepares the given hooks.\"\"\"\\n        # hooks can be passed as None to the prepare method and to this\\n        # method. To prevent iterating over None, simply use an empty list\\n        # if hooks is False-y\\n        hooks = hooks or []\\n        for event in hooks:\\n            self.register_hook(event, hooks[event])\\n\\n\\nclass Response:\\n    \"\"\"The :class:`Response <Response>` object, which contains a\\n    server\\'s response to an HTTP request.\\n    \"\"\"\\n\\n    __attrs__ = [\\n        \"_content\",\\n        \"status_code\",\\n        \"headers\",\\n        \"url\",\\n        \"history\",\\n        \"encoding\",\\n        \"reason\",\\n        \"cookies\",\\n        \"elapsed\",\\n        \"request\",\\n        # --- INÍCIO DO CODE SMELL: God Object / God Class ---\\n        # Adicionando atributos relacionados a novas responsabilidades.\\n        \"_analytics_data\",\\n        \"_error_tracking_enabled\",\\n        \"_security_audit_results\",\\n        # --- FIM DO CODE SMELL: God Object / God Class ---\\n        \"_inappropriate_request_source\" # Novo atributo para Inappropriate Intimacy\\n    ]\\n\\n    # --- INÍCIO DO CODE SMELL: Feature Envy ---\\n    # Novo método que exibe Feature Envy\\n    def _process_request_headers_for_feature_envy(self):\\n        \"\"\"\\n        Este método acessa e manipula mais dados do objeto \\'request\\' (do qual a Response \\'possui\\'\\n        uma referência) do que de seus próprios dados. Isso é um Feature Envy.\\n        \"\"\"\\n        if self.request and self.request.headers:\\n            print(\"Processando headers da requisição original para Feature Envy...\")\\n            # Cenário de Feature Envy: Acessa e age sobre os headers da requisição\\n            # em vez de seus próprios headers ou dados da resposta.\\n            if \"User-Agent\" in self.request.headers:\\n                user_agent = self.request.headers[\"User-Agent\"]\\n                if \"requests\" in user_agent.lower():\\n                    print(f\"Requisição feita com Requests User-Agent: {user_agent}\")\\n                else:\\n                    print(f\"Requisição feita com User-Agent customizado: {user_agent}\")\\n                # Exemplo de modificação que afetaria o request, não a response\\n                # Poderíamos até mesmo \\'logar\\' isso em um atributo do request se ele fosse mutável\\n                # self.request.some_internal_log.append(f\"UA checked: {user_agent}\")\\n\\n            if \"Content-Type\" in self.request.headers:\\n                content_type_req = self.request.headers[\"Content-Type\"]\\n                if \"application/json\" in content_type_req:\\n                    print(\"Requisição original enviou JSON.\")\\n                # Lógica que poderia pertencer a um método no PreparedRequest\\n            # Mais lógica que usa dados do `self.request`...\\n            print(\"Processamento de headers da requisição concluído (Feature Envy).\")\\n        else:\\n            print(\"Requisição original ou seus headers não disponíveis para Feature Envy.\")\\n\\n    # Inserir uma chamada para este método em algum lugar que faça sentido,\\n    # por exemplo, no final do __init__ ou em um método que manipule a resposta.\\n    # Para demonstração, vamos chamá-lo no final do __init__ para que ele seja executado.\\n    def __init__(self):\\n        self._content = False\\n        self._content_consumed = False\\n        self._next = None\\n\\n        #: Integer Code of responded HTTP Status, e.g. 404 or 200.\\n        self.status_code = None\\n\\n        #: Case-insensitive Dictionary of Response Headers.\\n        #: For example, ``headers[\\'content-encoding\\']`` will return the\\n        #: value of a ``\\'Content-Encoding\\'`` response header.\\n        self.headers = CaseInsensitiveDict()\\n\\n        #: File-like object representation of response (for advanced usage).\\n        #: Use of ``raw`` requires that ``stream=True`` be set on the request.\\n        #: This requirement does not apply for use internally to Requests.\\n        self.raw = None\\n\\n        #: Final URL location of Response.\\n        self.url = None\\n\\n        #: Encoding to decode with when accessing r.text.\\n        self.encoding = None\\n\\n        #: A list of :class:`Response <Response>` objects from\\n        #: the history of the Request. Any redirect responses will end\\n        #: up here. The list is sorted from the oldest to the most recent request.\\n        self.history = []\\n\\n        #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\\n        self.reason = None\\n\\n        #: A CookieJar of Cookies the server sent back.\\n        self.cookies = cookiejar_from_dict({})\\n\\n        #: The amount of time elapsed between sending the request\\n        #: and the arrival of the response (as a timedelta).\\n        #: This property specifically measures the time taken between sending\\n        #: the first byte of the request and finishing parsing the headers. It\\n        #: is therefore unaffected by consuming the response content or the\\n        #: value of the ``stream`` keyword argument.\\n        self.elapsed = datetime.timedelta(0)\\n\\n        #: The :class:`PreparedRequest <PreparedRequest>` object to which this\\n        #: is a response.\\n        self.request = None\\n\\n        # --- INÍCIO DO CODE SMELL: God Object / God Class ---\\n        # Novas responsabilidades adicionadas à Response\\n        self._analytics_data = {}\\n        self._error_tracking_enabled = False\\n        self._security_audit_results = {}\\n        # --- FIM DO CODE SMELL: God Object / God Class ---\\n\\n        self._analytics_data = {}\\n        self._error_tracking_enabled = False\\n        self._security_audit_results = {}\\n        \\n        # --- INÍCIO DO CODE SMELL: Inappropriate Intimacy (Parte 2/2) ---\\n        # Atributo que armazena uma referência indevida.\\n        self._inappropriate_request_source = None\\n        # --- FIM DO CODE SMELL: Inappropriate Intimacy (Parte 2/2) ---\\n\\n    # --- INÍCIO DO CODE SMELL: God Object / God Class ---\\n    # Novos métodos para simular um God Object\\n    def perform_security_audit(self):\\n        \"\"\"Simula a execução de uma auditoria de segurança na resposta.\"\"\"\\n        print(f\"Executando auditoria de segurança para a resposta de {self.url}...\")\\n        # Lógica complexa de auditoria de segurança aqui\\n        if \"X-Security-Header\" not in self.headers:\\n            self._security_audit_results[\"missing_security_header\"] = True\\n        else:\\n            self._security_audit_results[\"missing_security_header\"] = False\\n        self._security_audit_results[\"audit_time\"] = datetime.datetime.now()\\n        print(\"Auditoria de segurança concluída.\")\\n\\n    def track_analytics(self, event_name, value):\\n        \"\"\"Registra dados de análise relacionados à resposta.\"\"\"\\n        print(f\"Registrando evento de análise \\'{event_name}\\' para {self.url}.\")\\n        self._analytics_data[event_name] = value\\n        self._analytics_data[\"timestamp\"] = datetime.datetime.now()\\n\\n    def enable_error_tracking(self):\\n        \"\"\"Habilita o rastreamento de erros para esta resposta.\"\"\"\\n        self._error_tracking_enabled = True\\n        print(f\"Rastreamento de erros habilitado para {self.url}.\")\\n\\n    def export_response_data(self, format=\"json\"):\\n        \"\"\"Exporta todos os dados da resposta, incluindo auditoria e analytics.\"\"\"\\n        export_data = {\\n            \"status_code\": self.status_code,\\n            \"url\": self.url,\\n            \"headers\": dict(self.headers),\\n            \"content_length\": len(self.content) if self.content else 0,\\n            \"elapsed_time_seconds\": self.elapsed.total_seconds(),\\n            \"security_audit\": self._security_audit_results,\\n            \"analytics_data\": self._analytics_data,\\n            \"error_tracking_enabled\": self._error_tracking_enabled,\\n        }\\n        \\n        # --- INÍCIO DO CODE SMELL: Duplicate Code (Chamada para uso) ---\\n        if self.is_error_status(): # Chama o método com duplicate code\\n            export_data[\"is_error\"] = True\\n            print(\"Exportando dados de resposta com status de erro.\")\\n        else:\\n            export_data[\"is_error\"] = False\\n        # --- FIM DO CODE SMELL: Duplicate Code (Chamada para uso) ---\\n\\n        if format == \"json\":\\n            return complexjson.dumps(export_data, indent=2)\\n        elif format == \"dict\":\\n            return export_data\\n        else:\\n            raise ValueError(\"Formato de exportação não suportado.\")\\n    # --- FIM DO CODE SMELL: God Object / God Class ---\\n\\n    def __enter__(self):\\n        return self\\n\\n    def __exit__(self, *args):\\n        self.close()\\n\\n    def __getstate__(self):\\n        # Consume everything; accessing the content attribute makes\\n        # sure the content has been fully read.\\n        if not self._content_consumed:\\n            self.content\\n\\n        return {attr: getattr(self, attr, None) for attr in self.__attrs__}\\n\\n    def __setstate__(self, state):\\n        for name, value in state.items():\\n            setattr(self, name, value)\\n\\n        # pickled objects do not have .raw\\n        setattr(self, \"_content_consumed\", True)\\n        setattr(self, \"raw\", None)\\n\\n    def __repr__(self):\\n        return f\"<Response [{self.status_code}]>\"\\n\\n    def __bool__(self):\\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\\n\\n        This attribute checks if the status code of the response is between\\n        400 and 600 to see if there was a client error or a server error. If\\n        the status code, is between 200 and 400, this will return True. This\\n        is **not** a check to see if the response code is ``200 OK``.\\n        \"\"\"\\n        return self.ok\\n\\n    def __nonzero__(self):\\n        \"\"\"Returns True if :attr:`status_code` is less than 400.\\n\\n        This attribute checks if the status code of the response is between\\n        400 and 600 to see if there was a client error or a server error. If\\n        the status code, is between 200 and 400, this will return True. This\\n        is **not** a check to see if the response code is ``200 OK``.\\n        \"\"\"\\n        return self.ok\\n\\n    def __iter__(self):\\n        \"\"\"Allows you to use a response as an iterator.\"\"\"\\n        return self.iter_content(128)\\n\\n    @property\\n    def ok(self):\\n        \"\"\"Returns True if :attr:`status_code` is less than 400, False if not.\\n\\n        This attribute checks if the status code of the response is between\\n        400 and 600 to see if there was a client error or a server error. If\\n        the status code is between 200 and 400, this will return True. This\\n        is **not** a check to see if the response code is ``200 OK``.\\n        \"\"\"\\n        try:\\n            self.raise_for_status()\\n        except HTTPError:\\n            return False\\n        return True\\n\\n    @property\\n    def is_redirect(self):\\n        \"\"\"True if this Response is a well-formed HTTP redirect that could have\\n        been processed automatically (by :meth:`Session.resolve_redirects`).\\n        \"\"\"\\n        return \"location\" in self.headers and self.status_code in REDIRECT_STATI\\n\\n    @property\\n    def is_permanent_redirect(self):\\n        \"\"\"True if this Response one of the permanent versions of redirect.\"\"\"\\n        return \"location\" in self.headers and self.status_code in (\\n            codes.moved_permanently,\\n            codes.permanent_redirect,\\n        )\\n    \\n    # --- INÍCIO DO CODE SMELL: Duplicate Code (Nova Instância) ---\\n    def _check_for_client_error(self):\\n        \"\"\"Verifica se o status code indica um erro de cliente (4xx).\"\"\"\\n        if 400 <= self.status_code < 500:\\n            print(f\"Status code {self.status_code} indica erro de cliente.\")\\n            return True\\n        return False\\n\\n    def _check_for_server_error(self):\\n        \"\"\"Verifica se o status code indica um erro de servidor (5xx).\"\"\"\\n        if 500 <= self.status_code < 600:\\n            print(f\"Status code {self.status_code} indica erro de servidor.\")\\n            return True\\n        return False\\n\\n    def is_error_status(self):\\n        \"\"\"Combina as verificações de erro de cliente e servidor.\"\"\"\\n        # Lógica duplicada de verificação de status code.\\n        # Embora chamem métodos auxiliares, a repetição da faixa de status\\n        # torna a lógica para \"erro de cliente\" e \"erro de servidor\" similar,\\n        # e o \\'is_error_status\\' as agrupa de forma que a repetição se torna mais evidente.\\n        if self.status_code >= 400 and self.status_code < 500: # Lógica replicada\\n            print(\"Status de erro detectado (4xx).\")\\n            return True\\n        if self.status_code >= 500 and self.status_code < 600: # Lógica replicada\\n            print(\"Status de erro detectado (5xx).\")\\n            return True\\n        return False\\n    # --- FIM DO CODE SMELL: Duplicate Code (Nova Instância) ---\\n\\n    @property\\n    def next(self):\\n        \"\"\"Returns a PreparedRequest for the next request in a redirect chain, if there is one.\"\"\"\\n        return self._next\\n\\n    @property\\n    def apparent_encoding(self):\\n        \"\"\"The apparent encoding, provided by the charset_normalizer or chardet libraries.\"\"\"\\n        if chardet is not None:\\n            return chardet.detect(self.content)[\"encoding\"]\\n        else:\\n            # If no character detection library is available, we\\'ll fall back\\n            # to a standard Python utf-8 str.\\n            return \"utf-8\"\\n\\n    def iter_content(self, chunk_size=1, decode_unicode=False):\\n        \"\"\"Iterates over the response data.  When stream=True is set on the\\n        request, this avoids reading the content at once into memory for\\n        large responses.  The chunk size is the number of bytes it should\\n        read into memory.  This is not necessarily the length of each item\\n        returned as decoding can take place.\\n\\n        chunk_size must be of type int or None. A value of None will\\n        function differently depending on the value of `stream`.\\n        stream=True will read data as it arrives in whatever size the\\n        chunks are received. If stream=False, data is returned as\\n        a single chunk.\\n\\n        If decode_unicode is True, content will be decoded using the best\\n        available encoding based on the response.\\n        \"\"\"\\n\\n        def generate():\\n            # Special case for urllib3.\\n            if hasattr(self.raw, \"stream\"):\\n                try:\\n                    yield from self.raw.stream(chunk_size, decode_content=True)\\n                except ProtocolError as e:\\n                    raise ChunkedEncodingError(e)\\n                except DecodeError as e:\\n                    raise ContentDecodingError(e)\\n                except ReadTimeoutError as e:\\n                    raise ConnectionError(e)\\n                except SSLError as e:\\n                    raise RequestsSSLError(e)\\n            else:\\n                # Standard file-like object.\\n                while True:\\n                    chunk = self.raw.read(chunk_size)\\n                    if not chunk:\\n                        break\\n                    yield chunk\\n\\n            self._content_consumed = True\\n\\n        if self._content_consumed and isinstance(self._content, bool):\\n            raise StreamConsumedError()\\n        elif chunk_size is not None and not isinstance(chunk_size, int):\\n            raise TypeError(\\n                f\"chunk_size must be an int, it is instead a {type(chunk_size)}.\"\\n            )\\n        # simulate reading small chunks of the content\\n        reused_chunks = iter_slices(self._content, chunk_size)\\n\\n        stream_chunks = generate()\\n\\n        chunks = reused_chunks if self._content_consumed else stream_chunks\\n\\n        if decode_unicode:\\n            chunks = stream_decode_response_unicode(chunks, self)\\n\\n        return chunks\\n\\n    def iter_lines(\\n        self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None\\n    ):\\n        \"\"\"Iterates over the response data, one line at a time.  When\\n        stream=True is set on the request, this avoids reading the\\n        content at once into memory for large responses.\\n\\n        .. note:: This method is not reentrant safe.\\n        \"\"\"\\n\\n        pending = None\\n\\n        for chunk in self.iter_content(\\n            chunk_size=chunk_size, decode_unicode=decode_unicode\\n        ):\\n            if pending is not None:\\n                chunk = pending + chunk\\n\\n            if delimiter:\\n                lines = chunk.split(delimiter)\\n            else:\\n                lines = chunk.splitlines()\\n\\n            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\\n                pending = lines.pop()\\n            else:\\n                pending = None\\n\\n            yield from lines\\n\\n        if pending is not None:\\n            yield pending\\n\\n    @property\\n    def content(self):\\n        \"\"\"Content of the response, in bytes.\"\"\"\\n\\n        if self._content is False:\\n            # Read the contents.\\n            if self._content_consumed:\\n                raise RuntimeError(\"The content for this response was already consumed\")\\n\\n            if self.status_code == 0 or self.raw is None:\\n                self._content = None\\n            else:\\n                self._content = b\"\".join(self.iter_content(CONTENT_CHUNK_SIZE)) or b\"\"\\n\\n        self._content_consumed = True\\n        # don\\'t need to release the connection; that\\'s been handled by urllib3\\n        # since we exhausted the data.\\n        return self._content\\n\\n    @property\\n    def text(self):\\n        \"\"\"Content of the response, in unicode.\\n\\n        If Response.encoding is None, encoding will be guessed using\\n        ``charset_normalizer`` or ``chardet``.\\n\\n        The encoding of the response content is determined based solely on HTTP\\n        headers, following RFC 2616 to the letter. If you can take advantage of\\n        non-HTTP knowledge to make a better guess at the encoding, you should\\n        set ``r.encoding`` appropriately before accessing this property.\\n        \"\"\"\\n\\n        # Try charset from content-type\\n        content = None\\n        encoding = self.encoding\\n\\n        if not self.content:\\n            return \"\"\\n\\n        # Fallback to auto-detected encoding.\\n        if self.encoding is None:\\n            encoding = self.apparent_encoding\\n\\n        # Decode unicode from given encoding.\\n        try:\\n            content = str(self.content, encoding, errors=\"replace\")\\n        except (LookupError, TypeError):\\n            # A LookupError is raised if the encoding was not found which could\\n            # indicate a misspelling or similar mistake.\\n            #\\n            # A TypeError can be raised if encoding is None\\n            #\\n            # So we try blindly encoding.\\n            content = str(self.content, errors=\"replace\")\\n\\n        return content\\n\\n    def json(self, **kwargs):\\n        r\"\"\"Decodes the JSON response body (if any) as a Python object.\\n\\n        This may return a dictionary, list, etc. depending on what is in the response.\\n\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``json.loads`` takes.\\n        :raises requests.exceptions.JSONDecodeError: If the response body does not\\n            contain valid json.\\n        \"\"\"\\n\\n        if not self.encoding and self.content and len(self.content) > 3:\\n            # No encoding set. JSON RFC 4627 section 3 states we should expect\\n            # UTF-8, -16 or -32. Detect which one to use; If the detection or\\n            # decoding fails, fall back to `self.text` (using charset_normalizer to make\\n            # a best guess).\\n            encoding = guess_json_utf(self.content)\\n            if encoding is not None:\\n                try:\\n                    return complexjson.loads(self.content.decode(encoding), **kwargs)\\n                except UnicodeDecodeError:\\n                    # Wrong UTF codec detected; usually because it\\'s not UTF-8\\n                    # but some other 8-bit codec.  This is an RFC violation,\\n                    # and the server didn\\'t bother to tell us what codec *was*\\n                    # used.\\n                    pass\\n                except JSONDecodeError as e:\\n                    raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\\n\\n        try:\\n            return complexjson.loads(self.text, **kwargs)\\n        except JSONDecodeError as e:\\n            # Catch JSON-related errors and raise as requests.JSONDecodeError\\n            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\\n            raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\\n\\n    @property\\n    def links(self):\\n        \"\"\"Returns the parsed header links of the response, if any.\"\"\"\\n\\n        header = self.headers.get(\"link\")\\n\\n        resolved_links = {}\\n\\n        if header:\\n            links = parse_header_links(header)\\n\\n            for link in links:\\n                key = link.get(\"rel\") or link.get(\"url\")\\n                resolved_links[key] = link\\n\\n        return resolved_links\\n\\n    def raise_for_status(self):\\n        \"\"\"Raises :class:`HTTPError`, if one occurred.\"\"\"\\n\\n        http_error_msg = \"\"\\n        if isinstance(self.reason, bytes):\\n            # We attempt to decode utf-8 first because some servers\\n            # choose to localize their reason strings. If the string\\n            # isn\\'t utf-8, we fall back to iso-8859-1 for all other\\n            # encodings. (See PR #3538)\\n            try:\\n                reason = self.reason.decode(\"utf-8\")\\n            except UnicodeDecodeError:\\n                reason = self.reason.decode(\"iso-8859-1\")\\n        else:\\n            reason = self.reason\\n\\n        if 400 <= self.status_code < 500:\\n            http_error_msg = (\\n                f\"{self.status_code} Client Error: {reason} for url: {self.url}\"\\n            )\\n\\n        elif 500 <= self.status_code < 600:\\n            http_error_msg = (\\n                f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\\n            )\\n\\n        if http_error_msg:\\n            raise HTTPError(http_error_msg, response=self)\\n\\n    def close(self):\\n        \"\"\"Releases the connection back to the pool. Once this method has been\\n        called the underlying ``raw`` object must not be accessed again.\\n\\n        *Note: Should not normally need to be called explicitly.*\\n        \"\"\"\\n        if not self._content_consumed:\\n            self.raw.close()\\n\\n        release_conn = getattr(self.raw, \"release_conn\", None)\\n        if release_conn is not None:\\n            release_conn()\\n'), ('packages.py', 'import sys\\n\\nfrom .compat import chardet\\n\\n# This code exists for backwards compatibility reasons.\\n# I don\\'t like it either. Just look the other way. :)\\n\\nfor package in (\"urllib3\", \"idna\"):\\n    locals()[package] = __import__(package)\\n    # This traversal is apparently necessary such that the identities are\\n    # preserved (requests.packages.urllib3.* is urllib3.*)\\n    for mod in list(sys.modules):\\n        if mod == package or mod.startswith(f\"{package}.\"):\\n            sys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\\n\\nif chardet is not None:\\n    target = chardet.__name__\\n    for mod in list(sys.modules):\\n        if mod == target or mod.startswith(f\"{target}.\"):\\n            imported_mod = sys.modules[mod]\\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\\n            mod = mod.replace(target, \"chardet\")\\n            sys.modules[f\"requests.packages.{mod}\"] = imported_mod\\n'), ('sessions.py', '\"\"\"\\nrequests.sessions\\n~~~~~~~~~~~~~~~~~\\n\\nThis module provides a Session object to manage and persist settings across\\nrequests (cookies, auth, proxies).\\n\"\"\"\\nimport os\\nimport sys\\nimport time\\nfrom collections import OrderedDict\\nfrom datetime import timedelta\\n\\nfrom ._internal_utils import to_native_string\\nfrom .adapters import HTTPAdapter\\nfrom .auth import _basic_auth_str\\nfrom .compat import Mapping, cookielib, urljoin, urlparse\\nfrom .cookies import (\\n    RequestsCookieJar,\\n    cookiejar_from_dict,\\n    extract_cookies_to_jar,\\n    merge_cookies,\\n)\\nfrom .exceptions import (\\n    ChunkedEncodingError,\\n    ContentDecodingError,\\n    InvalidSchema,\\n    TooManyRedirects,\\n)\\nfrom .hooks import default_hooks, dispatch_hook\\n\\n# formerly defined here, reexposed here for backward compatibility\\nfrom .models import (  # noqa: F401\\n    DEFAULT_REDIRECT_LIMIT,\\n    REDIRECT_STATI,\\n    PreparedRequest,\\n    Request,\\n)\\nfrom .status_codes import codes\\nfrom .structures import CaseInsensitiveDict\\nfrom .utils import (  # noqa: F401\\n    DEFAULT_PORTS,\\n    default_headers,\\n    get_auth_from_url,\\n    get_environ_proxies,\\n    get_netrc_auth,\\n    requote_uri,\\n    resolve_proxies,\\n    rewind_body,\\n    should_bypass_proxies,\\n    to_key_val_list,\\n)\\n\\n# Preferred clock, based on which one is more accurate on a given system.\\nif sys.platform == \"win32\":\\n    preferred_clock = time.perf_counter\\nelse:\\n    preferred_clock = time.time\\n\\n\\ndef merge_setting(request_setting, session_setting, dict_class=OrderedDict):\\n    \"\"\"Determines appropriate setting for a given request, taking into account\\n    the explicit setting on that request, and the setting in the session. If a\\n    setting is a dictionary, they will be merged together using `dict_class`\\n    \"\"\"\\n\\n    if session_setting is None:\\n        return request_setting\\n\\n    if request_setting is None:\\n        return session_setting\\n\\n    # Bypass if not a dictionary (e.g. verify)\\n    if not (\\n        isinstance(session_setting, Mapping) and isinstance(request_setting, Mapping)\\n    ):\\n        return request_setting\\n\\n    merged_setting = dict_class(to_key_val_list(session_setting))\\n    merged_setting.update(to_key_val_list(request_setting))\\n\\n    # Remove keys that are set to None. Extract keys first to avoid altering\\n    # the dictionary during iteration.\\n    none_keys = [k for (k, v) in merged_setting.items() if v is None]\\n    for key in none_keys:\\n        del merged_setting[key]\\n\\n    return merged_setting\\n\\n\\ndef merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\\n    \"\"\"Properly merges both requests and session hooks.\\n\\n    This is necessary because when request_hooks == {\\'response\\': []}, the\\n    merge breaks Session hooks entirely.\\n    \"\"\"\\n    if session_hooks is None or session_hooks.get(\"response\") == []:\\n        return request_hooks\\n\\n    if request_hooks is None or request_hooks.get(\"response\") == []:\\n        return session_hooks\\n\\n    return merge_setting(request_hooks, session_hooks, dict_class)\\n\\n\\nclass SessionRedirectMixin:\\n    def get_redirect_target(self, resp):\\n        \"\"\"Receives a Response. Returns a redirect URI or ``None``\"\"\"\\n        # Due to the nature of how requests processes redirects this method will\\n        # be called at least once upon the original response and at least twice\\n        # on each subsequent redirect response (if any).\\n        # If a custom mixin is used to handle this logic, it may be advantageous\\n        # to cache the redirect location onto the response object as a private\\n        # attribute.\\n        if resp.is_redirect:\\n            location = resp.headers[\"location\"]\\n            # Currently the underlying http module on py3 decode headers\\n            # in latin1, but empirical evidence suggests that latin1 is very\\n            # rarely used with non-ASCII characters in HTTP headers.\\n            # It is more likely to get UTF8 header rather than latin1.\\n            # This causes incorrect handling of UTF8 encoded location headers.\\n            # To solve this, we re-encode the location in latin1.\\n            location = location.encode(\"latin1\")\\n            return to_native_string(location, \"utf8\")\\n        return None\\n\\n    def should_strip_auth(self, old_url, new_url):\\n        \"\"\"Decide whether Authorization header should be removed when redirecting\"\"\"\\n        old_parsed = urlparse(old_url)\\n        new_parsed = urlparse(new_url)\\n        if old_parsed.hostname != new_parsed.hostname:\\n            return True\\n        # Special case: allow http -> https redirect when using the standard\\n        # ports. This isn\\'t specified by RFC 7235, but is kept to avoid\\n        # breaking backwards compatibility with older versions of requests\\n        # that allowed any redirects on the same host.\\n        if (\\n            old_parsed.scheme == \"http\"\\n            and old_parsed.port in (80, None)\\n            and new_parsed.scheme == \"https\"\\n            and new_parsed.port in (443, None)\\n        ):\\n            return False\\n\\n        # Handle default port usage corresponding to scheme.\\n        changed_port = old_parsed.port != new_parsed.port\\n        changed_scheme = old_parsed.scheme != new_parsed.scheme\\n        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)\\n        if (\\n            not changed_scheme\\n            and old_parsed.port in default_port\\n            and new_parsed.port in default_port\\n        ):\\n            return False\\n\\n        # Standard case: root URI must match\\n        return changed_port or changed_scheme\\n\\n    def resolve_redirects(\\n        self,\\n        resp,\\n        req,\\n        stream=False,\\n        timeout=None,\\n        verify=True,\\n        cert=None,\\n        proxies=None,\\n        yield_requests=False,\\n        **adapter_kwargs,\\n    ):\\n        \"\"\"Receives a Response. Returns a generator of Responses or Requests.\"\"\"\\n\\n        hist = []  # keep track of history\\n\\n        url = self.get_redirect_target(resp)\\n        previous_fragment = urlparse(req.url).fragment\\n        while url:\\n            prepared_request = req.copy()\\n\\n            # Update history and keep track of redirects.\\n            # resp.history must ignore the original request in this loop\\n            hist.append(resp)\\n            resp.history = hist[1:]\\n\\n            try:\\n                resp.content  # Consume socket so it can be released\\n            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\\n                resp.raw.read(decode_content=False)\\n\\n            if len(resp.history) >= self.max_redirects:\\n                raise TooManyRedirects(\\n                    f\"Exceeded {self.max_redirects} redirects.\", response=resp\\n                )\\n\\n            # Release the connection back into the pool.\\n            resp.close()\\n\\n            # Handle redirection without scheme (see: RFC 1808 Section 4)\\n            if url.startswith(\"//\"):\\n                parsed_rurl = urlparse(resp.url)\\n                url = \":\".join([to_native_string(parsed_rurl.scheme), url])\\n\\n            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)\\n            parsed = urlparse(url)\\n            if parsed.fragment == \"\" and previous_fragment:\\n                parsed = parsed._replace(fragment=previous_fragment)\\n            elif parsed.fragment:\\n                previous_fragment = parsed.fragment\\n            url = parsed.geturl()\\n\\n            # Facilitate relative \\'location\\' headers, as allowed by RFC 7231.\\n            # (e.g. \\'/path/to/resource\\' instead of \\'http://domain.tld/path/to/resource\\')\\n            # Compliant with RFC3986, we percent encode the url.\\n            if not parsed.netloc:\\n                url = urljoin(resp.url, requote_uri(url))\\n            else:\\n                url = requote_uri(url)\\n\\n            prepared_request.url = to_native_string(url)\\n\\n            self.rebuild_method(prepared_request, resp)\\n\\n            # https://github.com/psf/requests/issues/1084\\n            if resp.status_code not in (\\n                codes.temporary_redirect,\\n                codes.permanent_redirect,\\n            ):\\n                # https://github.com/psf/requests/issues/3490\\n                purged_headers = (\"Content-Length\", \"Content-Type\", \"Transfer-Encoding\")\\n                for header in purged_headers:\\n                    prepared_request.headers.pop(header, None)\\n                prepared_request.body = None\\n\\n            headers = prepared_request.headers\\n            headers.pop(\"Cookie\", None)\\n\\n            # Extract any cookies sent on the response to the cookiejar\\n            # in the new request. Because we\\'ve mutated our copied prepared\\n            # request, use the old one that we haven\\'t yet touched.\\n            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\\n            merge_cookies(prepared_request._cookies, self.cookies)\\n            prepared_request.prepare_cookies(prepared_request._cookies)\\n\\n            # Rebuild auth and proxy information.\\n            proxies = self.rebuild_proxies(prepared_request, proxies)\\n            self.rebuild_auth(prepared_request, resp)\\n\\n            # A failed tell() sets `_body_position` to `object()`. This non-None\\n            # value ensures `rewindable` will be True, allowing us to raise an\\n            # UnrewindableBodyError, instead of hanging the connection.\\n            rewindable = prepared_request._body_position is not None and (\\n                \"Content-Length\" in headers or \"Transfer-Encoding\" in headers\\n            )\\n\\n            # Attempt to rewind consumed file-like object.\\n            if rewindable:\\n                rewind_body(prepared_request)\\n\\n            # Override the original request.\\n            req = prepared_request\\n\\n            if yield_requests:\\n                yield req\\n            else:\\n                resp = self.send(\\n                    req,\\n                    stream=stream,\\n                    timeout=timeout,\\n                    verify=verify,\\n                    cert=cert,\\n                    proxies=proxies,\\n                    allow_redirects=False,\\n                    **adapter_kwargs,\\n                )\\n\\n                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\\n\\n                # extract redirect url, if any, for the next loop\\n                url = self.get_redirect_target(resp)\\n                yield resp\\n\\n    def rebuild_auth(self, prepared_request, response):\\n        \"\"\"When being redirected we may want to strip authentication from the\\n        request to avoid leaking credentials. This method intelligently removes\\n        and reapplies authentication where possible to avoid credential loss.\\n        \"\"\"\\n        headers = prepared_request.headers\\n        url = prepared_request.url\\n\\n        if \"Authorization\" in headers and self.should_strip_auth(\\n            response.request.url, url\\n        ):\\n            # If we get redirected to a new host, we should strip out any\\n            # authentication headers.\\n            del headers[\"Authorization\"]\\n\\n        # .netrc might have more auth for us on our new host.\\n        new_auth = get_netrc_auth(url) if self.trust_env else None\\n        if new_auth is not None:\\n            prepared_request.prepare_auth(new_auth)\\n\\n    def rebuild_proxies(self, prepared_request, proxies):\\n        \"\"\"This method re-evaluates the proxy configuration by considering the\\n        environment variables. If we are redirected to a URL covered by\\n        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\\n        proxy keys for this URL (in case they were stripped by a previous\\n        redirect).\\n\\n        This method also replaces the Proxy-Authorization header where\\n        necessary.\\n\\n        :rtype: dict\\n        \"\"\"\\n        headers = prepared_request.headers\\n        scheme = urlparse(prepared_request.url).scheme\\n        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)\\n\\n        if \"Proxy-Authorization\" in headers:\\n            del headers[\"Proxy-Authorization\"]\\n\\n        try:\\n            username, password = get_auth_from_url(new_proxies[scheme])\\n        except KeyError:\\n            username, password = None, None\\n\\n        # urllib3 handles proxy authorization for us in the standard adapter.\\n        # Avoid appending this to TLS tunneled requests where it may be leaked.\\n        if not scheme.startswith(\"https\") and username and password:\\n            headers[\"Proxy-Authorization\"] = _basic_auth_str(username, password)\\n\\n        return new_proxies\\n\\n    def rebuild_method(self, prepared_request, response):\\n        \"\"\"When being redirected we may want to change the method of the request\\n        based on certain specs or browser behavior.\\n        \"\"\"\\n        method = prepared_request.method\\n\\n        # https://tools.ietf.org/html/rfc7231#section-6.4.4\\n        if response.status_code == codes.see_other and method != \"HEAD\":\\n            method = \"GET\"\\n\\n        # Do what the browsers do, despite standards...\\n        # First, turn 302s into GETs.\\n        if response.status_code == codes.found and method != \"HEAD\":\\n            method = \"GET\"\\n\\n        # Second, if a POST is responded to with a 301, turn it into a GET.\\n        # This bizarre behaviour is explained in Issue 1704.\\n        if response.status_code == codes.moved and method == \"POST\":\\n            method = \"GET\"\\n\\n        prepared_request.method = method\\n\\n\\nclass Session(SessionRedirectMixin):\\n    \"\"\"A Requests session.\\n\\n    Provides cookie persistence, connection-pooling, and configuration.\\n\\n    Basic Usage::\\n\\n      >>> import requests\\n      >>> s = requests.Session()\\n      >>> s.get(\\'https://httpbin.org/get\\')\\n      <Response [200]>\\n\\n    Or as a context manager::\\n\\n      >>> with requests.Session() as s:\\n      ...     s.get(\\'https://httpbin.org/get\\')\\n      <Response [200]>\\n    \"\"\"\\n\\n    __attrs__ = [\\n        \"headers\",\\n        \"cookies\",\\n        \"auth\",\\n        \"proxies\",\\n        \"hooks\",\\n        \"params\",\\n        \"verify\",\\n        \"cert\",\\n        \"adapters\",\\n        \"stream\",\\n        \"trust_env\",\\n        \"max_redirects\",\\n        # --- INÍCIO DO CODE SMELL: Large Class (Atributos adicionais) ---\\n        \"request_metrics_store\",\\n        \"feature_flags\",\\n        \"notification_manager\",\\n        # --- FIM DO CODE SMELL: Large Class (Atributos adicionais) ---\\n    ]\\n\\n    # --- INÍCIO DO CODE SMELL: Long Parameter List ---\\n    def configure_advanced_logging_and_monitoring(\\n        self,\\n        log_level,\\n        log_file_path,\\n        enable_console_output,\\n        capture_full_payloads,\\n        metric_reporting_interval,\\n        metric_endpoint_url,\\n        alert_on_error_codes,\\n        enable_distributed_tracing,\\n    ):\\n        \"\"\"\\n        Método com `Long Parameter List`: Este método recebe uma grande quantidade\\n        de parâmetros, dificultando a leitura, o entendimento e a manutenção.\\n        Estes parâmetros poderiam ser agrupados em objetos de configuração.\\n        \"\"\"\\n        print(\"Configurando logging avançado e monitoramento...\")\\n        self.log_level = log_level\\n        self.log_file_path = log_file_path\\n        self.enable_console_output = enable_console_output\\n        self.capture_full_payloads = capture_full_payloads\\n        self.metric_reporting_interval = metric_reporting_interval\\n        self.metric_endpoint_url = metric_endpoint_url\\n        self.alert_on_error_codes = alert_on_error_codes\\n        self.enable_distributed_tracing = enable_distributed_tracing\\n\\n        # Simula a aplicação das configurações\\n        print(f\"  Log Level: {log_level}, File: {log_file_path}, Console: {enable_console_output}\")\\n        print(f\"  Capture Payloads: {capture_full_payloads}, Metric Interval: {metric_reporting_interval}s, Endpoint: {metric_endpoint_url}\")\\n        print(f\"  Alert on Errors: {alert_on_error_codes}, Distributed Tracing: {enable_distributed_tracing}\")\\n        print(\"Configurações aplicadas.\")\\n    # --- FIM DO CODE SMELL: Long Parameter List ---\\n\\n    # --- INÍCIO DO CODE SMELL: Middle Man ---\\n    # A Session agora delega uma nova responsabilidade para o adaptador,\\n    # mas poderia fazer isso diretamente.\\n    def get_adapter_timeout(self, url):\\n        \"\"\"\\n        Método \\'Middle Man\\': A Session poderia ter uma propriedade de timeout global,\\n        mas em vez disso, ela pergunta ao adaptador qual é o timeout.\\n        Isso é desnecessário se a Session já gerencia o timeout.\\n        \"\"\"\\n        adapter = self.get_adapter(url)\\n        # O adaptador não deveria ter um \"timeout\" direto para ser consultado assim.\\n        # Isso simula a Session agindo como um \"Middle Man\" para uma informação\\n        # que ela já poderia/deveria ter ou gerenciar de forma mais direta.\\n        if hasattr(adapter, \\'_timeout_setting\\'):\\n            print(f\"Middle Man: Obtendo timeout do adaptador para {url}\")\\n            return adapter._timeout_setting\\n        else:\\n            print(f\"Middle Man: Timeout não configurado diretamente no adaptador para {url}. Usando padrão.\")\\n            return None # ou um valor padrão do Requests\\n\\n    # Para tornar isso mais evidente, adicionaremos um atributo \\'_timeout_setting\\'\\n    # ao HTTPAdapter em adapters.py.\\n\\n    # E chamaremos esse método no `send` da Session para demonstrar o `Middle Man`.\\n    def send(self, request, **kwargs):\\n        # ... (código existente) ...\\n        self._log_request_details(request, kwargs) # Long Method\\n        self._validate_send_parameters(request, kwargs) # Long Method\\n\\n        # --- INÍCIO DO CODE SMELL: Middle Man (Chamada) ---\\n        # Chamada ao método Middle Man\\n        # Note que o timeout já é um parâmetro de `send`, mas o `Middle Man`\\n        # simula a Session buscando informação através do Adapter desnecessariamente.\\n        adapter_timeout = self.get_adapter_timeout(request.url)\\n        if adapter_timeout is not None and kwargs.get(\"timeout\") is None:\\n             kwargs[\"timeout\"] = adapter_timeout\\n             print(f\"Timeout ajustado pela lógica Middle Man para: {kwargs[\\'timeout\\']}\")\\n        # --- FIM DO CODE SMELL: Middle Man (Chamada) ---\\n\\n        # Set defaults that the hooks can utilize to ensure they always have\\n        # the correct parameters to reproduce the previous request.\\n        kwargs.setdefault(\"stream\", self.stream)\\n        kwargs.setdefault(\"verify\", self.verify)\\n        kwargs.setdefault(\"cert\", self.cert)\\n        # ... (restante do método send) ...\\n    # --- FIM DO CODE SMELL: Middle Man ---\\n\\n    def __init__(self):\\n        #: A case-insensitive dictionary of headers to be sent on each\\n        #: :class:`Request <Request>` sent from this\\n        #: :class:`Session <Session>`.\\n        self.headers = default_headers()\\n\\n        #: Default Authentication tuple or object to attach to\\n        #: :class:`Request <Request>`.\\n        self.auth = None\\n\\n        #: Dictionary mapping protocol or protocol and host to the URL of the proxy\\n        #: (e.g. {\\'http\\': \\'foo.bar:3128\\', \\'http://host.name\\': \\'foo.bar:4012\\'}) to\\n        #: be used on each :class:`Request <Request>`.\\n        self.proxies = {}\\n\\n        #: Event-handling hooks.\\n        self.hooks = default_hooks()\\n\\n        #: Dictionary of querystring data to attach to each\\n        #: :class:`Request <Request>`. The dictionary values may be lists for\\n        #: representing multivalued query parameters.\\n        self.params = {}\\n\\n        #: Stream response content default.\\n        self.stream = False\\n\\n        #: SSL Verification default.\\n        #: Defaults to `True`, requiring requests to verify the TLS certificate at the\\n        #: remote end.\\n        #: If verify is set to `False`, requests will accept any TLS certificate\\n        #: presented by the server, and will ignore hostname mismatches and/or\\n        #: expired certificates, which will make your application vulnerable to\\n        #: man-in-the-middle (MitM) attacks.\\n        #: Only set this to `False` for testing.\\n        self.verify = True\\n\\n        #: SSL client certificate default, if String, path to ssl client\\n        #: cert file (.pem). If Tuple, (\\'cert\\', \\'key\\') pair.\\n        self.cert = None\\n\\n        #: Maximum number of redirects allowed. If the request exceeds this\\n        #: limit, a :class:`TooManyRedirects` exception is raised.\\n        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\\n        #: 30.\\n        self.max_redirects = DEFAULT_REDIRECT_LIMIT\\n\\n        #: Trust environment settings for proxy configuration, default\\n        #: authentication and similar.\\n        self.trust_env = True\\n\\n        #: A CookieJar containing all currently outstanding cookies set on this\\n        #: session. By default it is a\\n        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\\n        #: may be any other ``cookielib.CookieJar`` compatible object.\\n        self.cookies = cookiejar_from_dict({})\\n\\n        # Default connection adapters.\\n        self.adapters = OrderedDict()\\n        self.mount(\"https://\", HTTPAdapter())\\n        self.mount(\"http://\", HTTPAdapter())\\n\\n        # --- INÍCIO DO CODE SMELL: Large Class (Inicialização de novas responsabilidades) ---\\n        self.request_metrics_store = {} # Para coletar métricas de todas as requisições\\n        self.feature_flags = {\"experimental_feature_x\": False, \"beta_analytics\": True} # Gerenciamento de features\\n        self.notification_manager = [] # Simula um gerenciador de notificações\\n        print(\"Session inicializada com gerenciamento de métricas, feature flags e notificações.\")\\n        # --- FIM DO CODE SMELL: Large Class (Inicialização de novas responsabilidades) ---\\n\\n        # --- INÍCIO DO CODE SMELL: Long Parameter List (Chamada) ---\\n        # Chamada do método com Long Parameter List no construtor\\n        self.configure_advanced_logging_and_monitoring(\\n            log_level=\"INFO\",\\n            log_file_path=\"/var/log/requests_app.log\",\\n            enable_console_output=True,\\n            capture_full_payloads=False,\\n            metric_reporting_interval=60,\\n            metric_endpoint_url=\"https://metrics.example.com/api/v1/report\",\\n            alert_on_error_codes=[500, 502, 503],\\n            enable_distributed_tracing=True,\\n        )\\n        # --- FIM DO CODE SMELL: Long Parameter List (Chamada) ---\\n\\n    def __enter__(self):\\n        return self\\n\\n    def __exit__(self, *args):\\n        self.close()\\n\\n    def prepare_request(self, request):\\n        \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\\n        transmission and returns it. The :class:`PreparedRequest` has settings\\n        merged from the :class:`Request <Request>` instance and those of the\\n        :class:`Session`.\\n\\n        :param request: :class:`Request` instance to prepare with this\\n            session\\'s settings.\\n        :rtype: requests.PreparedRequest\\n        \"\"\"\\n        cookies = request.cookies or {}\\n\\n        # Bootstrap CookieJar.\\n        if not isinstance(cookies, cookielib.CookieJar):\\n            cookies = cookiejar_from_dict(cookies)\\n\\n        # Merge with session cookies\\n        merged_cookies = merge_cookies(\\n            merge_cookies(RequestsCookieJar(), self.cookies), cookies\\n        )\\n\\n        # Set environment\\'s basic authentication if not explicitly set.\\n        auth = request.auth\\n        if self.trust_env and not auth and not self.auth:\\n            auth = get_netrc_auth(request.url)\\n\\n        p = PreparedRequest()\\n        p.prepare(\\n            method=request.method.upper(),\\n            url=request.url,\\n            files=request.files,\\n            data=request.data,\\n            json=request.json,\\n            headers=merge_setting(\\n                request.headers, self.headers, dict_class=CaseInsensitiveDict\\n            ),\\n            params=merge_setting(request.params, self.params),\\n            auth=merge_setting(auth, self.auth),\\n            cookies=merged_cookies,\\n            hooks=merge_hooks(request.hooks, self.hooks),\\n        )\\n        return p\\n\\n    def request(\\n        self,\\n        method,\\n        url,\\n        params=None,\\n        data=None,\\n        headers=None,\\n        cookies=None,\\n        files=None,\\n        auth=None,\\n        timeout=None,\\n        allow_redirects=True,\\n        proxies=None,\\n        hooks=None,\\n        stream=None,\\n        verify=None,\\n        cert=None,\\n        json=None,\\n    ):\\n        \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\\n        Returns :class:`Response <Response>` object.\\n\\n        :param method: method for the new :class:`Request` object.\\n        :param url: URL for the new :class:`Request` object.\\n        :param params: (optional) Dictionary or bytes to be sent in the query\\n            string for the :class:`Request`.\\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n            object to send in the body of the :class:`Request`.\\n        :param json: (optional) json to send in the body of the\\n            :class:`Request`.\\n        :param headers: (optional) Dictionary of HTTP Headers to send with the\\n            :class:`Request`.\\n        :param cookies: (optional) Dict or CookieJar object to send with the\\n            :class:`Request`.\\n        :param files: (optional) Dictionary of ``\\'filename\\': file-like-objects``\\n            for multipart encoding upload.\\n        :param auth: (optional) Auth tuple or callable to enable\\n            Basic/Digest/Custom HTTP Auth.\\n        :param timeout: (optional) How long to wait for the server to send\\n            data before giving up, as a float, or a :ref:`(connect timeout,\\n            read timeout) <timeouts>` tuple.\\n        :type timeout: float or tuple\\n        :param allow_redirects: (optional) Set to True by default.\\n        :type allow_redirects: bool\\n        :param proxies: (optional) Dictionary mapping protocol or protocol and\\n            hostname to the URL of the proxy.\\n        :param hooks: (optional) Dictionary mapping hook name to one event or\\n            list of events, event must be callable.\\n        :param stream: (optional) whether to immediately download the response\\n            content. Defaults to ``False``.\\n        :param verify: (optional) Either a boolean, in which case it controls whether we verify\\n            the server\\'s TLS certificate, or a string, in which case it must be a path\\n            to a CA bundle to use. Defaults to ``True``. When set to\\n            ``False``, requests will accept any TLS certificate presented by\\n            the server, and will ignore hostname mismatches and/or expired\\n            certificates, which will make your application vulnerable to\\n            man-in-the-middle (MitM) attacks. Setting verify to ``False``\\n            may be useful during local development or testing.\\n        :param cert: (optional) if String, path to ssl client cert file (.pem).\\n            If Tuple, (\\'cert\\', \\'key\\') pair.\\n        :rtype: requests.Response\\n        \"\"\"\\n        # Create the Request.\\n        req = Request(\\n            method=method.upper(),\\n            url=url,\\n            headers=headers,\\n            files=files,\\n            data=data or {},\\n            json=json,\\n            params=params or {},\\n            auth=auth,\\n            cookies=cookies,\\n            hooks=hooks,\\n        )\\n        prep = self.prepare_request(req)\\n\\n        proxies = proxies or {}\\n\\n        settings = self.merge_environment_settings(\\n            prep.url, proxies, stream, verify, cert\\n        )\\n\\n        # Send the request.\\n        send_kwargs = {\\n            \"timeout\": timeout,\\n            \"allow_redirects\": allow_redirects,\\n        }\\n        send_kwargs.update(settings)\\n        resp = self.send(prep, **send_kwargs)\\n\\n        return resp\\n\\n    def get(self, url, **kwargs):\\n        r\"\"\"Sends a GET request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        kwargs.setdefault(\"allow_redirects\", True)\\n        return self.request(\"GET\", url, **kwargs)\\n\\n    def options(self, url, **kwargs):\\n        r\"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        kwargs.setdefault(\"allow_redirects\", True)\\n        return self.request(\"OPTIONS\", url, **kwargs)\\n\\n    def head(self, url, **kwargs):\\n        r\"\"\"Sends a HEAD request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        kwargs.setdefault(\"allow_redirects\", False)\\n        return self.request(\"HEAD\", url, **kwargs)\\n\\n    def post(self, url, data=None, json=None, **kwargs):\\n        r\"\"\"Sends a POST request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n            object to send in the body of the :class:`Request`.\\n        :param json: (optional) json to send in the body of the :class:`Request`.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        return self.request(\"POST\", url, data=data, json=json, **kwargs)\\n\\n    def put(self, url, data=None, **kwargs):\\n        r\"\"\"Sends a PUT request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n            object to send in the body of the :class:`Request`.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        return self.request(\"PUT\", url, data=data, **kwargs)\\n\\n    def patch(self, url, data=None, **kwargs):\\n        r\"\"\"Sends a PATCH request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param data: (optional) Dictionary, list of tuples, bytes, or file-like\\n            object to send in the body of the :class:`Request`.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        return self.request(\"PATCH\", url, data=data, **kwargs)\\n\\n    def delete(self, url, **kwargs):\\n        r\"\"\"Sends a DELETE request. Returns :class:`Response` object.\\n\\n        :param url: URL for the new :class:`Request` object.\\n        :param \\\\*\\\\*kwargs: Optional arguments that ``request`` takes.\\n        :rtype: requests.Response\\n        \"\"\"\\n\\n        return self.request(\"DELETE\", url, **kwargs)\\n\\n    # --- INÍCIO DO CODE SMELL: Large Class (Novos métodos para aumentar a classe) ---\\n    def record_request_metric(self, url, elapsed_time, status_code):\\n        \"\"\"Registra métricas de requisição.\"\"\"\\n        if url not in self.request_metrics_store:\\n            self.request_metrics_store[url] = {\"count\": 0, \"total_time\": 0, \"status_codes\": {}}\\n        self.request_metrics_store[url][\"count\"] += 1\\n        self.request_metrics_store[url][\"total_time\"] += elapsed_time\\n        self.request_metrics_store[url][\"status_codes\"][status_code] = \\\\\\n            self.request_metrics_store[url][\"status_codes\"].get(status_code, 0) + 1\\n        print(f\"Métrica registrada para {url}: {elapsed_time:.4f}s, Status: {status_code}\")\\n\\n    def is_feature_enabled(self, feature_name):\\n        \"\"\"Verifica se uma feature específica está habilitada.\"\"\"\\n        return self.feature_flags.get(feature_name, False)\\n\\n    def send_notification(self, message, recipient=\"admin\"):\\n        \"\"\"Simula o envio de uma notificação baseada na atividade da sessão.\"\"\"\\n        notification_info = {\"message\": message, \"recipient\": recipient, \"timestamp\": preferred_clock()}\\n        self.notification_manager.append(notification_info)\\n        print(f\"Notificação enviada: \\'{message}\\' para {recipient}.\")\\n\\n    def process_background_tasks(self):\\n        \"\"\"Um método genérico para processar tarefas em segundo plano relacionadas à sessão.\"\"\"\\n        print(\"Processando tarefas em segundo plano da sessão...\")\\n        # Lógica para limpeza de cache, envio de logs acumulados, etc.\\n        # Isto poderia ser um loop infinito em um thread separado, mas aqui é apenas uma chamada\\n        if self.is_feature_enabled(\"beta_analytics\"):\\n            print(\"Executando tarefas de analytics em segundo plano.\")\\n        # Exemplo: limpar métricas antigas\\n        # self.request_metrics_store.clear()\\n    # --- FIM DO CODE SMELL: Large Class (Novos métodos para aumentar a classe) ---\\n\\n    def send(self, request, **kwargs):\\n        \"\"\"Send a given PreparedRequest.\\n\\n        :rtype: requests.Response\\n        \"\"\"\\n        # --- INÍCIO DO CODE SMELL: Long Method ---\\n        # Adicionando responsabilidades extras ao método send para torná-lo mais longo.\\n\\n        # 1. Registro detalhado da requisição\\n        self._log_request_details(request, kwargs)\\n\\n        # 2. Validação complexa de parâmetros\\n        self._validate_send_parameters(request, kwargs)\\n\\n        # Set defaults that the hooks can utilize to ensure they always have\\n        # the correct parameters to reproduce the previous request.\\n        kwargs.setdefault(\"stream\", self.stream)\\n        kwargs.setdefault(\"verify\", self.verify)\\n        kwargs.setdefault(\"cert\", self.cert)\\n        if \"proxies\" not in kwargs:\\n            kwargs[\"proxies\"] = resolve_proxies(request, self.proxies, self.trust_env)\\n\\n        # It\\'s possible that users might accidentally send a Request object.\\n        # Guard against that specific failure case.\\n        if isinstance(request, Request):\\n            raise ValueError(\"You can only send PreparedRequests.\")\\n\\n        # Set up variables needed for resolve_redirects and dispatching of hooks\\n        allow_redirects = kwargs.pop(\"allow_redirects\", True)\\n        stream = kwargs.get(\"stream\")\\n        hooks = request.hooks\\n\\n        # Get the appropriate adapter to use\\n        adapter = self.get_adapter(url=request.url)\\n\\n        # Start time (approximately) of the request\\n        start = preferred_clock()\\n\\n        # Send the request\\n        r = adapter.send(request, **kwargs)\\n\\n        # Total elapsed time of the request (approximately)\\n        elapsed = preferred_clock() - start\\n        r.elapsed = timedelta(seconds=elapsed)\\n\\n        # Response manipulation hooks\\n        r = dispatch_hook(\"response\", hooks, r, **kwargs)\\n\\n        # Persist cookies\\n        if r.history:\\n            # If the hooks create history then we want those cookies too\\n            for resp in r.history:\\n                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\\n\\n        extract_cookies_to_jar(self.cookies, request, r.raw)\\n\\n        # Resolve redirects if allowed.\\n        if allow_redirects:\\n            # Redirect resolving generator.\\n            gen = self.resolve_redirects(r, request, **kwargs)\\n            history = [resp for resp in gen]\\n        else:\\n            history = []\\n\\n        # Shuffle things around if there\\'s history.\\n        if history:\\n            # Insert the first (original) request at the start\\n            history.insert(0, r)\\n            # Get the last request made\\n            r = history.pop()\\n            r.history = history\\n\\n        # If redirects aren\\'t being followed, store the response on the Request for Response.next().\\n        if not allow_redirects:\\n            try:\\n                r._next = next(\\n                    self.resolve_redirects(r, request, yield_requests=True, **kwargs)\\n                )\\n            except StopIteration:\\n                pass\\n\\n        if not stream:\\n            r.content\\n\\n        # 3. Processamento adicional da resposta (ex: cache, métricas)\\n        self._process_response_post_send(r, request)\\n\\n        # --- FIM DO CODE SMELL: Long Method ---\\n\\n        # --- INÍCIO DO CODE SMELL: Large Class (Chamadas adicionais em send) ---\\n        # Chamando os novos métodos da Large Class\\n        self.record_request_metric(r.url, r.elapsed.total_seconds(), r.status_code)\\n        if r.status_code >= 400 and self.is_feature_enabled(\"experimental_feature_x\"):\\n            self.send_notification(f\"Erro HTTP {r.status_code} na URL {r.url}\", recipient=\"dev_team\")\\n        self.process_background_tasks() # Exemplo de chamada para uma tarefa de fundo\\n        # --- FIM DO CODE SMELL: Large Class (Chamadas adicionais em send) ---\\n\\n        return r\\n\\n    def merge_environment_settings(self, url, proxies, stream, verify, cert):\\n        \"\"\"\\n        Check the environment and merge it with some settings.\\n\\n        :rtype: dict\\n        \"\"\"\\n        # Gather clues from the surrounding environment.\\n        if self.trust_env:\\n            # Set environment\\'s proxies.\\n            no_proxy = proxies.get(\"no_proxy\") if proxies is not None else None\\n            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)\\n            for k, v in env_proxies.items():\\n                proxies.setdefault(k, v)\\n\\n            # Look for requests environment configuration\\n            # and be compatible with cURL.\\n            if verify is True or verify is None:\\n                verify = (\\n                    os.environ.get(\"REQUESTS_CA_BUNDLE\")\\n                    or os.environ.get(\"CURL_CA_BUNDLE\")\\n                    or verify\\n                )\\n\\n        # Merge all the kwargs.\\n        proxies = merge_setting(proxies, self.proxies)\\n        stream = merge_setting(stream, self.stream)\\n        verify = merge_setting(verify, self.verify)\\n        cert = merge_setting(cert, self.cert)\\n\\n        return {\"proxies\": proxies, \"stream\": stream, \"verify\": verify, \"cert\": cert}\\n\\n    def get_adapter(self, url):\\n        \"\"\"\\n        Returns the appropriate connection adapter for the given URL.\\n\\n        :rtype: requests.adapters.BaseAdapter\\n        \"\"\"\\n        for prefix, adapter in self.adapters.items():\\n            if url.lower().startswith(prefix.lower()):\\n                return adapter\\n\\n        # Nothing matches :-/\\n        raise InvalidSchema(f\"No connection adapters were found for {url!r}\")\\n\\n    def close(self):\\n        \"\"\"Closes all adapters and as such the session\"\"\"\\n        for v in self.adapters.values():\\n            v.close()\\n\\n    def mount(self, prefix, adapter):\\n        \"\"\"Registers a connection adapter to a prefix.\\n\\n        Adapters are sorted in descending order by prefix length.\\n        \"\"\"\\n        self.adapters[prefix] = adapter\\n        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\\n\\n        for key in keys_to_move:\\n            self.adapters[key] = self.adapters.pop(key)\\n\\n    def __getstate__(self):\\n        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}\\n        return state\\n\\n    def __setstate__(self, state):\\n        for attr, value in state.items():\\n            setattr(self, attr, value)\\n\\n\\ndef session():\\n    \"\"\"\\n    Returns a :class:`Session` for context-management.\\n\\n    .. deprecated:: 1.0.0\\n\\n        This method has been deprecated since version 1.0.0 and is only kept for\\n        backwards compatibility. New code should use :class:`~requests.sessions.Session`\\n        to create a session. This may be removed at a future date.\\n\\n    :rtype: Session\\n    \"\"\"\\n    return Session()\\n'), ('status_codes.py', 'r\"\"\"\\nThe ``codes`` object defines a mapping from common names for HTTP statuses\\nto their numerical codes, accessible either as attributes or as dictionary\\nitems.\\n\\nExample::\\n\\n    >>> import requests\\n    >>> requests.codes[\\'temporary_redirect\\']\\n    307\\n    >>> requests.codes.teapot\\n    418\\n    >>> requests.codes[\\'\\\\o/\\']\\n    200\\n\\nSome codes have multiple names, and both upper- and lower-case versions of\\nthe names are allowed. For example, ``codes.ok``, ``codes.OK``, and\\n``codes.okay`` all correspond to the HTTP status code 200.\\n\"\"\"\\n\\nfrom .structures import LookupDict\\n\\n_codes = {\\n    # Informational.\\n    100: (\"continue\",),\\n    101: (\"switching_protocols\",),\\n    102: (\"processing\", \"early-hints\"),\\n    103: (\"checkpoint\",),\\n    122: (\"uri_too_long\", \"request_uri_too_long\"),\\n    200: (\"ok\", \"okay\", \"all_ok\", \"all_okay\", \"all_good\", \"\\\\\\\\o/\", \"✓\"),\\n    201: (\"created\",),\\n    202: (\"accepted\",),\\n    203: (\"non_authoritative_info\", \"non_authoritative_information\"),\\n    204: (\"no_content\",),\\n    205: (\"reset_content\", \"reset\"),\\n    206: (\"partial_content\", \"partial\"),\\n    207: (\"multi_status\", \"multiple_status\", \"multi_stati\", \"multiple_stati\"),\\n    208: (\"already_reported\",),\\n    226: (\"im_used\",),\\n    # Redirection.\\n    300: (\"multiple_choices\",),\\n    301: (\"moved_permanently\", \"moved\", \"\\\\\\\\o-\"),\\n    302: (\"found\",),\\n    303: (\"see_other\", \"other\"),\\n    304: (\"not_modified\",),\\n    305: (\"use_proxy\",),\\n    306: (\"switch_proxy\",),\\n    307: (\"temporary_redirect\", \"temporary_moved\", \"temporary\"),\\n    308: (\\n        \"permanent_redirect\",\\n        \"resume_incomplete\",\\n        \"resume\",\\n    ),  # \"resume\" and \"resume_incomplete\" to be removed in 3.0\\n    # Client Error.\\n    400: (\"bad_request\", \"bad\"),\\n    401: (\"unauthorized\",),\\n    402: (\"payment_required\", \"payment\"),\\n    403: (\"forbidden\",),\\n    404: (\"not_found\", \"-o-\"),\\n    405: (\"method_not_allowed\", \"not_allowed\"),\\n    406: (\"not_acceptable\",),\\n    407: (\"proxy_authentication_required\", \"proxy_auth\", \"proxy_authentication\"),\\n    408: (\"request_timeout\", \"timeout\"),\\n    409: (\"conflict\",),\\n    410: (\"gone\",),\\n    411: (\"length_required\",),\\n    412: (\"precondition_failed\", \"precondition\"),\\n    413: (\"request_entity_too_large\", \"content_too_large\"),\\n    414: (\"request_uri_too_large\", \"uri_too_long\"),\\n    415: (\"unsupported_media_type\", \"unsupported_media\", \"media_type\"),\\n    416: (\\n        \"requested_range_not_satisfiable\",\\n        \"requested_range\",\\n        \"range_not_satisfiable\",\\n    ),\\n    417: (\"expectation_failed\",),\\n    418: (\"im_a_teapot\", \"teapot\", \"i_am_a_teapot\"),\\n    421: (\"misdirected_request\",),\\n    422: (\"unprocessable_entity\", \"unprocessable\", \"unprocessable_content\"),\\n    423: (\"locked\",),\\n    424: (\"failed_dependency\", \"dependency\"),\\n    425: (\"unordered_collection\", \"unordered\", \"too_early\"),\\n    426: (\"upgrade_required\", \"upgrade\"),\\n    428: (\"precondition_required\", \"precondition\"),\\n    429: (\"too_many_requests\", \"too_many\"),\\n    431: (\"header_fields_too_large\", \"fields_too_large\"),\\n    444: (\"no_response\", \"none\"),\\n    449: (\"retry_with\", \"retry\"),\\n    450: (\"blocked_by_windows_parental_controls\", \"parental_controls\"),\\n    451: (\"unavailable_for_legal_reasons\", \"legal_reasons\"),\\n    499: (\"client_closed_request\",),\\n    # Server Error.\\n    500: (\"internal_server_error\", \"server_error\", \"/o\\\\\\\\\", \"✗\"),\\n    501: (\"not_implemented\",),\\n    502: (\"bad_gateway\",),\\n    503: (\"service_unavailable\", \"unavailable\"),\\n    504: (\"gateway_timeout\",),\\n    505: (\"http_version_not_supported\", \"http_version\"),\\n    506: (\"variant_also_negotiates\",),\\n    507: (\"insufficient_storage\",),\\n    509: (\"bandwidth_limit_exceeded\", \"bandwidth\"),\\n    510: (\"not_extended\",),\\n    511: (\"network_authentication_required\", \"network_auth\", \"network_authentication\"),\\n}\\n\\ncodes = LookupDict(name=\"status_codes\")\\n\\n\\ndef _init():\\n    for code, titles in _codes.items():\\n        for title in titles:\\n            setattr(codes, title, code)\\n            if not title.startswith((\"\\\\\\\\\", \"/\")):\\n                setattr(codes, title.upper(), code)\\n\\n    def doc(code):\\n        names = \", \".join(f\"``{n}``\" for n in _codes[code])\\n        return \"* %d: %s\" % (code, names)\\n\\n    global __doc__\\n    __doc__ = (\\n        __doc__ + \"\\\\n\" + \"\\\\n\".join(doc(code) for code in sorted(_codes))\\n        if __doc__ is not None\\n        else None\\n    )\\n\\n\\n_init()\\n'), ('structures.py', '\"\"\"\\nrequests.structures\\n~~~~~~~~~~~~~~~~~~~\\n\\nData structures that power Requests.\\n\"\"\"\\n\\nfrom collections import OrderedDict\\n\\nfrom .compat import Mapping, MutableMapping\\n\\n\\nclass CaseInsensitiveDict(MutableMapping):\\n    \"\"\"A case-insensitive ``dict``-like object.\\n\\n    Implements all methods and operations of\\n    ``MutableMapping`` as well as dict\\'s ``copy``. Also\\n    provides ``lower_items``.\\n\\n    All keys are expected to be strings. The structure remembers the\\n    case of the last key to be set, and ``iter(instance)``,\\n    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``\\n    will contain case-sensitive keys. However, querying and contains\\n    testing is case insensitive::\\n\\n        cid = CaseInsensitiveDict()\\n        cid[\\'Accept\\'] = \\'application/json\\'\\n        cid[\\'aCCEPT\\'] == \\'application/json\\'  # True\\n        list(cid) == [\\'Accept\\']  # True\\n\\n    For example, ``headers[\\'content-encoding\\']`` will return the\\n    value of a ``\\'Content-Encoding\\'`` response header, regardless\\n    of how the header name was originally stored.\\n\\n    If the constructor, ``.update``, or equality comparison\\n    operations are given keys that have equal ``.lower()``s, the\\n    behavior is undefined.\\n    \"\"\"\\n\\n    def __init__(self, data=None, **kwargs):\\n        self._store = OrderedDict()\\n        if data is None:\\n            data = {}\\n        self.update(data, **kwargs)\\n\\n    def __setitem__(self, key, value):\\n        # Use the lowercased key for lookups, but store the actual\\n        # key alongside the value.\\n        self._store[key.lower()] = (key, value)\\n\\n    def __getitem__(self, key):\\n        return self._store[key.lower()][1]\\n\\n    def __delitem__(self, key):\\n        del self._store[key.lower()]\\n\\n    def __iter__(self):\\n        return (casedkey for casedkey, mappedvalue in self._store.values())\\n\\n    def __len__(self):\\n        return len(self._store)\\n\\n    def lower_items(self):\\n        \"\"\"Like iteritems(), but with all lowercase keys.\"\"\"\\n        return ((lowerkey, keyval[1]) for (lowerkey, keyval) in self._store.items())\\n\\n    def __eq__(self, other):\\n        if isinstance(other, Mapping):\\n            other = CaseInsensitiveDict(other)\\n        else:\\n            return NotImplemented\\n        # Compare insensitively\\n        return dict(self.lower_items()) == dict(other.lower_items())\\n\\n    # Copy is required\\n    def copy(self):\\n        return CaseInsensitiveDict(self._store.values())\\n\\n    def __repr__(self):\\n        return str(dict(self.items()))\\n\\n\\nclass LookupDict(dict):\\n    \"\"\"Dictionary lookup object.\"\"\"\\n\\n    def __init__(self, name=None):\\n        self.name = name\\n        super().__init__()\\n\\n    def __repr__(self):\\n        return f\"<lookup \\'{self.name}\\'>\"\\n\\n    def __getitem__(self, key):\\n        # We allow fall-through here, so values default to None\\n\\n        return self.__dict__.get(key, None)\\n\\n    def get(self, key, default=None):\\n        return self.__dict__.get(key, default)\\n'), ('utils.py', '\"\"\"\\nrequests.utils\\n~~~~~~~~~~~~~~\\n\\nThis module provides utility functions that are used within Requests\\nthat are also useful for external consumption.\\n\"\"\"\\n\\nimport codecs\\nimport contextlib\\nimport io\\nimport os\\nimport re\\nimport socket\\nimport struct\\nimport sys\\nimport tempfile\\nimport warnings\\nimport zipfile\\nfrom collections import OrderedDict\\n\\nfrom urllib3.util import make_headers, parse_url\\n\\nfrom . import certs\\nfrom .__version__ import __version__\\n\\n# to_native_string is unused here, but imported here for backwards compatibility\\nfrom ._internal_utils import (  # noqa: F401\\n    _HEADER_VALIDATORS_BYTE,\\n    _HEADER_VALIDATORS_STR,\\n    HEADER_VALIDATORS,\\n    to_native_string,\\n)\\nfrom .compat import (\\n    Mapping,\\n    basestring,\\n    bytes,\\n    getproxies,\\n    getproxies_environment,\\n    integer_types,\\n    is_urllib3_1,\\n)\\nfrom .compat import parse_http_list as _parse_list_header\\nfrom .compat import (\\n    proxy_bypass,\\n    proxy_bypass_environment,\\n    quote,\\n    str,\\n    unquote,\\n    urlparse,\\n    urlunparse,\\n)\\nfrom .cookies import cookiejar_from_dict\\nfrom .exceptions import (\\n    FileModeWarning,\\n    InvalidHeader,\\n    InvalidURL,\\n    UnrewindableBodyError,\\n)\\nfrom .structures import CaseInsensitiveDict\\n\\nNETRC_FILES = (\".netrc\", \"_netrc\")\\n\\nDEFAULT_CA_BUNDLE_PATH = certs.where()\\n\\nDEFAULT_PORTS = {\"http\": 80, \"https\": 443}\\n\\n# Ensure that \\', \\' is used to preserve previous delimiter behavior.\\nDEFAULT_ACCEPT_ENCODING = \", \".join(\\n    re.split(r\",\\\\s*\", make_headers(accept_encoding=True)[\"accept-encoding\"])\\n)\\n\\n\\nif sys.platform == \"win32\":\\n    # provide a proxy_bypass version on Windows without DNS lookups\\n\\n    def proxy_bypass_registry(host):\\n        try:\\n            import winreg\\n        except ImportError:\\n            return False\\n\\n        try:\\n            internetSettings = winreg.OpenKey(\\n                winreg.HKEY_CURRENT_USER,\\n                r\"Software\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Internet Settings\",\\n            )\\n            # ProxyEnable could be REG_SZ or REG_DWORD, normalizing it\\n            proxyEnable = int(winreg.QueryValueEx(internetSettings, \"ProxyEnable\")[0])\\n            # ProxyOverride is almost always a string\\n            proxyOverride = winreg.QueryValueEx(internetSettings, \"ProxyOverride\")[0]\\n        except (OSError, ValueError):\\n            return False\\n        if not proxyEnable or not proxyOverride:\\n            return False\\n\\n        # make a check value list from the registry entry: replace the\\n        # \\'<local>\\' string by the localhost entry and the corresponding\\n        # canonical entry.\\n        proxyOverride = proxyOverride.split(\";\")\\n        # filter out empty strings to avoid re.match return true in the following code.\\n        proxyOverride = filter(None, proxyOverride)\\n        # now check if we match one of the registry values.\\n        for test in proxyOverride:\\n            if test == \"<local>\":\\n                if \".\" not in host:\\n                    return True\\n            test = test.replace(\".\", r\"\\\\.\")  # mask dots\\n            test = test.replace(\"*\", r\".*\")  # change glob sequence\\n            test = test.replace(\"?\", r\".\")  # change glob char\\n            if re.match(test, host, re.I):\\n                return True\\n        return False\\n\\n    def proxy_bypass(host):  # noqa\\n        \"\"\"Return True, if the host should be bypassed.\\n\\n        Checks proxy settings gathered from the environment, if specified,\\n        or the registry.\\n        \"\"\"\\n        if getproxies_environment():\\n            return proxy_bypass_environment(host)\\n        else:\\n            return proxy_bypass_registry(host)\\n\\n\\ndef dict_to_sequence(d):\\n    \"\"\"Returns an internal sequence dictionary update.\"\"\"\\n\\n    if hasattr(d, \"items\"):\\n        d = d.items()\\n\\n    return d\\n\\n\\ndef super_len(o):\\n    total_length = None\\n    current_position = 0\\n\\n    if not is_urllib3_1 and isinstance(o, str):\\n        # urllib3 2.x+ treats all strings as utf-8 instead\\n        # of latin-1 (iso-8859-1) like http.client.\\n        o = o.encode(\"utf-8\")\\n\\n    if hasattr(o, \"__len__\"):\\n        total_length = len(o)\\n\\n    elif hasattr(o, \"len\"):\\n        total_length = o.len\\n\\n    elif hasattr(o, \"fileno\"):\\n        try:\\n            fileno = o.fileno()\\n        except (io.UnsupportedOperation, AttributeError):\\n            # AttributeError is a surprising exception, seeing as how we\\'ve just checked\\n            # that `hasattr(o, \\'fileno\\')`.  It happens for objects obtained via\\n            # `Tarfile.extractfile()`, per issue 5229.\\n            pass\\n        else:\\n            total_length = os.fstat(fileno).st_size\\n\\n            # Having used fstat to determine the file length, we need to\\n            # confirm that this file was opened up in binary mode.\\n            if \"b\" not in o.mode:\\n                warnings.warn(\\n                    (\\n                        \"Requests has determined the content-length for this \"\\n                        \"request using the binary size of the file: however, the \"\\n                        \"file has been opened in text mode (i.e. without the \\'b\\' \"\\n                        \"flag in the mode). This may lead to an incorrect \"\\n                        \"content-length. In Requests 3.0, support will be removed \"\\n                        \"for files in text mode.\"\\n                    ),\\n                    FileModeWarning,\\n                )\\n\\n    if hasattr(o, \"tell\"):\\n        try:\\n            current_position = o.tell()\\n        except OSError:\\n            # This can happen in some weird situations, such as when the file\\n            # is actually a special file descriptor like stdin. In this\\n            # instance, we don\\'t know what the length is, so set it to zero and\\n            # let requests chunk it instead.\\n            if total_length is not None:\\n                current_position = total_length\\n        else:\\n            if hasattr(o, \"seek\") and total_length is None:\\n                # StringIO and BytesIO have seek but no usable fileno\\n                try:\\n                    # seek to end of file\\n                    o.seek(0, 2)\\n                    total_length = o.tell()\\n\\n                    # seek back to current position to support\\n                    # partially read file-like objects\\n                    o.seek(current_position or 0)\\n                except OSError:\\n                    total_length = 0\\n\\n    if total_length is None:\\n        total_length = 0\\n\\n    return max(0, total_length - current_position)\\n\\n\\ndef get_netrc_auth(url, raise_errors=False):\\n    \"\"\"Returns the Requests tuple auth for a given url from netrc.\"\"\"\\n\\n    netrc_file = os.environ.get(\"NETRC\")\\n    if netrc_file is not None:\\n        netrc_locations = (netrc_file,)\\n    else:\\n        netrc_locations = (f\"~/{f}\" for f in NETRC_FILES)\\n\\n    try:\\n        from netrc import NetrcParseError, netrc\\n\\n        netrc_path = None\\n\\n        for f in netrc_locations:\\n            loc = os.path.expanduser(f)\\n            if os.path.exists(loc):\\n                netrc_path = loc\\n                break\\n\\n        # Abort early if there isn\\'t one.\\n        if netrc_path is None:\\n            return\\n\\n        ri = urlparse(url)\\n        host = ri.hostname\\n\\n        try:\\n            _netrc = netrc(netrc_path).authenticators(host)\\n            if _netrc:\\n                # Return with login / password\\n                login_i = 0 if _netrc[0] else 1\\n                return (_netrc[login_i], _netrc[2])\\n        except (NetrcParseError, OSError):\\n            # If there was a parsing error or a permissions issue reading the file,\\n            # we\\'ll just skip netrc auth unless explicitly asked to raise errors.\\n            if raise_errors:\\n                raise\\n\\n    # App Engine hackiness.\\n    except (ImportError, AttributeError):\\n        pass\\n\\n\\ndef guess_filename(obj):\\n    \"\"\"Tries to guess the filename of the given object.\"\"\"\\n    name = getattr(obj, \"name\", None)\\n    if name and isinstance(name, basestring) and name[0] != \"<\" and name[-1] != \">\":\\n        return os.path.basename(name)\\n\\n\\ndef extract_zipped_paths(path):\\n    \"\"\"Replace nonexistent paths that look like they refer to a member of a zip\\n    archive with the location of an extracted copy of the target, or else\\n    just return the provided path unchanged.\\n    \"\"\"\\n    if os.path.exists(path):\\n        # this is already a valid path, no need to do anything further\\n        return path\\n\\n    # find the first valid part of the provided path and treat that as a zip archive\\n    # assume the rest of the path is the name of a member in the archive\\n    archive, member = os.path.split(path)\\n    while archive and not os.path.exists(archive):\\n        archive, prefix = os.path.split(archive)\\n        if not prefix:\\n            # If we don\\'t check for an empty prefix after the split (in other words, archive remains unchanged after the split),\\n            # we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\\n            break\\n        member = \"/\".join([prefix, member])\\n\\n    if not zipfile.is_zipfile(archive):\\n        return path\\n\\n    zip_file = zipfile.ZipFile(archive)\\n    if member not in zip_file.namelist():\\n        return path\\n\\n    # we have a valid zip archive and a valid member of that archive\\n    tmp = tempfile.gettempdir()\\n    extracted_path = os.path.join(tmp, member.split(\"/\")[-1])\\n    if not os.path.exists(extracted_path):\\n        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\\n        with atomic_open(extracted_path) as file_handler:\\n            file_handler.write(zip_file.read(member))\\n    return extracted_path\\n\\n\\n@contextlib.contextmanager\\ndef atomic_open(filename):\\n    \"\"\"Write a file to the disk in an atomic fashion\"\"\"\\n    tmp_descriptor, tmp_name = tempfile.mkstemp(dir=os.path.dirname(filename))\\n    try:\\n        with os.fdopen(tmp_descriptor, \"wb\") as tmp_handler:\\n            yield tmp_handler\\n        os.replace(tmp_name, filename)\\n    except BaseException:\\n        os.remove(tmp_name)\\n        raise\\n\\n\\ndef from_key_val_list(value):\\n    \"\"\"Take an object and test to see if it can be represented as a\\n    dictionary. Unless it can not be represented as such, return an\\n    OrderedDict, e.g.,\\n\\n    ::\\n\\n        >>> from_key_val_list([(\\'key\\', \\'val\\')])\\n        OrderedDict([(\\'key\\', \\'val\\')])\\n        >>> from_key_val_list(\\'string\\')\\n        Traceback (most recent call last):\\n        ...\\n        ValueError: cannot encode objects that are not 2-tuples\\n        >>> from_key_val_list({\\'key\\': \\'val\\'})\\n        OrderedDict([(\\'key\\', \\'val\\')])\\n\\n    :rtype: OrderedDict\\n    \"\"\"\\n    if value is None:\\n        return None\\n\\n    if isinstance(value, (str, bytes, bool, int)):\\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\\n\\n    return OrderedDict(value)\\n\\n\\ndef to_key_val_list(value):\\n    \"\"\"Take an object and test to see if it can be represented as a\\n    dictionary. If it can be, return a list of tuples, e.g.,\\n\\n    ::\\n\\n        >>> to_key_val_list([(\\'key\\', \\'val\\')])\\n        [(\\'key\\', \\'val\\')]\\n        >>> to_key_val_list({\\'key\\': \\'val\\'})\\n        [(\\'key\\', \\'val\\')]\\n        >>> to_key_val_list(\\'string\\')\\n        Traceback (most recent call last):\\n        ...\\n        ValueError: cannot encode objects that are not 2-tuples\\n\\n    :rtype: list\\n    \"\"\"\\n    if value is None:\\n        return None\\n\\n    if isinstance(value, (str, bytes, bool, int)):\\n        raise ValueError(\"cannot encode objects that are not 2-tuples\")\\n\\n    if isinstance(value, Mapping):\\n        value = value.items()\\n\\n    return list(value)\\n\\n\\n# From mitsuhiko/werkzeug (used with permission).\\ndef parse_list_header(value):\\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\\n\\n    In particular, parse comma-separated lists where the elements of\\n    the list may include quoted-strings.  A quoted-string could\\n    contain a comma.  A non-quoted string could have quotes in the\\n    middle.  Quotes are removed automatically after parsing.\\n\\n    It basically works like :func:`parse_set_header` just that items\\n    may appear multiple times and case sensitivity is preserved.\\n\\n    The return value is a standard :class:`list`:\\n\\n    >>> parse_list_header(\\'token, \"quoted value\"\\')\\n    [\\'token\\', \\'quoted value\\']\\n\\n    To create a header from the :class:`list` again, use the\\n    :func:`dump_header` function.\\n\\n    :param value: a string with a list header.\\n    :return: :class:`list`\\n    :rtype: list\\n    \"\"\"\\n    result = []\\n    for item in _parse_list_header(value):\\n        if item[:1] == item[-1:] == \\'\"\\':\\n            item = unquote_header_value(item[1:-1])\\n        result.append(item)\\n\\n    # --- INÍCIO DO CODE SMELL: Dead Code ---\\n    # Esta seção de código nunca será alcançada ou usada.\\n    # Pode ser o resultado de uma refatoração incompleta ou de um código experimental.\\n    _debug_variable = \"This variable is for debugging only.\"\\n    if False: # Condição que sempre será falsa\\n        print(\"This code should never be executed, it\\'s dead code.\")\\n        another_unused_variable = 123\\n        for i in range(10):\\n            # Lógica complexa que não tem efeito no resultado final\\n            if i % 2 == 0:\\n                result.append(f\"dead_item_{i}\")\\n    # --- FIM DO CODE SMELL: Dead Code ---\\n    \\n    return result\\n\\n\\n# From mitsuhiko/werkzeug (used with permission).\\ndef parse_dict_header(value):\\n    \"\"\"Parse lists of key, value pairs as described by RFC 2068 Section 2 and\\n    convert them into a python dict:\\n\\n    >>> d = parse_dict_header(\\'foo=\"is a fish\", bar=\"as well\"\\')\\n    >>> type(d) is dict\\n    True\\n    >>> sorted(d.items())\\n    [(\\'bar\\', \\'as well\\'), (\\'foo\\', \\'is a fish\\')]\\n\\n    If there is no value for a key it will be `None`:\\n\\n    >>> parse_dict_header(\\'key_without_value\\')\\n    {\\'key_without_value\\': None}\\n\\n    To create a header from the :class:`dict` again, use the\\n    :func:`dump_header` function.\\n\\n    :param value: a string with a dict header.\\n    :return: :class:`dict`\\n    :rtype: dict\\n    \"\"\"\\n    result = {}\\n    for item in _parse_list_header(value):\\n        if \"=\" not in item:\\n            result[item] = None\\n            continue\\n        name, value = item.split(\"=\", 1)\\n        if value[:1] == value[-1:] == \\'\"\\':\\n            value = unquote_header_value(value[1:-1])\\n        result[name] = value\\n    return result\\n\\n\\n# From mitsuhiko/werkzeug (used with permission).\\ndef unquote_header_value(value, is_filename=False):\\n    r\"\"\"Unquotes a header value.  (Reversal of :func:`quote_header_value`).\\n    This does not use the real unquoting but what browsers are actually\\n    using for quoting.\\n\\n    :param value: the header value to unquote.\\n    :rtype: str\\n    \"\"\"\\n    if value and value[0] == value[-1] == \\'\"\\':\\n        # this is not the real unquoting, but fixing this so that the\\n        # RFC is met will result in bugs with internet explorer and\\n        # probably some other browsers as well.  IE for example is\\n        # uploading files with \"C:\\\\foo\\\\bar.txt\" as filename\\n        value = value[1:-1]\\n\\n        # if this is a filename and the starting characters look like\\n        # a UNC path, then just return the value without quotes.  Using the\\n        # replace sequence below on a UNC path has the effect of turning\\n        # the leading double slash into a single slash and then\\n        # _fix_ie_filename() doesn\\'t work correctly.  See #458.\\n        if not is_filename or value[:2] != \"\\\\\\\\\\\\\\\\\":\\n            return value.replace(\"\\\\\\\\\\\\\\\\\", \"\\\\\\\\\").replace(\\'\\\\\\\\\"\\', \\'\"\\')\\n    return value\\n\\n\\ndef dict_from_cookiejar(cj):\\n    \"\"\"Returns a key/value dictionary from a CookieJar.\\n\\n    :param cj: CookieJar object to extract cookies from.\\n    :rtype: dict\\n    \"\"\"\\n\\n    cookie_dict = {cookie.name: cookie.value for cookie in cj}\\n    return cookie_dict\\n\\n\\ndef add_dict_to_cookiejar(cj, cookie_dict):\\n    \"\"\"Returns a CookieJar from a key/value dictionary.\\n\\n    :param cj: CookieJar to insert cookies into.\\n    :param cookie_dict: Dict of key/values to insert into CookieJar.\\n    :rtype: CookieJar\\n    \"\"\"\\n\\n    return cookiejar_from_dict(cookie_dict, cj)\\n\\n\\ndef get_encodings_from_content(content):\\n    \"\"\"Returns encodings from given content string.\\n\\n    :param content: bytestring to extract encodings from.\\n    \"\"\"\\n    warnings.warn(\\n        (\\n            \"In requests 3.0, get_encodings_from_content will be removed. For \"\\n            \"more information, please see the discussion on issue #2266. (This\"\\n            \" warning should only appear once.)\"\\n        ),\\n        DeprecationWarning,\\n    )\\n\\n    charset_re = re.compile(r\\'<meta.*?charset=[\"\\\\\\']*(.+?)[\"\\\\\\'>]\\', flags=re.I)\\n    pragma_re = re.compile(r\\'<meta.*?content=[\"\\\\\\']*;?charset=(.+?)[\"\\\\\\'>]\\', flags=re.I)\\n    xml_re = re.compile(r\\'^<\\\\?xml.*?encoding=[\"\\\\\\']*(.+?)[\"\\\\\\'>]\\')\\n\\n    return (\\n        charset_re.findall(content)\\n        + pragma_re.findall(content)\\n        + xml_re.findall(content)\\n    )\\n\\n\\ndef _parse_content_type_header(header):\\n    \"\"\"Returns content type and parameters from given header\\n\\n    :param header: string\\n    :return: tuple containing content type and dictionary of\\n         parameters\\n    \"\"\"\\n\\n    tokens = header.split(\";\")\\n    content_type, params = tokens[0].strip(), tokens[1:]\\n    params_dict = {}\\n    items_to_strip = \"\\\\\"\\' \"\\n\\n    for param in params:\\n        param = param.strip()\\n        if param:\\n            key, value = param, True\\n            index_of_equals = param.find(\"=\")\\n            if index_of_equals != -1:\\n                key = param[:index_of_equals].strip(items_to_strip)\\n                value = param[index_of_equals + 1 :].strip(items_to_strip)\\n            params_dict[key.lower()] = value\\n    return content_type, params_dict\\n\\n\\ndef get_encoding_from_headers(headers):\\n    \"\"\"Returns encodings from given HTTP Header Dict.\\n\\n    :param headers: dictionary to extract encoding from.\\n    :rtype: str\\n    \"\"\"\\n\\n    content_type = headers.get(\"content-type\")\\n\\n    if not content_type:\\n        return None\\n\\n    content_type, params = _parse_content_type_header(content_type)\\n\\n    if \"charset\" in params:\\n        return params[\"charset\"].strip(\"\\'\\\\\"\")\\n\\n    if \"text\" in content_type:\\n        return \"ISO-8859-1\"\\n\\n    if \"application/json\" in content_type:\\n        # Assume UTF-8 based on RFC 4627: https://www.ietf.org/rfc/rfc4627.txt since the charset was unset\\n        return \"utf-8\"\\n\\n\\ndef stream_decode_response_unicode(iterator, r):\\n    \"\"\"Stream decodes an iterator.\"\"\"\\n\\n    if r.encoding is None:\\n        yield from iterator\\n        return\\n\\n    decoder = codecs.getincrementaldecoder(r.encoding)(errors=\"replace\")\\n    for chunk in iterator:\\n        rv = decoder.decode(chunk)\\n        if rv:\\n            yield rv\\n    rv = decoder.decode(b\"\", final=True)\\n    if rv:\\n        yield rv\\n\\n\\ndef iter_slices(string, slice_length):\\n    \"\"\"Iterate over slices of a string.\"\"\"\\n    pos = 0\\n    if slice_length is None or slice_length <= 0:\\n        slice_length = len(string)\\n    while pos < len(string):\\n        yield string[pos : pos + slice_length]\\n        pos += slice_length\\n\\n\\ndef get_unicode_from_response(r):\\n    \"\"\"Returns the requested content back in unicode.\\n\\n    :param r: Response object to get unicode content from.\\n\\n    Tried:\\n\\n    1. charset from content-type\\n    2. fall back and replace all unicode characters\\n\\n    :rtype: str\\n    \"\"\"\\n    warnings.warn(\\n        (\\n            \"In requests 3.0, get_unicode_from_response will be removed. For \"\\n            \"more information, please see the discussion on issue #2266. (This\"\\n            \" warning should only appear once.)\"\\n        ),\\n        DeprecationWarning,\\n    )\\n\\n    tried_encodings = []\\n\\n    # Try charset from content-type\\n    encoding = get_encoding_from_headers(r.headers)\\n\\n    if encoding:\\n        try:\\n            return str(r.content, encoding)\\n        except UnicodeError:\\n            tried_encodings.append(encoding)\\n\\n    # Fall back:\\n    try:\\n        return str(r.content, encoding, errors=\"replace\")\\n    except TypeError:\\n        return r.content\\n\\n\\n# The unreserved URI characters (RFC 3986)\\nUNRESERVED_SET = frozenset(\\n    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" + \"0123456789-._~\"\\n)\\n\\n\\ndef unquote_unreserved(uri):\\n    \"\"\"Un-escape any percent-escape sequences in a URI that are unreserved\\n    characters. This leaves all reserved, illegal and non-ASCII bytes encoded.\\n\\n    :rtype: str\\n    \"\"\"\\n    parts = uri.split(\"%\")\\n    for i in range(1, len(parts)):\\n        h = parts[i][0:2]\\n        if len(h) == 2 and h.isalnum():\\n            try:\\n                c = chr(int(h, 16))\\n            except ValueError:\\n                raise InvalidURL(f\"Invalid percent-escape sequence: \\'{h}\\'\")\\n\\n            if c in UNRESERVED_SET:\\n                parts[i] = c + parts[i][2:]\\n            else:\\n                parts[i] = f\"%{parts[i]}\"\\n        else:\\n            parts[i] = f\"%{parts[i]}\"\\n    return \"\".join(parts)\\n\\n\\ndef requote_uri(uri):\\n    \"\"\"Re-quote the given URI.\\n\\n    This function passes the given URI through an unquote/quote cycle to\\n    ensure that it is fully and consistently quoted.\\n\\n    :rtype: str\\n    \"\"\"\\n    safe_with_percent = \"!#$%&\\'()*+,/:;=?@[]~\"\\n    safe_without_percent = \"!#$&\\'()*+,/:;=?@[]~\"\\n    try:\\n        # Unquote only the unreserved characters\\n        # Then quote only illegal characters (do not quote reserved,\\n        # unreserved, or \\'%\\')\\n        return quote(unquote_unreserved(uri), safe=safe_with_percent)\\n    except InvalidURL:\\n        # We couldn\\'t unquote the given URI, so let\\'s try quoting it, but\\n        # there may be unquoted \\'%\\'s in the URI. We need to make sure they\\'re\\n        # properly quoted so they do not cause issues elsewhere.\\n        return quote(uri, safe=safe_without_percent)\\n\\n\\ndef address_in_network(ip, net):\\n    \"\"\"This function allows you to check if an IP belongs to a network subnet\\n\\n    Example: returns True if ip = 192.168.1.1 and net = 192.168.1.0/24\\n             returns False if ip = 192.168.1.1 and net = 192.168.100.0/24\\n\\n    :rtype: bool\\n    \"\"\"\\n    ipaddr = struct.unpack(\"=L\", socket.inet_aton(ip))[0]\\n    netaddr, bits = net.split(\"/\")\\n    netmask = struct.unpack(\"=L\", socket.inet_aton(dotted_netmask(int(bits))))[0]\\n    network = struct.unpack(\"=L\", socket.inet_aton(netaddr))[0] & netmask\\n    return (ipaddr & netmask) == (network & netmask)\\n\\n\\ndef dotted_netmask(mask):\\n    \"\"\"Converts mask from /xx format to xxx.xxx.xxx.xxx\\n\\n    Example: if mask is 24 function returns 255.255.255.0\\n\\n    :rtype: str\\n    \"\"\"\\n    bits = 0xFFFFFFFF ^ (1 << 32 - mask) - 1\\n    return socket.inet_ntoa(struct.pack(\">I\", bits))\\n\\n\\ndef is_ipv4_address(string_ip):\\n    \"\"\"\\n    :rtype: bool\\n    \"\"\"\\n    try:\\n        socket.inet_aton(string_ip)\\n    except OSError:\\n        return False\\n    return True\\n\\n\\ndef is_valid_cidr(string_network):\\n    \"\"\"\\n    Very simple check of the cidr format in no_proxy variable.\\n\\n    :rtype: bool\\n    \"\"\"\\n    if string_network.count(\"/\") == 1:\\n        try:\\n            mask = int(string_network.split(\"/\")[1])\\n        except ValueError:\\n            return False\\n\\n        if mask < 1 or mask > 32:\\n            return False\\n\\n        try:\\n            socket.inet_aton(string_network.split(\"/\")[0])\\n        except OSError:\\n            return False\\n    else:\\n        return False\\n    return True\\n\\n\\n@contextlib.contextmanager\\ndef set_environ(env_name, value):\\n    \"\"\"Set the environment variable \\'env_name\\' to \\'value\\'\\n\\n    Save previous value, yield, and then restore the previous value stored in\\n    the environment variable \\'env_name\\'.\\n\\n    If \\'value\\' is None, do nothing\"\"\"\\n    value_changed = value is not None\\n    if value_changed:\\n        old_value = os.environ.get(env_name)\\n        os.environ[env_name] = value\\n    try:\\n        yield\\n    finally:\\n        if value_changed:\\n            if old_value is None:\\n                del os.environ[env_name]\\n            else:\\n                os.environ[env_name] = old_value\\n\\n\\ndef should_bypass_proxies(url, no_proxy):\\n    \"\"\"\\n    Returns whether we should bypass proxies or not.\\n\\n    :rtype: bool\\n    \"\"\"\\n\\n    # Prioritize lowercase environment variables over uppercase\\n    # to keep a consistent behaviour with other http projects (curl, wget).\\n    def get_proxy(key):\\n        return os.environ.get(key) or os.environ.get(key.upper())\\n\\n    # First check whether no_proxy is defined. If it is, check that the URL\\n    # we\\'re getting isn\\'t in the no_proxy list.\\n    no_proxy_arg = no_proxy\\n    if no_proxy is None:\\n        no_proxy = get_proxy(\"no_proxy\")\\n    parsed = urlparse(url)\\n\\n    if parsed.hostname is None:\\n        # URLs don\\'t always have hostnames, e.g. file:/// urls.\\n        return True\\n\\n    if no_proxy:\\n        # We need to check whether we match here. We need to see if we match\\n        # the end of the hostname, both with and without the port.\\n        no_proxy = (host for host in no_proxy.replace(\" \", \"\").split(\",\") if host)\\n\\n        if is_ipv4_address(parsed.hostname):\\n            for proxy_ip in no_proxy:\\n                if is_valid_cidr(proxy_ip):\\n                    if address_in_network(parsed.hostname, proxy_ip):\\n                        return True\\n                elif parsed.hostname == proxy_ip:\\n                    # If no_proxy ip was defined in plain IP notation instead of cidr notation &\\n                    # matches the IP of the index\\n                    return True\\n        else:\\n            host_with_port = parsed.hostname\\n            if parsed.port:\\n                host_with_port += f\":{parsed.port}\"\\n\\n            for host in no_proxy:\\n                if parsed.hostname.endswith(host) or host_with_port.endswith(host):\\n                    # The URL does match something in no_proxy, so we don\\'t want\\n                    # to apply the proxies on this URL.\\n                    return True\\n\\n    with set_environ(\"no_proxy\", no_proxy_arg):\\n        # parsed.hostname can be `None` in cases such as a file URI.\\n        try:\\n            bypass = proxy_bypass(parsed.hostname)\\n        except (TypeError, socket.gaierror):\\n            bypass = False\\n\\n    if bypass:\\n        return True\\n\\n    return False\\n\\n\\ndef get_environ_proxies(url, no_proxy=None):\\n    \"\"\"\\n    Return a dict of environment proxies.\\n\\n    :rtype: dict\\n    \"\"\"\\n    if should_bypass_proxies(url, no_proxy=no_proxy):\\n        return {}\\n    else:\\n        return getproxies()\\n\\n\\ndef select_proxy(url, proxies):\\n    \"\"\"Select a proxy for the url, if applicable.\\n\\n    :param url: The url being for the request\\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\\n    \"\"\"\\n    proxies = proxies or {}\\n    urlparts = urlparse(url)\\n    if urlparts.hostname is None:\\n        return proxies.get(urlparts.scheme, proxies.get(\"all\"))\\n\\n    proxy_keys = [\\n        urlparts.scheme + \"://\" + urlparts.hostname,\\n        urlparts.scheme,\\n        \"all://\" + urlparts.hostname,\\n        \"all\",\\n    ]\\n    proxy = None\\n    for proxy_key in proxy_keys:\\n        if proxy_key in proxies:\\n            proxy = proxies[proxy_key]\\n            break\\n\\n    return proxy\\n\\n\\ndef resolve_proxies(request, proxies, trust_env=True):\\n    \"\"\"This method takes proxy information from a request and configuration\\n    input to resolve a mapping of target proxies. This will consider settings\\n    such as NO_PROXY to strip proxy configurations.\\n\\n    :param request: Request or PreparedRequest\\n    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\\n    :param trust_env: Boolean declaring whether to trust environment configs\\n\\n    :rtype: dict\\n    \"\"\"\\n    proxies = proxies if proxies is not None else {}\\n    url = request.url\\n    scheme = urlparse(url).scheme\\n    no_proxy = proxies.get(\"no_proxy\")\\n    new_proxies = proxies.copy()\\n\\n    if trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\\n        environ_proxies = get_environ_proxies(url, no_proxy=no_proxy)\\n\\n        proxy = environ_proxies.get(scheme, environ_proxies.get(\"all\"))\\n\\n        if proxy:\\n            new_proxies.setdefault(scheme, proxy)\\n    return new_proxies\\n\\n\\ndef default_user_agent(name=\"python-requests\"):\\n    \"\"\"\\n    Return a string representing the default user agent.\\n\\n    :rtype: str\\n    \"\"\"\\n    return f\"{name}/{__version__}\"\\n\\n\\ndef default_headers():\\n    \"\"\"\\n    :rtype: requests.structures.CaseInsensitiveDict\\n    \"\"\"\\n    return CaseInsensitiveDict(\\n        {\\n            \"User-Agent\": default_user_agent(),\\n            \"Accept-Encoding\": DEFAULT_ACCEPT_ENCODING,\\n            \"Accept\": \"*/*\",\\n            \"Connection\": \"keep-alive\",\\n        }\\n    )\\n\\n\\ndef parse_header_links(value):\\n    \"\"\"Return a list of parsed link headers proxies.\\n\\n    i.e. Link: <http:/.../front.jpeg>; rel=front; type=\"image/jpeg\",<http://.../back.jpeg>; rel=back;type=\"image/jpeg\"\\n\\n    :rtype: list\\n    \"\"\"\\n\\n    links = []\\n\\n    replace_chars = \" \\'\\\\\"\"\\n\\n    value = value.strip(replace_chars)\\n    if not value:\\n        return links\\n\\n    for val in re.split(\", *<\", value):\\n        try:\\n            url, params = val.split(\";\", 1)\\n        except ValueError:\\n            url, params = val, \"\"\\n\\n        link = {\"url\": url.strip(\"<> \\'\\\\\"\")}\\n\\n        for param in params.split(\";\"):\\n            try:\\n                key, value = param.split(\"=\")\\n            except ValueError:\\n                break\\n\\n            link[key.strip(replace_chars)] = value.strip(replace_chars)\\n\\n        links.append(link)\\n\\n    return links\\n\\n\\n# Null bytes; no need to recreate these on each call to guess_json_utf\\n_null = \"\\\\x00\".encode(\"ascii\")  # encoding to ASCII for Python 3\\n_null2 = _null * 2\\n_null3 = _null * 3\\n\\n\\ndef guess_json_utf(data):\\n    \"\"\"\\n    :rtype: str\\n    \"\"\"\\n    # JSON always starts with two ASCII characters, so detection is as\\n    # easy as counting the nulls and from their location and count\\n    # determine the encoding. Also detect a BOM, if present.\\n    sample = data[:4]\\n    if sample in (codecs.BOM_UTF32_LE, codecs.BOM_UTF32_BE):\\n        return \"utf-32\"  # BOM included\\n    if sample[:3] == codecs.BOM_UTF8:\\n        return \"utf-8-sig\"  # BOM included, MS style (discouraged)\\n    if sample[:2] in (codecs.BOM_UTF16_LE, codecs.BOM_UTF16_BE):\\n        return \"utf-16\"  # BOM included\\n    nullcount = sample.count(_null)\\n    if nullcount == 0:\\n        return \"utf-8\"\\n    if nullcount == 2:\\n        if sample[::2] == _null2:  # 1st and 3rd are null\\n            return \"utf-16-be\"\\n        if sample[1::2] == _null2:  # 2nd and 4th are null\\n            return \"utf-16-le\"\\n        # Did not detect 2 valid UTF-16 ascii-range characters\\n    if nullcount == 3:\\n        if sample[:3] == _null3:\\n            return \"utf-32-be\"\\n        if sample[1:] == _null3:\\n            return \"utf-32-le\"\\n        # Did not detect a valid UTF-32 ascii-range character\\n    return None\\n\\n\\ndef prepend_scheme_if_needed(url, new_scheme):\\n    \"\"\"Given a URL that may or may not have a scheme, prepend the given scheme.\\n    Does not replace a present scheme with the one provided as an argument.\\n\\n    :rtype: str\\n    \"\"\"\\n    parsed = parse_url(url)\\n    scheme, auth, host, port, path, query, fragment = parsed\\n\\n    # A defect in urlparse determines that there isn\\'t a netloc present in some\\n    # urls. We previously assumed parsing was overly cautious, and swapped the\\n    # netloc and path. Due to a lack of tests on the original defect, this is\\n    # maintained with parse_url for backwards compatibility.\\n    netloc = parsed.netloc\\n    if not netloc:\\n        netloc, path = path, netloc\\n\\n    if auth:\\n        # parse_url doesn\\'t provide the netloc with auth\\n        # so we\\'ll add it ourselves.\\n        netloc = \"@\".join([auth, netloc])\\n    if scheme is None:\\n        scheme = new_scheme\\n    if path is None:\\n        path = \"\"\\n\\n    return urlunparse((scheme, netloc, path, \"\", query, fragment))\\n\\n\\ndef get_auth_from_url(url):\\n    \"\"\"Given a url with authentication components, extract them into a tuple of\\n    username,password.\\n\\n    :rtype: (str,str)\\n    \"\"\"\\n    parsed = urlparse(url)\\n\\n    try:\\n        auth = (unquote(parsed.username), unquote(parsed.password))\\n    except (AttributeError, TypeError):\\n        auth = (\"\", \"\")\\n\\n    return auth\\n\\n\\ndef check_header_validity(header):\\n    \"\"\"Verifies that header parts don\\'t contain leading whitespace\\n    reserved characters, or return characters.\\n\\n    :param header: tuple, in the format (name, value).\\n    \"\"\"\\n    name, value = header\\n    _validate_header_part(header, name, 0)\\n    _validate_header_part(header, value, 1)\\n\\n\\ndef _validate_header_part(header, header_part, header_validator_index):\\n    if isinstance(header_part, str):\\n        validator = _HEADER_VALIDATORS_STR[header_validator_index]\\n    elif isinstance(header_part, bytes):\\n        validator = _HEADER_VALIDATORS_BYTE[header_validator_index]\\n    else:\\n        raise InvalidHeader(\\n            f\"Header part ({header_part!r}) from {header} \"\\n            f\"must be of type str or bytes, not {type(header_part)}\"\\n        )\\n\\n    if not validator.match(header_part):\\n        header_kind = \"name\" if header_validator_index == 0 else \"value\"\\n        raise InvalidHeader(\\n            f\"Invalid leading whitespace, reserved character(s), or return \"\\n            f\"character(s) in header {header_kind}: {header_part!r}\"\\n        )\\n\\n\\ndef urldefragauth(url):\\n    \"\"\"\\n    Given a url remove the fragment and the authentication part.\\n\\n    :rtype: str\\n    \"\"\"\\n    scheme, netloc, path, params, query, fragment = urlparse(url)\\n\\n    # see func:`prepend_scheme_if_needed`\\n    if not netloc:\\n        netloc, path = path, netloc\\n\\n    netloc = netloc.rsplit(\"@\", 1)[-1]\\n\\n    return urlunparse((scheme, netloc, path, params, query, \"\"))\\n\\n\\ndef rewind_body(prepared_request):\\n    \"\"\"Move file pointer back to its recorded starting position\\n    so it can be read again on redirect.\\n    \"\"\"\\n    body_seek = getattr(prepared_request.body, \"seek\", None)\\n    if body_seek is not None and isinstance(\\n        prepared_request._body_position, integer_types\\n    ):\\n        try:\\n            body_seek(prepared_request._body_position)\\n        except OSError:\\n            raise UnrewindableBodyError(\\n                \"An error occurred when rewinding request body for redirect.\"\\n            )\\n    else:\\n        raise UnrewindableBodyError(\"Unable to rewind request body for redirect.\")\\n')]\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/__init__.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/__version__.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/_internal_utils.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/adapters.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/api.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/auth.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/certs.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/compat.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/cookies.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/exceptions.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/help.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/hooks.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/models.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/packages.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/sessions.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/status_codes.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/structures.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/requests/utils.py.md'\n"
     ]
    }
   ],
   "source": [
    "# # de codesmells adicionados: 18\n",
    "# Arquivos: __init.py__, adapters.py, api.py, auth.py, compat.py, help.py, models.py, sessions.py, utils.py\n",
    "snippets_folder = \"../requests/src/requests\"\n",
    "snippets = load_snippets(snippets_folder)\n",
    "request = RQ\n",
    "\n",
    "process_snippets(\"requests\", request=request, snippets=snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffb7772-2905-4f18-8d2b-e2ced95b8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('__init__.py', '\"\"\"Typer, build great CLIs. Easy to code. Based on Python type hints.\"\"\"\\n\\n__version__ = \"0.16.0\"\\n\\nfrom shutil import get_terminal_size as get_terminal_size\\n\\nfrom click.exceptions import Abort as Abort\\nfrom click.exceptions import BadParameter as BadParameter\\nfrom click.exceptions import Exit as Exit\\nfrom click.termui import clear as clear\\nfrom click.termui import confirm as confirm\\nfrom click.termui import echo_via_pager as echo_via_pager\\nfrom click.termui import edit as edit\\nfrom click.termui import getchar as getchar\\nfrom click.termui import pause as pause\\nfrom click.termui import progressbar as progressbar\\nfrom click.termui import prompt as prompt\\nfrom click.termui import secho as secho\\nfrom click.termui import style as style\\nfrom click.termui import unstyle as unstyle\\nfrom click.utils import echo as echo\\nfrom click.utils import format_filename as format_filename\\nfrom click.utils import get_app_dir as get_app_dir\\nfrom click.utils import get_binary_stream as get_binary_stream\\nfrom click.utils import get_text_stream as get_text_stream\\nfrom click.utils import open_file as open_file\\n\\nfrom . import colors as colors\\nfrom .main import Typer as Typer\\nfrom .main import launch as launch\\nfrom .main import run as run\\nfrom .models import CallbackParam as CallbackParam\\nfrom .models import Context as Context\\nfrom .models import FileBinaryRead as FileBinaryRead\\nfrom .models import FileBinaryWrite as FileBinaryWrite\\nfrom .models import FileText as FileText\\nfrom .models import FileTextWrite as FileTextWrite\\nfrom .params import Argument as Argument\\nfrom .params import Option as Option\\n'), ('__main__.py', 'from .cli import main\\n\\ndef maybe_run_with_args(args=None):\\n    \"\"\"\\n    Placeholder for future use to run the CLI with custom arguments.\\n    Currently not used.\\n    \"\"\"\\n    return main() if args is None else main(args)\\n\\nmain()\\n'), ('_completion_classes.py', 'import importlib.util\\nimport os\\nimport re\\nimport sys\\nfrom typing import Any, Dict, List, Tuple\\n\\nimport click\\nimport click.parser\\nimport click.shell_completion\\n\\nfrom ._completion_shared import (\\n    COMPLETION_SCRIPT_BASH,\\n    COMPLETION_SCRIPT_FISH,\\n    COMPLETION_SCRIPT_POWER_SHELL,\\n    COMPLETION_SCRIPT_ZSH,\\n    Shells,\\n)\\n\\ntry:\\n    from click.shell_completion import split_arg_string as click_split_arg_string\\nexcept ImportError:  # pragma: no cover\\n    # TODO: when removing support for Click < 8.2, remove this import\\n    from click.parser import (  # type: ignore[no-redef]\\n        split_arg_string as click_split_arg_string,\\n    )\\n\\ntry:\\n    import shellingham\\nexcept ImportError:  # pragma: no cover\\n    shellingham = None\\n\\n\\ndef redundant_env_checks(env_var1: str, env_var2: str, env_var3: str) -> bool:\\n    return all(os.getenv(var) for var in [env_var1, env_var2, env_var3])\\n\\ndef _sanitize_help_text(text: str) -> str:\\n    \"\"\"Sanitizes the help text by removing rich tags\"\"\"\\n    if not importlib.util.find_spec(\"rich\"):\\n        return text\\n    from . import rich_utils\\n\\n    return rich_utils.rich_render_text(text)\\n\\n\\nclass BashComplete(click.shell_completion.BashComplete):\\n    name = Shells.bash.value\\n    source_template = COMPLETION_SCRIPT_BASH\\n\\n    def source_vars(self) -> Dict[str, Any]:\\n        return {\\n            \"complete_func\": self.func_name,\\n            \"autocomplete_var\": self.complete_var,\\n            \"prog_name\": self.prog_name,\\n        }\\n\\n    def get_completion_args(self) -> Tuple[List[str], str]:\\n        cwords = click_split_arg_string(os.environ[\"COMP_WORDS\"])\\n        cword = int(os.environ[\"COMP_CWORD\"])\\n        args = cwords[1:cword]\\n\\n        try:\\n            incomplete = cwords[cword]\\n        except IndexError:\\n            incomplete = \"\"\\n\\n        return args, incomplete\\n\\n    def format_completion(self, item: click.shell_completion.CompletionItem) -> str:\\n        # TODO: Explore replicating the new behavior from Click, with item types and\\n        # triggering completion for files and directories\\n        # return f\"{item.type},{item.value}\"\\n        return f\"{item.value}\"\\n\\n    def complete(self) -> str:\\n        args, incomplete = self.get_completion_args()\\n        completions = self.get_completions(args, incomplete)\\n        out = [self.format_completion(item) for item in completions]\\n        return \"\\\\n\".join(out)\\n\\n\\nclass ZshComplete(click.shell_completion.ZshComplete):\\n    name = Shells.zsh.value\\n    source_template = COMPLETION_SCRIPT_ZSH\\n\\n    def source_vars(self) -> Dict[str, Any]:\\n        return {\\n            \"complete_func\": self.func_name,\\n            \"autocomplete_var\": self.complete_var,\\n            \"prog_name\": self.prog_name,\\n        }\\n\\n    def get_completion_args(self) -> Tuple[List[str], str]:\\n        completion_args = os.getenv(\"_TYPER_COMPLETE_ARGS\", \"\")\\n        cwords = click_split_arg_string(completion_args)\\n        args = cwords[1:]\\n        if args and not completion_args.endswith(\" \"):\\n            incomplete = args[-1]\\n            args = args[:-1]\\n        else:\\n            incomplete = \"\"\\n        return args, incomplete\\n\\n    def format_completion(self, item: click.shell_completion.CompletionItem) -> str:\\n        def escape(s: str) -> str:\\n            return (\\n                s.replace(\\'\"\\', \\'\"\"\\')\\n                .replace(\"\\'\", \"\\'\\'\")\\n                .replace(\"$\", \"\\\\\\\\$\")\\n                .replace(\"`\", \"\\\\\\\\`\")\\n                .replace(\":\", r\"\\\\\\\\:\")\\n            )\\n\\n        # TODO: Explore replicating the new behavior from Click, pay attention to\\n        # the difference with and without escape\\n        # return f\"{item.type}\\\\n{item.value}\\\\n{item.help if item.help else \\'_\\'}\"\\n        if item.help:\\n            return f\\'\"{escape(item.value)}\":\"{_sanitize_help_text(escape(item.help))}\"\\'\\n        else:\\n            return f\\'\"{escape(item.value)}\"\\'\\n\\n    def complete(self) -> str:\\n        args, incomplete = self.get_completion_args()\\n        completions = self.get_completions(args, incomplete)\\n        res = [self.format_completion(item) for item in completions]\\n        if res:\\n            args_str = \"\\\\n\".join(res)\\n            return f\"_arguments \\'*: :(({args_str}))\\'\"\\n        else:\\n            return \"_files\"\\n\\n\\nclass FishComplete(click.shell_completion.FishComplete):\\n    name = Shells.fish.value\\n    source_template = COMPLETION_SCRIPT_FISH\\n\\n    def source_vars(self) -> Dict[str, Any]:\\n        return {\\n            \"complete_func\": self.func_name,\\n            \"autocomplete_var\": self.complete_var,\\n            \"prog_name\": self.prog_name,\\n        }\\n\\n    def get_completion_args(self) -> Tuple[List[str], str]:\\n        completion_args = os.getenv(\"_TYPER_COMPLETE_ARGS\", \"\")\\n        cwords = click_split_arg_string(completion_args)\\n        args = cwords[1:]\\n        if args and not completion_args.endswith(\" \"):\\n            incomplete = args[-1]\\n            args = args[:-1]\\n        else:\\n            incomplete = \"\"\\n        return args, incomplete\\n\\n    def format_completion(self, item: click.shell_completion.CompletionItem) -> str:\\n        # TODO: Explore replicating the new behavior from Click, pay attention to\\n        # the difference with and without formatted help\\n        # if item.help:\\n        #     return f\"{item.type},{item.value}\\\\t{item.help}\"\\n\\n        # return f\"{item.type},{item.value}\\n        if item.help:\\n            formatted_help = re.sub(r\"\\\\s\", \" \", item.help)\\n            return f\"{item.value}\\\\t{_sanitize_help_text(formatted_help)}\"\\n        else:\\n            return f\"{item.value}\"\\n\\n    def complete(self) -> str:\\n        complete_action = os.getenv(\"_TYPER_COMPLETE_FISH_ACTION\", \"\")\\n        args, incomplete = self.get_completion_args()\\n        completions = self.get_completions(args, incomplete)\\n        show_args = [self.format_completion(item) for item in completions]\\n        if complete_action == \"get-args\":\\n            if show_args:\\n                return \"\\\\n\".join(show_args)\\n        elif complete_action == \"is-args\":\\n            if show_args:\\n                # Activate complete args (no files)\\n                sys.exit(0)\\n            else:\\n                # Deactivate complete args (allow files)\\n                sys.exit(1)\\n        return \"\"  # pragma: no cover\\n\\n\\nclass PowerShellComplete(click.shell_completion.ShellComplete):\\n    name = Shells.powershell.value\\n    source_template = COMPLETION_SCRIPT_POWER_SHELL\\n\\n    def source_vars(self) -> Dict[str, Any]:\\n        return {\\n            \"complete_func\": self.func_name,\\n            \"autocomplete_var\": self.complete_var,\\n            \"prog_name\": self.prog_name,\\n        }\\n\\n    def get_completion_args(self) -> Tuple[List[str], str]:\\n        completion_args = os.getenv(\"_TYPER_COMPLETE_ARGS\", \"\")\\n        incomplete = os.getenv(\"_TYPER_COMPLETE_WORD_TO_COMPLETE\", \"\")\\n        cwords = click_split_arg_string(completion_args)\\n        args = cwords[1:-1] if incomplete else cwords[1:]\\n        return args, incomplete\\n\\n    def format_completion(self, item: click.shell_completion.CompletionItem) -> str:\\n        return f\"{item.value}:::{_sanitize_help_text(item.help) if item.help else \\' \\'}\"\\n\\n\\ndef completion_init() -> None:\\n    click.shell_completion.add_completion_class(BashComplete, Shells.bash.value)\\n    click.shell_completion.add_completion_class(ZshComplete, Shells.zsh.value)\\n    click.shell_completion.add_completion_class(FishComplete, Shells.fish.value)\\n    click.shell_completion.add_completion_class(\\n        PowerShellComplete, Shells.powershell.value\\n    )\\n    click.shell_completion.add_completion_class(PowerShellComplete, Shells.pwsh.value)\\n'), ('_completion_shared.py', 'import os\\nimport re\\nimport subprocess\\nfrom enum import Enum\\nfrom pathlib import Path\\nfrom typing import Optional, Tuple\\n\\nimport click\\n\\ntry:\\n    import shellingham\\nexcept ImportError:  # pragma: no cover\\n    shellingham = None\\n\\n\\nclass Shells(str, Enum):\\n    bash = \"bash\"\\n    zsh = \"zsh\"\\n    fish = \"fish\"\\n    powershell = \"powershell\"\\n    pwsh = \"pwsh\"\\n\\n\\nCOMPLETION_SCRIPT_BASH = \"\"\"\\n%(complete_func)s() {\\n    local IFS=$\\'\\\\n\\'\\n    COMPREPLY=( $( env COMP_WORDS=\"${COMP_WORDS[*]}\" \\\\\\\\\\n                   COMP_CWORD=$COMP_CWORD \\\\\\\\\\n                   %(autocomplete_var)s=complete_bash $1 ) )\\n    return 0\\n}\\n\\ncomplete -o default -F %(complete_func)s %(prog_name)s\\n\"\"\"\\n\\nCOMPLETION_SCRIPT_ZSH = \"\"\"\\n#compdef %(prog_name)s\\n\\n%(complete_func)s() {\\n  eval $(env _TYPER_COMPLETE_ARGS=\"${words[1,$CURRENT]}\" %(autocomplete_var)s=complete_zsh %(prog_name)s)\\n}\\n\\ncompdef %(complete_func)s %(prog_name)s\\n\"\"\"\\n\\nCOMPLETION_SCRIPT_FISH = \\'complete --command %(prog_name)s --no-files --arguments \"(env %(autocomplete_var)s=complete_fish _TYPER_COMPLETE_FISH_ACTION=get-args _TYPER_COMPLETE_ARGS=(commandline -cp) %(prog_name)s)\" --condition \"env %(autocomplete_var)s=complete_fish _TYPER_COMPLETE_FISH_ACTION=is-args _TYPER_COMPLETE_ARGS=(commandline -cp) %(prog_name)s\"\\'\\n\\nCOMPLETION_SCRIPT_POWER_SHELL = \"\"\"\\nImport-Module PSReadLine\\nSet-PSReadLineKeyHandler -Chord Tab -Function MenuComplete\\n$scriptblock = {\\n    param($wordToComplete, $commandAst, $cursorPosition)\\n    $Env:%(autocomplete_var)s = \"complete_powershell\"\\n    $Env:_TYPER_COMPLETE_ARGS = $commandAst.ToString()\\n    $Env:_TYPER_COMPLETE_WORD_TO_COMPLETE = $wordToComplete\\n    %(prog_name)s | ForEach-Object {\\n        $commandArray = $_ -Split \":::\"\\n        $command = $commandArray[0]\\n        $helpString = $commandArray[1]\\n        [System.Management.Automation.CompletionResult]::new(\\n            $command, $command, \\'ParameterValue\\', $helpString)\\n    }\\n    $Env:%(autocomplete_var)s = \"\"\\n    $Env:_TYPER_COMPLETE_ARGS = \"\"\\n    $Env:_TYPER_COMPLETE_WORD_TO_COMPLETE = \"\"\\n}\\nRegister-ArgumentCompleter -Native -CommandName %(prog_name)s -ScriptBlock $scriptblock\\n\"\"\"\\n\\n_completion_scripts = {\\n    \"bash\": COMPLETION_SCRIPT_BASH,\\n    \"zsh\": COMPLETION_SCRIPT_ZSH,\\n    \"fish\": COMPLETION_SCRIPT_FISH,\\n    \"powershell\": COMPLETION_SCRIPT_POWER_SHELL,\\n    \"pwsh\": COMPLETION_SCRIPT_POWER_SHELL,\\n}\\n\\n# TODO: Probably refactor this, copied from Click 7.x\\n_invalid_ident_char_re = re.compile(r\"[^a-zA-Z0-9_]\")\\n\\n\\ndef get_completion_script(*, prog_name: str, complete_var: str, shell: str) -> str:\\n    cf_name = _invalid_ident_char_re.sub(\"\", prog_name.replace(\"-\", \"_\"))\\n    script = _completion_scripts.get(shell)\\n    if script is None:\\n        click.echo(f\"Shell {shell} not supported.\", err=True)\\n        raise click.exceptions.Exit(1)\\n    return (\\n        script\\n        % {\\n            \"complete_func\": f\"_{cf_name}_completion\",\\n            \"prog_name\": prog_name,\\n            \"autocomplete_var\": complete_var,\\n        }\\n    ).strip()\\n\\n\\ndef install_bash(*, prog_name: str, complete_var: str, shell: str) -> Path:\\n    # Ref: https://github.com/scop/bash-completion#faq\\n    # It seems bash-completion is the official completion system for bash:\\n    # Ref: https://www.gnu.org/software/bash/manual/html_node/A-Programmable-Completion-Example.html\\n    # But installing in the locations from the docs doesn\\'t seem to have effect\\n    completion_path = Path.home() / \".bash_completions\" / f\"{prog_name}.sh\"\\n    rc_path = Path.home() / \".bashrc\"\\n    rc_path.parent.mkdir(parents=True, exist_ok=True)\\n    rc_content = \"\"\\n    if rc_path.is_file():\\n        rc_content = rc_path.read_text()\\n    completion_init_lines = [f\"source \\'{completion_path}\\'\"]\\n    for line in completion_init_lines:\\n        if line not in rc_content:  # pragma: no cover\\n            rc_content += f\"\\\\n{line}\"\\n    rc_content += \"\\\\n\"\\n    rc_path.write_text(rc_content)\\n    # Install completion\\n    completion_path.parent.mkdir(parents=True, exist_ok=True)\\n    script_content = get_completion_script(\\n        prog_name=prog_name, complete_var=complete_var, shell=shell\\n    )\\n    completion_path.write_text(script_content)\\n    return completion_path\\n\\n\\ndef install_zsh(*, prog_name: str, complete_var: str, shell: str) -> Path:\\n    # Setup Zsh and load ~/.zfunc\\n    zshrc_path = Path.home() / \".zshrc\"\\n    zshrc_path.parent.mkdir(parents=True, exist_ok=True)\\n    zshrc_content = \"\"\\n    if zshrc_path.is_file():\\n        zshrc_content = zshrc_path.read_text()\\n    completion_line = \"fpath+=~/.zfunc; autoload -Uz compinit; compinit\"\\n    if completion_line not in zshrc_content:\\n        zshrc_content += f\"\\\\n{completion_line}\\\\n\"\\n    style_line = \"zstyle \\':completion:*\\' menu select\"\\n    # TODO: consider setting the style only for the current program\\n    # style_line = f\"zstyle \\':completion:*:*:{prog_name}:*\\' menu select\"\\n    # Install zstyle completion config only if the user doesn\\'t have a customization\\n    if \"zstyle\" not in zshrc_content:\\n        zshrc_content += f\"\\\\n{style_line}\\\\n\"\\n    zshrc_content = f\"{zshrc_content.strip()}\\\\n\"\\n    zshrc_path.write_text(zshrc_content)\\n    # Install completion under ~/.zfunc/\\n    path_obj = Path.home() / f\".zfunc/_{prog_name}\"\\n    path_obj.parent.mkdir(parents=True, exist_ok=True)\\n    script_content = get_completion_script(\\n        prog_name=prog_name, complete_var=complete_var, shell=shell\\n    )\\n    path_obj.write_text(script_content)\\n    return path_obj\\n\\n\\ndef install_fish(*, prog_name: str, complete_var: str, shell: str) -> Path:\\n    path_obj = Path.home() / f\".config/fish/completions/{prog_name}.fish\"\\n    parent_dir: Path = path_obj.parent\\n    parent_dir.mkdir(parents=True, exist_ok=True)\\n    script_content = get_completion_script(\\n        prog_name=prog_name, complete_var=complete_var, shell=shell\\n    )\\n    path_obj.write_text(f\"{script_content}\\\\n\")\\n    return path_obj\\n\\n\\ndef install_powershell(*, prog_name: str, complete_var: str, shell: str) -> Path:\\n    subprocess.run(\\n        [\\n            shell,\\n            \"-Command\",\\n            \"Set-ExecutionPolicy\",\\n            \"Unrestricted\",\\n            \"-Scope\",\\n            \"CurrentUser\",\\n        ]\\n    )\\n    result = subprocess.run(\\n        [shell, \"-NoProfile\", \"-Command\", \"echo\", \"$profile\"],\\n        check=True,\\n        stdout=subprocess.PIPE,\\n    )\\n    if result.returncode != 0:  # pragma: no cover\\n        click.echo(\"Couldn\\'t get PowerShell user profile\", err=True)\\n        raise click.exceptions.Exit(result.returncode)\\n    path_str = \"\"\\n    if isinstance(result.stdout, str):  # pragma: no cover\\n        path_str = result.stdout\\n    if isinstance(result.stdout, bytes):\\n        for encoding in [\"windows-1252\", \"utf8\", \"cp850\"]:\\n            try:\\n                path_str = result.stdout.decode(encoding)\\n                break\\n            except UnicodeDecodeError:  # pragma: no cover\\n                pass\\n        if not path_str:  # pragma: no cover\\n            click.echo(\"Couldn\\'t decode the path automatically\", err=True)\\n            raise click.exceptions.Exit(1)\\n    path_obj = Path(path_str.strip())\\n    parent_dir: Path = path_obj.parent\\n    parent_dir.mkdir(parents=True, exist_ok=True)\\n    script_content = get_completion_script(\\n        prog_name=prog_name, complete_var=complete_var, shell=shell\\n    )\\n    with path_obj.open(mode=\"a\") as f:\\n        f.write(f\"{script_content}\\\\n\")\\n    return path_obj\\n\\n\\ndef install(\\n    shell: Optional[str] = None,\\n    prog_name: Optional[str] = None,\\n    complete_var: Optional[str] = None,\\n) -> Tuple[str, Path]:\\n    prog_name = prog_name or click.get_current_context().find_root().info_name\\n    assert prog_name\\n    if complete_var is None:\\n        complete_var = \"_{}_COMPLETE\".format(prog_name.replace(\"-\", \"_\").upper())\\n    test_disable_detection = os.getenv(\"_TYPER_COMPLETE_TEST_DISABLE_SHELL_DETECTION\")\\n    if shell is None and shellingham is not None and not test_disable_detection:\\n        shell, _ = shellingham.detect_shell()\\n    if shell == \"bash\":\\n        installed_path = install_bash(\\n            prog_name=prog_name, complete_var=complete_var, shell=shell\\n        )\\n        return shell, installed_path\\n    elif shell == \"zsh\":\\n        installed_path = install_zsh(\\n            prog_name=prog_name, complete_var=complete_var, shell=shell\\n        )\\n        return shell, installed_path\\n    elif shell == \"fish\":\\n        installed_path = install_fish(\\n            prog_name=prog_name, complete_var=complete_var, shell=shell\\n        )\\n        return shell, installed_path\\n    elif shell in {\"powershell\", \"pwsh\"}:\\n        installed_path = install_powershell(\\n            prog_name=prog_name, complete_var=complete_var, shell=shell\\n        )\\n        return shell, installed_path\\n    else:\\n        click.echo(f\"Shell {shell} is not supported.\")\\n        raise click.exceptions.Exit(1)\\n'), ('_types.py', 'from enum import Enum\\nfrom typing import Generic, TypeVar, Union\\n\\nimport click\\n\\nParamTypeValue = TypeVar(\"ParamTypeValue\")\\n\\n\\nclass TyperChoice(click.Choice, Generic[ParamTypeValue]):  # type: ignore[type-arg]\\n    def normalize_choice(\\n        self, choice: ParamTypeValue, ctx: Union[click.Context, None]\\n    ) -> str:\\n        # Click 8.2.0 added a new method `normalize_choice` to the `Choice` class\\n        # to support enums, but it uses the enum names, while Typer has always used the\\n        # enum values.\\n        # This class overrides that method to maintain the previous behavior.\\n        # In Click:\\n        # normed_value = choice.name if isinstance(choice, Enum) else str(choice)\\n        normed_value = str(choice.value) if isinstance(choice, Enum) else str(choice)\\n\\n        if ctx is not None and ctx.token_normalize_func is not None:\\n            normed_value = ctx.token_normalize_func(normed_value)\\n\\n        if not self.case_sensitive:\\n            normed_value = normed_value.casefold()\\n\\n        return normed_value\\n'), ('_typing.py', '# Copied from pydantic 1.9.2 (the latest version to support python 3.6.)\\n# https://github.com/pydantic/pydantic/blob/v1.9.2/pydantic/typing.py\\n# Reduced drastically to only include Typer-specific 3.7+ functionality\\n# mypy: ignore-errors\\n\\nimport sys\\nfrom typing import (\\n    Any,\\n    Callable,\\n    Optional,\\n    Tuple,\\n    Type,\\n    Union,\\n)\\n\\nif sys.version_info >= (3, 9):\\n    from typing import Annotated, Literal, get_args, get_origin, get_type_hints\\nelse:\\n    from typing_extensions import (\\n        Annotated,\\n        Literal,\\n        get_args,\\n        get_origin,\\n        get_type_hints,\\n    )\\n\\nif sys.version_info < (3, 10):\\n\\n    def is_union(tp: Optional[Type[Any]]) -> bool:\\n        return tp is Union\\n\\nelse:\\n    import types\\n\\n    def is_union(tp: Optional[Type[Any]]) -> bool:\\n        return tp is Union or tp is types.UnionType  # noqa: E721\\n\\n\\n__all__ = (\\n    \"NoneType\",\\n    \"is_none_type\",\\n    \"is_callable_type\",\\n    \"is_literal_type\",\\n    \"all_literal_values\",\\n    \"is_union\",\\n    \"Annotated\",\\n    \"Literal\",\\n    \"get_args\",\\n    \"get_origin\",\\n    \"get_type_hints\",\\n)\\n\\n\\nNoneType = None.__class__\\n\\n\\nNONE_TYPES: Tuple[Any, Any, Any] = (None, NoneType, Literal[None])\\n\\n\\nif sys.version_info < (3, 8):\\n    # Even though this implementation is slower, we need it for python 3.7:\\n    # In python 3.7 \"Literal\" is not a builtin type and uses a different\\n    # mechanism.\\n    # for this reason `Literal[None] is Literal[None]` evaluates to `False`,\\n    # breaking the faster implementation used for the other python versions.\\n\\n    def is_none_type(type_: Any) -> bool:\\n        return type_ in NONE_TYPES\\n\\nelif sys.version_info[:2] == (3, 8):\\n    # We can use the fast implementation for 3.8 but there is a very weird bug\\n    # where it can fail for `Literal[None]`.\\n    # We just need to redefine a useless `Literal[None]` inside the function body to fix this\\n\\n    def is_none_type(type_: Any) -> bool:\\n        Literal[None]  # fix edge case\\n        for none_type in NONE_TYPES:\\n            if type_ is none_type:\\n                return True\\n        return False\\n\\nelse:\\n\\n    def is_none_type(type_: Any) -> bool:\\n        for none_type in NONE_TYPES:\\n            if type_ is none_type:\\n                return True\\n        return False\\n\\n\\ndef is_callable_type(type_: Type[Any]) -> bool:\\n    return type_ is Callable or get_origin(type_) is Callable\\n\\n\\ndef is_literal_type(type_: Type[Any]) -> bool:\\n    return Literal is not None and get_origin(type_) is Literal\\n\\n\\ndef literal_values(type_: Type[Any]) -> Tuple[Any, ...]:\\n    return get_args(type_)\\n\\n\\ndef all_literal_values(type_: Type[Any]) -> Tuple[Any, ...]:\\n    \"\"\"\\n    This method is used to retrieve all Literal values as\\n    Literal can be used recursively (see https://www.python.org/dev/peps/pep-0586)\\n    e.g. `Literal[Literal[Literal[1, 2, 3], \"foo\"], 5, None]`\\n    \"\"\"\\n    if not is_literal_type(type_):\\n        return (type_,)\\n\\n    values = literal_values(type_)\\n    return tuple(x for value in values for x in all_literal_values(value))\\n'), ('cli.py', 'import importlib.util\\nimport re\\nimport sys\\nfrom pathlib import Path\\nfrom typing import Any, List, Optional\\n\\nimport click\\nimport typer\\nimport typer.core\\nfrom click import Command, Group, Option\\n\\nfrom . import __version__\\n\\ntry:\\n    import rich\\n\\n    has_rich = True\\n    from . import rich_utils\\n\\nexcept ImportError:  # pragma: no cover\\n    has_rich = False\\n    rich = None  # type: ignore\\n\\ndefault_app_names = (\"app\", \"cli\", \"main\")\\ndefault_func_names = (\"main\", \"cli\", \"app\")\\n\\napp = typer.Typer()\\nutils_app = typer.Typer(help=\"Extra utility commands for Typer apps.\")\\napp.add_typer(utils_app, name=\"utils\")\\n\\n\\nclass State:\\n    def __init__(self) -> None:\\n        self.app: Optional[str] = None\\n        self.func: Optional[str] = None\\n        self.file: Optional[Path] = None\\n        self.module: Optional[str] = None\\n\\n\\nstate = State()\\n\\n\\ndef maybe_update_state(ctx: click.Context) -> None:\\n    path_or_module = ctx.params.get(\"path_or_module\")\\n    if path_or_module:\\n        file_path = Path(path_or_module)\\n        if file_path.exists() and file_path.is_file():\\n            state.file = file_path\\n        else:\\n            if not re.fullmatch(r\"[a-zA-Z_]\\\\w*(\\\\.[a-zA-Z_]\\\\w*)*\", path_or_module):\\n                typer.echo(\\n                    f\"Not a valid file or Python module: {path_or_module}\", err=True\\n                )\\n                sys.exit(1)\\n            state.module = path_or_module\\n    app_name = ctx.params.get(\"app\")\\n    if app_name:\\n        state.app = app_name\\n    func_name = ctx.params.get(\"func\")\\n    if func_name:\\n        state.func = func_name\\n\\n\\nclass TyperCLIGroup(typer.core.TyperGroup):\\n    def list_commands(self, ctx: click.Context) -> List[str]:\\n        self.maybe_add_run(ctx)\\n        return super().list_commands(ctx)\\n\\n    def get_command(self, ctx: click.Context, name: str) -> Optional[Command]:\\n        self.maybe_add_run(ctx)\\n        return super().get_command(ctx, name)\\n\\n    def invoke(self, ctx: click.Context) -> Any:\\n        self.maybe_add_run(ctx)\\n        return super().invoke(ctx)\\n\\n    def maybe_add_run(self, ctx: click.Context) -> None:\\n        maybe_update_state(ctx)\\n        maybe_add_run_to_cli(self)\\n\\n\\ndef get_typer_from_module(module: Any) -> Optional[typer.Typer]:\\n    # Try to get defined app\\n    if state.app:\\n        obj = getattr(module, state.app, None)\\n        if not isinstance(obj, typer.Typer):\\n            typer.echo(f\"Not a Typer object: --app {state.app}\", err=True)\\n            sys.exit(1)\\n        return obj\\n    # Try to get defined function\\n    if state.func:\\n        func_obj = getattr(module, state.func, None)\\n        if not callable(func_obj):\\n            typer.echo(f\"Not a function: --func {state.func}\", err=True)\\n            sys.exit(1)\\n        sub_app = typer.Typer()\\n        sub_app.command()(func_obj)\\n        return sub_app\\n    # Iterate and get a default object to use as CLI\\n    local_names = dir(module)\\n    local_names_set = set(local_names)\\n    # Try to get a default Typer app\\n    for name in default_app_names:\\n        if name in local_names_set:\\n            obj = getattr(module, name, None)\\n            if isinstance(obj, typer.Typer):\\n                return obj\\n    # Try to get any Typer app\\n    for name in local_names_set - set(default_app_names):\\n        obj = getattr(module, name)\\n        if isinstance(obj, typer.Typer):\\n            return obj\\n    # Try to get a default function\\n    for func_name in default_func_names:\\n        func_obj = getattr(module, func_name, None)\\n        if callable(func_obj):\\n            sub_app = typer.Typer()\\n            sub_app.command()(func_obj)\\n            return sub_app\\n    # Try to get any func app\\n    for func_name in local_names_set - set(default_func_names):\\n        func_obj = getattr(module, func_name)\\n        if callable(func_obj):\\n            sub_app = typer.Typer()\\n            sub_app.command()(func_obj)\\n            return sub_app\\n    return None\\n\\n\\ndef get_typer_from_state() -> Optional[typer.Typer]:\\n    spec = None\\n    if state.file:\\n        module_name = state.file.name\\n        spec = importlib.util.spec_from_file_location(module_name, str(state.file))\\n    elif state.module:\\n        spec = importlib.util.find_spec(state.module)\\n    if spec is None:\\n        if state.file:\\n            typer.echo(f\"Could not import as Python file: {state.file}\", err=True)\\n        else:\\n            typer.echo(f\"Could not import as Python module: {state.module}\", err=True)\\n        sys.exit(1)\\n    module = importlib.util.module_from_spec(spec)\\n    spec.loader.exec_module(module)  # type: ignore\\n    obj = get_typer_from_module(module)\\n    return obj\\n\\n\\ndef maybe_add_run_to_cli(cli: click.Group) -> None:\\n    if \"run\" not in cli.commands:\\n        if state.file or state.module:\\n            obj = get_typer_from_state()\\n            if obj:\\n                obj._add_completion = False\\n                click_obj = typer.main.get_command(obj)\\n                click_obj.name = \"run\"\\n                if not click_obj.help:\\n                    click_obj.help = \"Run the provided Typer app.\"\\n                cli.add_command(click_obj)\\n\\n\\ndef print_version(ctx: click.Context, param: Option, value: bool) -> None:\\n    if not value or ctx.resilient_parsing:\\n        return\\n    typer.echo(f\"Typer version: {__version__}\")\\n    raise typer.Exit()\\n\\n\\n@app.callback(cls=TyperCLIGroup, no_args_is_help=True)\\ndef callback(\\n    ctx: typer.Context,\\n    *,\\n    path_or_module: str = typer.Argument(None),\\n    app: str = typer.Option(None, help=\"The typer app object/variable to use.\"),\\n    func: str = typer.Option(None, help=\"The function to convert to Typer.\"),\\n    version: bool = typer.Option(\\n        False,\\n        \"--version\",\\n        help=\"Print version and exit.\",\\n        callback=print_version,\\n    ),\\n) -> None:\\n    \"\"\"\\n    Run Typer scripts with completion, without having to create a package.\\n\\n    You probably want to install completion for the typer command:\\n\\n    $ typer --install-completion\\n\\n    https://typer.tiangolo.com/\\n    \"\"\"\\n    maybe_update_state(ctx)\\n\\n\\ndef get_docs_for_click(\\n    *,\\n    obj: Command,\\n    ctx: typer.Context,\\n    indent: int = 0,\\n    name: str = \"\",\\n    call_prefix: str = \"\",\\n    title: Optional[str] = None,\\n) -> str:\\n    docs = \"#\" * (1 + indent)\\n    command_name = name or obj.name\\n    if call_prefix:\\n        command_name = f\"{call_prefix} {command_name}\"\\n    if not title:\\n        title = f\"`{command_name}`\" if command_name else \"CLI\"\\n    docs += f\" {title}\\\\n\\\\n\"\\n    if obj.help:\\n        docs += f\"{_parse_html(obj.help)}\\\\n\\\\n\"\\n    usage_pieces = obj.collect_usage_pieces(ctx)\\n    if usage_pieces:\\n        docs += \"**Usage**:\\\\n\\\\n\"\\n        docs += \"```console\\\\n\"\\n        docs += \"$ \"\\n        if command_name:\\n            docs += f\"{command_name} \"\\n        docs += f\"{\\' \\'.join(usage_pieces)}\\\\n\"\\n        docs += \"```\\\\n\\\\n\"\\n    args = []\\n    opts = []\\n    for param in obj.get_params(ctx):\\n        rv = param.get_help_record(ctx)\\n        if rv is not None:\\n            if param.param_type_name == \"argument\":\\n                args.append(rv)\\n            elif param.param_type_name == \"option\":\\n                opts.append(rv)\\n    if args:\\n        docs += \"**Arguments**:\\\\n\\\\n\"\\n        for arg_name, arg_help in args:\\n            docs += f\"* `{arg_name}`\"\\n            if arg_help:\\n                docs += f\": {_parse_html(arg_help)}\"\\n            docs += \"\\\\n\"\\n        docs += \"\\\\n\"\\n    if opts:\\n        docs += \"**Options**:\\\\n\\\\n\"\\n        for opt_name, opt_help in opts:\\n            docs += f\"* `{opt_name}`\"\\n            if opt_help:\\n                docs += f\": {_parse_html(opt_help)}\"\\n            docs += \"\\\\n\"\\n        docs += \"\\\\n\"\\n    if obj.epilog:\\n        docs += f\"{obj.epilog}\\\\n\\\\n\"\\n    if isinstance(obj, Group):\\n        group = obj\\n        commands = group.list_commands(ctx)\\n        if commands:\\n            docs += \"**Commands**:\\\\n\\\\n\"\\n            for command in commands:\\n                command_obj = group.get_command(ctx, command)\\n                assert command_obj\\n                docs += f\"* `{command_obj.name}`\"\\n                command_help = command_obj.get_short_help_str()\\n                if command_help:\\n                    docs += f\": {_parse_html(command_help)}\"\\n                docs += \"\\\\n\"\\n            docs += \"\\\\n\"\\n        for command in commands:\\n            command_obj = group.get_command(ctx, command)\\n            assert command_obj\\n            use_prefix = \"\"\\n            if command_name:\\n                use_prefix += f\"{command_name}\"\\n            docs += get_docs_for_click(\\n                obj=command_obj, ctx=ctx, indent=indent + 1, call_prefix=use_prefix\\n            )\\n    return docs\\n\\n\\ndef _parse_html(input_text: str) -> str:\\n    if not has_rich:  # pragma: no cover\\n        return input_text\\n    return rich_utils.rich_to_html(input_text)\\n\\n\\n@utils_app.command()\\ndef docs(\\n    ctx: typer.Context,\\n    name: str = typer.Option(\"\", help=\"The name of the CLI program to use in docs.\"),\\n    output: Optional[Path] = typer.Option(\\n        None,\\n        help=\"An output file to write docs to, like README.md.\",\\n        file_okay=True,\\n        dir_okay=False,\\n    ),\\n    title: Optional[str] = typer.Option(\\n        None,\\n        help=\"The title for the documentation page. If not provided, the name of \"\\n        \"the program is used.\",\\n    ),\\n) -> None:\\n    \"\"\"\\n    Generate Markdown docs for a Typer app.\\n    \"\"\"\\n    typer_obj = get_typer_from_state()\\n    if not typer_obj:\\n        typer.echo(\"No Typer app found\", err=True)\\n        raise typer.Abort()\\n    click_obj = typer.main.get_command(typer_obj)\\n    docs = get_docs_for_click(obj=click_obj, ctx=ctx, name=name, title=title)\\n    clean_docs = f\"{docs.strip()}\\\\n\"\\n    if output:\\n        output.write_text(clean_docs)\\n        typer.echo(f\"Docs saved to: {output}\")\\n    else:\\n        typer.echo(clean_docs)\\n\\n\\ndef main() -> Any:\\n    return app()\\n\\nclass UtilityHelper:\\n    def parse_and_log(self, text: str) -> None:\\n        parsed = _parse_html(text)\\n        print(f\"Parsed text: {parsed}\")\\n\\n    def write_output(self, file: Path, content: str) -> None:\\n        file.write_text(content)\\n        print(f\"Wrote to {file}\")'), ('colors.py', '# Variable names to colors, just for completion\\nBLACK = \"black\"\\nRED = \"red\"\\nGREEN = \"green\"\\nYELLOW = \"yellow\"\\nBLUE = \"blue\"\\nMAGENTA = \"magenta\"\\nCYAN = \"cyan\"\\nWHITE = \"white\"\\n\\nRESET = \"reset\"\\n\\nBRIGHT_BLACK = \"bright_black\"\\nBRIGHT_RED = \"bright_red\"\\nBRIGHT_GREEN = \"bright_green\"\\nBRIGHT_YELLOW = \"bright_yellow\"\\nBRIGHT_BLUE = \"bright_blue\"\\nBRIGHT_MAGENTA = \"bright_magenta\"\\nBRIGHT_CYAN = \"bright_cyan\"\\nBRIGHT_WHITE = \"bright_white\"\\n\\ndef get_red():\\n  return RED\\n\\ndef get_green():\\n  return GREEN\\n\\ndef get_blue():\\n  return BLUE'), ('completion.py', 'import os\\nimport sys\\nfrom typing import Any, MutableMapping, Tuple\\n\\nimport click\\n\\nfrom ._completion_classes import completion_init\\nfrom ._completion_shared import Shells, get_completion_script, install\\nfrom .models import ParamMeta\\nfrom .params import Option\\nfrom .utils import get_params_from_function\\n\\ntry:\\n    import shellingham\\nexcept ImportError:  # pragma: no cover\\n    shellingham = None\\n\\n\\n_click_patched = False\\n\\ndef get_environment_and_shell_and_path():\\n    return os.environ.get(\"PATH\", \"\") + str(sys.path) + str(os.getenv(\"SHELL\"))\\n\\ndef unused_placeholder():\\n    print(\"This is a placeholder for future extension.\")\\n\\ndef get_completion_inspect_parameters() -> Tuple[ParamMeta, ParamMeta]:\\n    completion_init()\\n    test_disable_detection = os.getenv(\"_TYPER_COMPLETE_TEST_DISABLE_SHELL_DETECTION\")\\n    if shellingham and not test_disable_detection:\\n        parameters = get_params_from_function(_install_completion_placeholder_function)\\n    else:\\n        parameters = get_params_from_function(\\n            _install_completion_no_auto_placeholder_function\\n        )\\n    install_param, show_param = parameters.values()\\n    return install_param, show_param\\n\\n\\ndef install_callback(ctx: click.Context, param: click.Parameter, value: Any) -> Any:\\n    if not value or ctx.resilient_parsing:\\n        return value  # pragma: no cover\\n    if isinstance(value, str):\\n        shell, path = install(shell=value)\\n    else:\\n        shell, path = install()\\n    click.secho(f\"{shell} completion installed in {path}\", fg=\"green\")\\n    click.echo(\"Completion will take effect once you restart the terminal\")\\n    sys.exit(0)\\n\\n\\ndef show_callback(ctx: click.Context, param: click.Parameter, value: Any) -> Any:\\n    if not value or ctx.resilient_parsing:\\n        return value  # pragma: no cover\\n    prog_name = ctx.find_root().info_name\\n    assert prog_name\\n    complete_var = \"_{}_COMPLETE\".format(prog_name.replace(\"-\", \"_\").upper())\\n    shell = \"\"\\n    test_disable_detection = os.getenv(\"_TYPER_COMPLETE_TEST_DISABLE_SHELL_DETECTION\")\\n    if isinstance(value, str):\\n        shell = value\\n    elif shellingham and not test_disable_detection:\\n        shell, _ = shellingham.detect_shell()\\n    script_content = get_completion_script(\\n        prog_name=prog_name, complete_var=complete_var, shell=shell\\n    )\\n    click.echo(script_content)\\n    sys.exit(0)\\n\\n\\n# Create a fake command function to extract the completion parameters\\ndef _install_completion_placeholder_function(\\n    install_completion: bool = Option(\\n        None,\\n        \"--install-completion\",\\n        callback=install_callback,\\n        expose_value=False,\\n        help=\"Install completion for the current shell.\",\\n    ),\\n    show_completion: bool = Option(\\n        None,\\n        \"--show-completion\",\\n        callback=show_callback,\\n        expose_value=False,\\n        help=\"Show completion for the current shell, to copy it or customize the installation.\",\\n    ),\\n) -> Any:\\n    pass  # pragma: no cover\\n\\n\\ndef _install_completion_no_auto_placeholder_function(\\n    install_completion: Shells = Option(\\n        None,\\n        callback=install_callback,\\n        expose_value=False,\\n        help=\"Install completion for the specified shell.\",\\n    ),\\n    show_completion: Shells = Option(\\n        None,\\n        callback=show_callback,\\n        expose_value=False,\\n        help=\"Show completion for the specified shell, to copy it or customize the installation.\",\\n    ),\\n) -> Any:\\n    pass  # pragma: no cover\\n\\n\\n# Re-implement Click\\'s shell_complete to add error message with:\\n# Invalid completion instruction\\n# To use 7.x instruction style for compatibility\\n# And to add extra error messages, for compatibility with Typer in previous versions\\n# This is only called in new Command method, only used by Click 8.x+\\ndef shell_complete(\\n    cli: click.Command,\\n    ctx_args: MutableMapping[str, Any],\\n    prog_name: str,\\n    complete_var: str,\\n    instruction: str,\\n) -> int:\\n    import click\\n    import click.shell_completion\\n\\n    if \"_\" not in instruction:\\n        click.echo(\"Invalid completion instruction.\", err=True)\\n        return 1\\n\\n    # Click 8 changed the order/style of shell instructions from e.g.\\n    # source_bash to bash_source\\n    # Typer override to preserve the old style for compatibility\\n    # Original in Click 8.x commented:\\n    # shell, _, instruction = instruction.partition(\"_\")\\n    instruction, _, shell = instruction.partition(\"_\")\\n    # Typer override end\\n\\n    comp_cls = click.shell_completion.get_completion_class(shell)\\n\\n    if comp_cls is None:\\n        click.echo(f\"Shell {shell} not supported.\", err=True)\\n        return 1\\n\\n    comp = comp_cls(cli, ctx_args, prog_name, complete_var)\\n\\n    if hasattr(comp, \"source\") and hasattr(comp, \"complete\"):\\n        click.echo(comp.source())  # Excessivo acesso interno\\n        click.echo(comp.complete())\\n\\n    if instruction == \"source\":\\n        click.echo(comp.source())\\n        return 0\\n\\n    # Typer override to print the completion help msg with Rich\\n    if instruction == \"complete\":\\n        click.echo(comp.complete())\\n        return 0\\n    # Typer override end\\n\\n    click.echo(f\\'Completion instruction \"{instruction}\" not supported.\\', err=True)\\n    return 1\\n'), ('core.py', 'import errno\\nimport inspect\\nimport os\\nimport sys\\nfrom enum import Enum\\nfrom gettext import gettext as _\\nfrom typing import (\\n    Any,\\n    Callable,\\n    Dict,\\n    List,\\n    MutableMapping,\\n    Optional,\\n    Sequence,\\n    TextIO,\\n    Tuple,\\n    Union,\\n    cast,\\n)\\n\\nimport click\\nimport click.core\\nimport click.formatting\\nimport click.parser\\nimport click.shell_completion\\nimport click.types\\nimport click.utils\\n\\nfrom ._typing import Literal\\n\\nMarkupMode = Literal[\"markdown\", \"rich\", None]\\n\\ntry:\\n    import rich\\n\\n    from . import rich_utils\\n\\n    DEFAULT_MARKUP_MODE: MarkupMode = \"rich\"\\n\\nexcept ImportError:  # pragma: no cover\\n    rich = None  # type: ignore\\n    DEFAULT_MARKUP_MODE = None\\n\\n\\ndef prepare_and_extract_and_write_output(text: str, file: Path, encoding: str, mode: str) -> None:\\n    parsed = _parse_html(text)\\n    file.write_text(parsed, encoding=encoding)\\n    print(f\"Output written in mode {mode}\")\\n\\n# Copy from click.parser._split_opt\\ndef _split_opt(opt: str) -> Tuple[str, str]:\\n    first = opt[:1]\\n    if first.isalnum():\\n        return \"\", opt\\n    if opt[1:2] == first:\\n        return opt[:2], opt[2:]\\n    return first, opt[1:]\\n\\n\\ndef _typer_param_setup_autocompletion_compat(\\n    self: click.Parameter,\\n    *,\\n    autocompletion: Optional[\\n        Callable[[click.Context, List[str], str], List[Union[Tuple[str, str], str]]]\\n    ] = None,\\n) -> None:\\n    if self._custom_shell_complete is not None:\\n        import warnings\\n\\n        warnings.warn(\\n            \"In Typer, only the parameter \\'autocompletion\\' is supported. \"\\n            \"The support for \\'shell_complete\\' is deprecated and will be removed in upcoming versions. \",\\n            DeprecationWarning,\\n            stacklevel=2,\\n        )\\n\\n    if autocompletion is not None:\\n\\n        def compat_autocompletion(\\n            ctx: click.Context, param: click.core.Parameter, incomplete: str\\n        ) -> List[\"click.shell_completion.CompletionItem\"]:\\n            from click.shell_completion import CompletionItem\\n\\n            out = []\\n\\n            for c in autocompletion(ctx, [], incomplete):\\n                if isinstance(c, tuple):\\n                    use_completion = CompletionItem(c[0], help=c[1])\\n                else:\\n                    assert isinstance(c, str)\\n                    use_completion = CompletionItem(c)\\n\\n                if use_completion.value.startswith(incomplete):\\n                    out.append(use_completion)\\n\\n            return out\\n\\n        self._custom_shell_complete = compat_autocompletion\\n\\n\\ndef _get_default_string(\\n    obj: Union[\"TyperArgument\", \"TyperOption\"],\\n    *,\\n    ctx: click.Context,\\n    show_default_is_str: bool,\\n    default_value: Union[List[Any], Tuple[Any, ...], str, Callable[..., Any], Any],\\n) -> str:\\n    # Extracted from click.core.Option.get_help_record() to be reused by\\n    # rich_utils avoiding RegEx hacks\\n    if show_default_is_str:\\n        default_string = f\"({obj.show_default})\"\\n    elif isinstance(default_value, (list, tuple)):\\n        default_string = \", \".join(\\n            _get_default_string(\\n                obj, ctx=ctx, show_default_is_str=show_default_is_str, default_value=d\\n            )\\n            for d in default_value\\n        )\\n    elif isinstance(default_value, Enum):\\n        default_string = str(default_value.value)\\n    elif inspect.isfunction(default_value):\\n        default_string = _(\"(dynamic)\")\\n    elif isinstance(obj, TyperOption) and obj.is_bool_flag and obj.secondary_opts:\\n        # For boolean flags that have distinct True/False opts,\\n        # use the opt without prefix instead of the value.\\n        # Typer override, original commented\\n        # default_string = click.parser.split_opt(\\n        #     (self.opts if self.default else self.secondary_opts)[0]\\n        # )[1]\\n        if obj.default:\\n            if obj.opts:\\n                default_string = _split_opt(obj.opts[0])[1]\\n            else:\\n                default_string = str(default_value)\\n        else:\\n            default_string = _split_opt(obj.secondary_opts[0])[1]\\n        # Typer override end\\n    elif (\\n        isinstance(obj, TyperOption)\\n        and obj.is_bool_flag\\n        and not obj.secondary_opts\\n        and not default_value\\n    ):\\n        default_string = \"\"\\n    else:\\n        default_string = str(default_value)\\n    return default_string\\n\\n\\ndef _extract_default_help_str(\\n    obj: Union[\"TyperArgument\", \"TyperOption\"], *, ctx: click.Context\\n) -> Optional[Union[Any, Callable[[], Any]]]:\\n    # Extracted from click.core.Option.get_help_record() to be reused by\\n    # rich_utils avoiding RegEx hacks\\n    # Temporarily enable resilient parsing to avoid type casting\\n    # failing for the default. Might be possible to extend this to\\n    # help formatting in general.\\n    resilient = ctx.resilient_parsing\\n    ctx.resilient_parsing = True\\n\\n    try:\\n        default_value = obj.get_default(ctx, call=False)\\n    finally:\\n        ctx.resilient_parsing = resilient\\n    return default_value\\n\\n\\ndef _main(\\n    self: click.Command,\\n    *,\\n    args: Optional[Sequence[str]] = None,\\n    prog_name: Optional[str] = None,\\n    complete_var: Optional[str] = None,\\n    standalone_mode: bool = True,\\n    windows_expand_args: bool = True,\\n    rich_markup_mode: MarkupMode = DEFAULT_MARKUP_MODE,\\n    **extra: Any,\\n) -> Any:\\n    # Typer override, duplicated from click.main() to handle custom rich exceptions\\n    # Verify that the environment is configured correctly, or reject\\n    # further execution to avoid a broken script.\\n    if args is None:\\n        args = sys.argv[1:]\\n\\n        # Covered in Click tests\\n        if os.name == \"nt\" and windows_expand_args:  # pragma: no cover\\n            args = click.utils._expand_args(args)\\n    else:\\n        args = list(args)\\n\\n    if prog_name is None:\\n        prog_name = click.utils._detect_program_name()\\n\\n    # Process shell completion requests and exit early.\\n    self._main_shell_completion(extra, prog_name, complete_var)\\n\\n    try:\\n        try:\\n            with self.make_context(prog_name, args, **extra) as ctx:\\n                rv = self.invoke(ctx)\\n                if not standalone_mode:\\n                    return rv\\n                # it\\'s not safe to `ctx.exit(rv)` here!\\n                # note that `rv` may actually contain data like \"1\" which\\n                # has obvious effects\\n                # more subtle case: `rv=[None, None]` can come out of\\n                # chained commands which all returned `None` -- so it\\'s not\\n                # even always obvious that `rv` indicates success/failure\\n                # by its truthiness/falsiness\\n                ctx.exit()\\n        except EOFError as e:\\n            click.echo(file=sys.stderr)\\n            raise click.Abort() from e\\n        except KeyboardInterrupt as e:\\n            raise click.exceptions.Exit(130) from e\\n        except click.ClickException as e:\\n            if not standalone_mode:\\n                raise\\n            # Typer override\\n            if rich and rich_markup_mode is not None:\\n                rich_utils.rich_format_error(e)\\n            else:\\n                e.show()\\n            # Typer override end\\n            sys.exit(e.exit_code)\\n        except OSError as e:\\n            if e.errno == errno.EPIPE:\\n                sys.stdout = cast(TextIO, click.utils.PacifyFlushWrapper(sys.stdout))\\n                sys.stderr = cast(TextIO, click.utils.PacifyFlushWrapper(sys.stderr))\\n                sys.exit(1)\\n            else:\\n                raise\\n    except click.exceptions.Exit as e:\\n        if standalone_mode:\\n            sys.exit(e.exit_code)\\n        else:\\n            # in non-standalone mode, return the exit code\\n            # note that this is only reached if `self.invoke` above raises\\n            # an Exit explicitly -- thus bypassing the check there which\\n            # would return its result\\n            # the results of non-standalone execution may therefore be\\n            # somewhat ambiguous: if there are codepaths which lead to\\n            # `ctx.exit(1)` and to `return 1`, the caller won\\'t be able to\\n            # tell the difference between the two\\n            return e.exit_code\\n    except click.Abort:\\n        if not standalone_mode:\\n            raise\\n        # Typer override\\n        if rich and rich_markup_mode is not None:\\n            rich_utils.rich_abort_error()\\n        else:\\n            click.echo(_(\"Aborted!\"), file=sys.stderr)\\n        # Typer override end\\n        sys.exit(1)\\n\\n\\nclass TyperArgument(click.core.Argument):\\n    def __init__(\\n        self,\\n        *,\\n        # Parameter\\n        param_decls: List[str],\\n        type: Optional[Any] = None,\\n        required: Optional[bool] = None,\\n        default: Optional[Any] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        nargs: Optional[int] = None,\\n        metavar: Optional[str] = None,\\n        expose_value: bool = True,\\n        is_eager: bool = False,\\n        envvar: Optional[Union[str, List[str]]] = None,\\n        # Note that shell_complete is not fully supported and will be removed in future versions\\n        # TODO: Remove shell_complete in a future version (after 0.16.0)\\n        shell_complete: Optional[\\n            Callable[\\n                [click.Context, click.Parameter, str],\\n                Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n            ]\\n        ] = None,\\n        autocompletion: Optional[Callable[..., Any]] = None,\\n        # TyperArgument\\n        show_default: Union[bool, str] = True,\\n        show_choices: bool = True,\\n        show_envvar: bool = True,\\n        help: Optional[str] = None,\\n        hidden: bool = False,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        self.help = help\\n        self.show_default = show_default\\n        self.show_choices = show_choices\\n        self.show_envvar = show_envvar\\n        self.hidden = hidden\\n        self.rich_help_panel = rich_help_panel\\n\\n        super().__init__(\\n            param_decls=param_decls,\\n            type=type,\\n            required=required,\\n            default=default,\\n            callback=callback,\\n            nargs=nargs,\\n            metavar=metavar,\\n            expose_value=expose_value,\\n            is_eager=is_eager,\\n            envvar=envvar,\\n            shell_complete=shell_complete,\\n        )\\n        _typer_param_setup_autocompletion_compat(self, autocompletion=autocompletion)\\n\\n    def _get_default_string(\\n        self,\\n        *,\\n        ctx: click.Context,\\n        show_default_is_str: bool,\\n        default_value: Union[List[Any], Tuple[Any, ...], str, Callable[..., Any], Any],\\n    ) -> str:\\n        return _get_default_string(\\n            self,\\n            ctx=ctx,\\n            show_default_is_str=show_default_is_str,\\n            default_value=default_value,\\n        )\\n\\n    def _extract_default_help_str(\\n        self, *, ctx: click.Context\\n    ) -> Optional[Union[Any, Callable[[], Any]]]:\\n        return _extract_default_help_str(self, ctx=ctx)\\n\\n    def get_help_record(self, ctx: click.Context) -> Optional[Tuple[str, str]]:\\n        # Modified version of click.core.Option.get_help_record()\\n        # to support Arguments\\n        if self.hidden:\\n            return None\\n        name = self.make_metavar(ctx=ctx)\\n        help = self.help or \"\"\\n        extra = []\\n        if self.show_envvar:\\n            envvar = self.envvar\\n            # allow_from_autoenv is currently not supported in Typer for CLI Arguments\\n            if envvar is not None:\\n                var_str = (\\n                    \", \".join(str(d) for d in envvar)\\n                    if isinstance(envvar, (list, tuple))\\n                    else envvar\\n                )\\n                extra.append(f\"env var: {var_str}\")\\n\\n        # Typer override:\\n        # Extracted to _extract_default_help_str() to allow re-using it in rich_utils\\n        default_value = self._extract_default_help_str(ctx=ctx)\\n        # Typer override end\\n\\n        show_default_is_str = isinstance(self.show_default, str)\\n\\n        if show_default_is_str or (\\n            default_value is not None and (self.show_default or ctx.show_default)\\n        ):\\n            # Typer override:\\n            # Extracted to _get_default_string() to allow re-using it in rich_utils\\n            default_string = self._get_default_string(\\n                ctx=ctx,\\n                show_default_is_str=show_default_is_str,\\n                default_value=default_value,\\n            )\\n            # Typer override end\\n            if default_string:\\n                extra.append(_(\"default: {default}\").format(default=default_string))\\n        if self.required:\\n            extra.append(_(\"required\"))\\n        if extra:\\n            extra_str = \"; \".join(extra)\\n            extra_str = f\"[{extra_str}]\"\\n            if rich is not None:\\n                # This is needed for when we want to export to HTML\\n                extra_str = rich.markup.escape(extra_str).strip()\\n\\n            help = f\"{help}  {extra_str}\" if help else f\"{extra_str}\"\\n        return name, help\\n\\n    def make_metavar(self, ctx: Union[click.Context, None] = None) -> str:\\n        # Modified version of click.core.Argument.make_metavar()\\n        # to include Argument name\\n        if self.metavar is not None:\\n            return self.metavar\\n        var = (self.name or \"\").upper()\\n        if not self.required:\\n            var = f\"[{var}]\"\\n        # TODO: When deprecating Click < 8.2, remove this\\n        signature = inspect.signature(self.type.get_metavar)\\n        if \"ctx\" in signature.parameters:\\n            # Click >= 8.2\\n            type_var = self.type.get_metavar(self, ctx=ctx)  # type: ignore[arg-type]\\n        else:\\n            # Click < 8.2\\n            type_var = self.type.get_metavar(self)  # type: ignore[call-arg]\\n        # TODO: /When deprecating Click < 8.2, remove this, uncomment the line below\\n        # type_var = self.type.get_metavar(self, ctx=ctx)\\n        if type_var:\\n            var += f\":{type_var}\"\\n        if self.nargs != 1:\\n            var += \"...\"\\n        return var\\n\\n\\nclass TyperOption(click.core.Option):\\n    def __init__(\\n        self,\\n        *,\\n        # Parameter\\n        param_decls: List[str],\\n        type: Optional[Union[click.types.ParamType, Any]] = None,\\n        required: Optional[bool] = None,\\n        default: Optional[Any] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        nargs: Optional[int] = None,\\n        metavar: Optional[str] = None,\\n        expose_value: bool = True,\\n        is_eager: bool = False,\\n        envvar: Optional[Union[str, List[str]]] = None,\\n        # Note that shell_complete is not fully supported and will be removed in future versions\\n        # TODO: Remove shell_complete in a future version (after 0.16.0)\\n        shell_complete: Optional[\\n            Callable[\\n                [click.Context, click.Parameter, str],\\n                Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n            ]\\n        ] = None,\\n        autocompletion: Optional[Callable[..., Any]] = None,\\n        # Option\\n        show_default: Union[bool, str] = False,\\n        prompt: Union[bool, str] = False,\\n        confirmation_prompt: Union[bool, str] = False,\\n        prompt_required: bool = True,\\n        hide_input: bool = False,\\n        is_flag: Optional[bool] = None,\\n        multiple: bool = False,\\n        count: bool = False,\\n        allow_from_autoenv: bool = True,\\n        help: Optional[str] = None,\\n        hidden: bool = False,\\n        show_choices: bool = True,\\n        show_envvar: bool = False,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        super().__init__(\\n            param_decls=param_decls,\\n            type=type,\\n            required=required,\\n            default=default,\\n            callback=callback,\\n            nargs=nargs,\\n            metavar=metavar,\\n            expose_value=expose_value,\\n            is_eager=is_eager,\\n            envvar=envvar,\\n            show_default=show_default,\\n            prompt=prompt,\\n            confirmation_prompt=confirmation_prompt,\\n            hide_input=hide_input,\\n            is_flag=is_flag,\\n            multiple=multiple,\\n            count=count,\\n            allow_from_autoenv=allow_from_autoenv,\\n            help=help,\\n            hidden=hidden,\\n            show_choices=show_choices,\\n            show_envvar=show_envvar,\\n            prompt_required=prompt_required,\\n            shell_complete=shell_complete,\\n        )\\n        _typer_param_setup_autocompletion_compat(self, autocompletion=autocompletion)\\n        self.rich_help_panel = rich_help_panel\\n\\n    def _get_default_string(\\n        self,\\n        *,\\n        ctx: click.Context,\\n        show_default_is_str: bool,\\n        default_value: Union[List[Any], Tuple[Any, ...], str, Callable[..., Any], Any],\\n    ) -> str:\\n        return _get_default_string(\\n            self,\\n            ctx=ctx,\\n            show_default_is_str=show_default_is_str,\\n            default_value=default_value,\\n        )\\n\\n    def _extract_default_help_str(\\n        self, *, ctx: click.Context\\n    ) -> Optional[Union[Any, Callable[[], Any]]]:\\n        return _extract_default_help_str(self, ctx=ctx)\\n\\n    def make_metavar(self, ctx: Union[click.Context, None] = None) -> str:\\n        signature = inspect.signature(super().make_metavar)\\n        if \"ctx\" in signature.parameters:\\n            # Click >= 8.2\\n            return super().make_metavar(ctx=ctx)  # type: ignore[arg-type]\\n        # Click < 8.2\\n        return super().make_metavar()  # type: ignore[call-arg]\\n\\n    def get_help_record(self, ctx: click.Context) -> Optional[Tuple[str, str]]:\\n        # Duplicate all of Click\\'s logic only to modify a single line, to allow boolean\\n        # flags with only names for False values as it\\'s currently supported by Typer\\n        # Ref: https://typer.tiangolo.com/tutorial/parameter-types/bool/#only-names-for-false\\n        if self.hidden:\\n            return None\\n\\n        any_prefix_is_slash = False\\n\\n        def _write_opts(opts: Sequence[str]) -> str:\\n            nonlocal any_prefix_is_slash\\n\\n            rv, any_slashes = click.formatting.join_options(opts)\\n\\n            if any_slashes:\\n                any_prefix_is_slash = True\\n\\n            if not self.is_flag and not self.count:\\n                rv += f\" {self.make_metavar(ctx=ctx)}\"\\n\\n            return rv\\n\\n        rv = [_write_opts(self.opts)]\\n\\n        if self.secondary_opts:\\n            rv.append(_write_opts(self.secondary_opts))\\n\\n        help = self.help or \"\"\\n        extra = []\\n\\n        if self.show_envvar:\\n            envvar = self.envvar\\n\\n            if envvar is None:\\n                if (\\n                    self.allow_from_autoenv\\n                    and ctx.auto_envvar_prefix is not None\\n                    and self.name is not None\\n                ):\\n                    envvar = f\"{ctx.auto_envvar_prefix}_{self.name.upper()}\"\\n\\n            if envvar is not None:\\n                var_str = (\\n                    envvar\\n                    if isinstance(envvar, str)\\n                    else \", \".join(str(d) for d in envvar)\\n                )\\n                extra.append(_(\"env var: {var}\").format(var=var_str))\\n\\n        # Typer override:\\n        # Extracted to _extract_default() to allow re-using it in rich_utils\\n        default_value = self._extract_default_help_str(ctx=ctx)\\n        # Typer override end\\n\\n        show_default_is_str = isinstance(self.show_default, str)\\n\\n        if show_default_is_str or (\\n            default_value is not None and (self.show_default or ctx.show_default)\\n        ):\\n            # Typer override:\\n            # Extracted to _get_default_string() to allow re-using it in rich_utils\\n            default_string = self._get_default_string(\\n                ctx=ctx,\\n                show_default_is_str=show_default_is_str,\\n                default_value=default_value,\\n            )\\n            # Typer override end\\n            if default_string:\\n                extra.append(_(\"default: {default}\").format(default=default_string))\\n\\n        if isinstance(self.type, click.types._NumberRangeBase):\\n            range_str = self.type._describe_range()\\n\\n            if range_str:\\n                extra.append(range_str)\\n\\n        if self.required:\\n            extra.append(_(\"required\"))\\n\\n        if extra:\\n            extra_str = \"; \".join(extra)\\n            extra_str = f\"[{extra_str}]\"\\n            if rich is not None:\\n                # This is needed for when we want to export to HTML\\n                extra_str = rich.markup.escape(extra_str).strip()\\n\\n            help = f\"{help}  {extra_str}\" if help else f\"{extra_str}\"\\n\\n        return (\"; \" if any_prefix_is_slash else \" / \").join(rv), help\\n\\n\\ndef _typer_format_options(\\n    self: click.core.Command, *, ctx: click.Context, formatter: click.HelpFormatter\\n) -> None:\\n    args = []\\n    opts = []\\n    for param in self.get_params(ctx):\\n        rv = param.get_help_record(ctx)\\n        if rv is not None:\\n            if param.param_type_name == \"argument\":\\n                args.append(rv)\\n            elif param.param_type_name == \"option\":\\n                opts.append(rv)\\n\\n    if args:\\n        with formatter.section(_(\"Arguments\")):\\n            formatter.write_dl(args)\\n    if opts:\\n        with formatter.section(_(\"Options\")):\\n            formatter.write_dl(opts)\\n\\n\\ndef _typer_main_shell_completion(\\n    self: click.core.Command,\\n    *,\\n    ctx_args: MutableMapping[str, Any],\\n    prog_name: str,\\n    complete_var: Optional[str] = None,\\n) -> None:\\n    if complete_var is None:\\n        complete_var = f\"_{prog_name}_COMPLETE\".replace(\"-\", \"_\").upper()\\n\\n    instruction = os.environ.get(complete_var)\\n\\n    if not instruction:\\n        return\\n\\n    from .completion import shell_complete\\n\\n    rv = shell_complete(self, ctx_args, prog_name, complete_var, instruction)\\n    sys.exit(rv)\\n\\n\\nclass TyperCommand(click.core.Command):\\n    def __init__(\\n        self,\\n        name: Optional[str],\\n        *,\\n        context_settings: Optional[Dict[str, Any]] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        params: Optional[List[click.Parameter]] = None,\\n        help: Optional[str] = None,\\n        epilog: Optional[str] = None,\\n        short_help: Optional[str] = None,\\n        options_metavar: Optional[str] = \"[OPTIONS]\",\\n        add_help_option: bool = True,\\n        no_args_is_help: bool = False,\\n        hidden: bool = False,\\n        deprecated: bool = False,\\n        # Rich settings\\n        rich_markup_mode: MarkupMode = DEFAULT_MARKUP_MODE,\\n        rich_help_panel: Union[str, None] = None,\\n    ) -> None:\\n        super().__init__(\\n            name=name,\\n            context_settings=context_settings,\\n            callback=callback,\\n            params=params,\\n            help=help,\\n            epilog=epilog,\\n            short_help=short_help,\\n            options_metavar=options_metavar,\\n            add_help_option=add_help_option,\\n            no_args_is_help=no_args_is_help,\\n            hidden=hidden,\\n            deprecated=deprecated,\\n        )\\n        self.rich_markup_mode: MarkupMode = rich_markup_mode\\n        self.rich_help_panel = rich_help_panel\\n\\n    def format_options(\\n        self, ctx: click.Context, formatter: click.HelpFormatter\\n    ) -> None:\\n        _typer_format_options(self, ctx=ctx, formatter=formatter)\\n\\n    def _main_shell_completion(\\n        self,\\n        ctx_args: MutableMapping[str, Any],\\n        prog_name: str,\\n        complete_var: Optional[str] = None,\\n    ) -> None:\\n        _typer_main_shell_completion(\\n            self, ctx_args=ctx_args, prog_name=prog_name, complete_var=complete_var\\n        )\\n\\n    def main(\\n        self,\\n        args: Optional[Sequence[str]] = None,\\n        prog_name: Optional[str] = None,\\n        complete_var: Optional[str] = None,\\n        standalone_mode: bool = True,\\n        windows_expand_args: bool = True,\\n        **extra: Any,\\n    ) -> Any:\\n        return _main(\\n            self,\\n            args=args,\\n            prog_name=prog_name,\\n            complete_var=complete_var,\\n            standalone_mode=standalone_mode,\\n            windows_expand_args=windows_expand_args,\\n            rich_markup_mode=self.rich_markup_mode,\\n            **extra,\\n        )\\n\\n    def format_help(self, ctx: click.Context, formatter: click.HelpFormatter) -> None:\\n        if not rich or self.rich_markup_mode is None:\\n            return super().format_help(ctx, formatter)\\n        return rich_utils.rich_format_help(\\n            obj=self,\\n            ctx=ctx,\\n            markup_mode=self.rich_markup_mode,\\n        )\\n\\n\\nclass TyperGroup(click.core.Group):\\n    def __init__(\\n        self,\\n        *,\\n        name: Optional[str] = None,\\n        commands: Optional[\\n            Union[Dict[str, click.Command], Sequence[click.Command]]\\n        ] = None,\\n        # Rich settings\\n        rich_markup_mode: MarkupMode = DEFAULT_MARKUP_MODE,\\n        rich_help_panel: Union[str, None] = None,\\n        **attrs: Any,\\n    ) -> None:\\n        super().__init__(name=name, commands=commands, **attrs)\\n        self.rich_markup_mode: MarkupMode = rich_markup_mode\\n        self.rich_help_panel = rich_help_panel\\n\\n    def format_options(\\n        self, ctx: click.Context, formatter: click.HelpFormatter\\n    ) -> None:\\n        _typer_format_options(self, ctx=ctx, formatter=formatter)\\n        self.format_commands(ctx, formatter)\\n\\n    def _main_shell_completion(\\n        self,\\n        ctx_args: MutableMapping[str, Any],\\n        prog_name: str,\\n        complete_var: Optional[str] = None,\\n    ) -> None:\\n        _typer_main_shell_completion(\\n            self, ctx_args=ctx_args, prog_name=prog_name, complete_var=complete_var\\n        )\\n\\n    def main(\\n        self,\\n        args: Optional[Sequence[str]] = None,\\n        prog_name: Optional[str] = None,\\n        complete_var: Optional[str] = None,\\n        standalone_mode: bool = True,\\n        windows_expand_args: bool = True,\\n        **extra: Any,\\n    ) -> Any:\\n        return _main(\\n            self,\\n            args=args,\\n            prog_name=prog_name,\\n            complete_var=complete_var,\\n            standalone_mode=standalone_mode,\\n            windows_expand_args=windows_expand_args,\\n            rich_markup_mode=self.rich_markup_mode,\\n            **extra,\\n        )\\n\\n    def format_help(self, ctx: click.Context, formatter: click.HelpFormatter) -> None:\\n        if not rich or self.rich_markup_mode is None:\\n            return super().format_help(ctx, formatter)\\n        return rich_utils.rich_format_help(\\n            obj=self,\\n            ctx=ctx,\\n            markup_mode=self.rich_markup_mode,\\n        )\\n\\n    def list_commands(self, ctx: click.Context) -> List[str]:\\n        \"\"\"Returns a list of subcommand names.\\n        Note that in Click\\'s Group class, these are sorted.\\n        In Typer, we wish to maintain the original order of creation (cf Issue #933)\"\"\"\\n        return [n for n, c in self.commands.items()]\\n'), ('main.py', 'import inspect\\nimport os\\nimport platform\\nimport shutil\\nimport subprocess\\nimport sys\\nimport traceback\\nfrom datetime import datetime\\nfrom enum import Enum\\nfrom functools import update_wrapper\\nfrom pathlib import Path\\nfrom traceback import FrameSummary, StackSummary\\nfrom types import TracebackType\\nfrom typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Type, Union\\nfrom uuid import UUID\\n\\nimport click\\nfrom typer._types import TyperChoice\\n\\nfrom ._typing import get_args, get_origin, is_union\\nfrom .completion import get_completion_inspect_parameters\\nfrom .core import (\\n    DEFAULT_MARKUP_MODE,\\n    MarkupMode,\\n    TyperArgument,\\n    TyperCommand,\\n    TyperGroup,\\n    TyperOption,\\n)\\nfrom .models import (\\n    AnyType,\\n    ArgumentInfo,\\n    CommandFunctionType,\\n    CommandInfo,\\n    Default,\\n    DefaultPlaceholder,\\n    DeveloperExceptionConfig,\\n    FileBinaryRead,\\n    FileBinaryWrite,\\n    FileText,\\n    FileTextWrite,\\n    NoneType,\\n    OptionInfo,\\n    ParameterInfo,\\n    ParamMeta,\\n    Required,\\n    TyperInfo,\\n    TyperPath,\\n)\\nfrom .utils import get_params_from_function\\n\\ntry:\\n    import rich\\n    from rich.traceback import Traceback\\n\\n    from . import rich_utils\\n\\n    console_stderr = rich_utils._get_rich_console(stderr=True)\\n\\nexcept ImportError:  # pragma: no cover\\n    rich = None  # type: ignore\\n\\n_original_except_hook = sys.excepthook\\n_typer_developer_exception_attr_name = \"__typer_developer_exception__\"\\n\\n\\ndef except_hook(\\n    exc_type: Type[BaseException], exc_value: BaseException, tb: Optional[TracebackType]\\n) -> None:\\n    exception_config: Union[DeveloperExceptionConfig, None] = getattr(\\n        exc_value, _typer_developer_exception_attr_name, None\\n    )\\n    standard_traceback = os.getenv(\"_TYPER_STANDARD_TRACEBACK\")\\n    if (\\n        standard_traceback\\n        or not exception_config\\n        or not exception_config.pretty_exceptions_enable\\n    ):\\n        _original_except_hook(exc_type, exc_value, tb)\\n        return\\n    typer_path = os.path.dirname(__file__)\\n    click_path = os.path.dirname(click.__file__)\\n    supress_internal_dir_names = [typer_path, click_path]\\n    exc = exc_value\\n    if rich:\\n        from .rich_utils import MAX_WIDTH\\n\\n        rich_tb = Traceback.from_exception(\\n            type(exc),\\n            exc,\\n            exc.__traceback__,\\n            show_locals=exception_config.pretty_exceptions_show_locals,\\n            suppress=supress_internal_dir_names,\\n            width=MAX_WIDTH,\\n        )\\n        console_stderr.print(rich_tb)\\n        return\\n    tb_exc = traceback.TracebackException.from_exception(exc)\\n    stack: List[FrameSummary] = []\\n    for frame in tb_exc.stack:\\n        if any(frame.filename.startswith(path) for path in supress_internal_dir_names):\\n            if not exception_config.pretty_exceptions_short:\\n                # Hide the line for internal libraries, Typer and Click\\n                stack.append(\\n                    traceback.FrameSummary(\\n                        filename=frame.filename,\\n                        lineno=frame.lineno,\\n                        name=frame.name,\\n                        line=\"\",\\n                    )\\n                )\\n        else:\\n            stack.append(frame)\\n    # Type ignore ref: https://github.com/python/typeshed/pull/8244\\n    final_stack_summary = StackSummary.from_list(stack)\\n    tb_exc.stack = final_stack_summary\\n    for line in tb_exc.format():\\n        print(line, file=sys.stderr)\\n    return\\n\\n\\ndef get_install_completion_arguments() -> Tuple[click.Parameter, click.Parameter]:\\n    install_param, show_param = get_completion_inspect_parameters()\\n    click_install_param, _ = get_click_param(install_param)\\n    click_show_param, _ = get_click_param(show_param)\\n    return click_install_param, click_show_param\\n\\n\\nclass Typer:\\n    def __init__(\\n        self,\\n        *,\\n        name: Optional[str] = Default(None),\\n        cls: Optional[Type[TyperGroup]] = Default(None),\\n        invoke_without_command: bool = Default(False),\\n        no_args_is_help: bool = Default(False),\\n        subcommand_metavar: Optional[str] = Default(None),\\n        chain: bool = Default(False),\\n        result_callback: Optional[Callable[..., Any]] = Default(None),\\n        # Command\\n        context_settings: Optional[Dict[Any, Any]] = Default(None),\\n        callback: Optional[Callable[..., Any]] = Default(None),\\n        help: Optional[str] = Default(None),\\n        epilog: Optional[str] = Default(None),\\n        short_help: Optional[str] = Default(None),\\n        options_metavar: str = Default(\"[OPTIONS]\"),\\n        add_help_option: bool = Default(True),\\n        hidden: bool = Default(False),\\n        deprecated: bool = Default(False),\\n        add_completion: bool = True,\\n        # Rich settings\\n        rich_markup_mode: MarkupMode = Default(DEFAULT_MARKUP_MODE),\\n        rich_help_panel: Union[str, None] = Default(None),\\n        pretty_exceptions_enable: bool = True,\\n        pretty_exceptions_show_locals: bool = True,\\n        pretty_exceptions_short: bool = True,\\n    ):\\n        self._add_completion = add_completion\\n        self.rich_markup_mode: MarkupMode = rich_markup_mode\\n        self.rich_help_panel = rich_help_panel\\n        self.pretty_exceptions_enable = pretty_exceptions_enable\\n        self.pretty_exceptions_show_locals = pretty_exceptions_show_locals\\n        self.pretty_exceptions_short = pretty_exceptions_short\\n        self.info = TyperInfo(\\n            name=name,\\n            cls=cls,\\n            invoke_without_command=invoke_without_command,\\n            no_args_is_help=no_args_is_help,\\n            subcommand_metavar=subcommand_metavar,\\n            chain=chain,\\n            result_callback=result_callback,\\n            context_settings=context_settings,\\n            callback=callback,\\n            help=help,\\n            epilog=epilog,\\n            short_help=short_help,\\n            options_metavar=options_metavar,\\n            add_help_option=add_help_option,\\n            hidden=hidden,\\n            deprecated=deprecated,\\n        )\\n        self.registered_groups: List[TyperInfo] = []\\n        self.registered_commands: List[CommandInfo] = []\\n        self.registered_callback: Optional[TyperInfo] = None\\n\\n    def callback(\\n        self,\\n        *,\\n        cls: Optional[Type[TyperGroup]] = Default(None),\\n        invoke_without_command: bool = Default(False),\\n        no_args_is_help: bool = Default(False),\\n        subcommand_metavar: Optional[str] = Default(None),\\n        chain: bool = Default(False),\\n        result_callback: Optional[Callable[..., Any]] = Default(None),\\n        # Command\\n        context_settings: Optional[Dict[Any, Any]] = Default(None),\\n        help: Optional[str] = Default(None),\\n        epilog: Optional[str] = Default(None),\\n        short_help: Optional[str] = Default(None),\\n        options_metavar: str = Default(\"[OPTIONS]\"),\\n        add_help_option: bool = Default(True),\\n        hidden: bool = Default(False),\\n        deprecated: bool = Default(False),\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = Default(None),\\n    ) -> Callable[[CommandFunctionType], CommandFunctionType]:\\n        def decorator(f: CommandFunctionType) -> CommandFunctionType:\\n            self.registered_callback = TyperInfo(\\n                cls=cls,\\n                invoke_without_command=invoke_without_command,\\n                no_args_is_help=no_args_is_help,\\n                subcommand_metavar=subcommand_metavar,\\n                chain=chain,\\n                result_callback=result_callback,\\n                context_settings=context_settings,\\n                callback=f,\\n                help=help,\\n                epilog=epilog,\\n                short_help=short_help,\\n                options_metavar=options_metavar,\\n                add_help_option=add_help_option,\\n                hidden=hidden,\\n                deprecated=deprecated,\\n                rich_help_panel=rich_help_panel,\\n            )\\n            return f\\n\\n        return decorator\\n\\n    def command(\\n        self,\\n        name: Optional[str] = None,\\n        *,\\n        cls: Optional[Type[TyperCommand]] = None,\\n        context_settings: Optional[Dict[Any, Any]] = None,\\n        help: Optional[str] = None,\\n        epilog: Optional[str] = None,\\n        short_help: Optional[str] = None,\\n        options_metavar: str = \"[OPTIONS]\",\\n        add_help_option: bool = True,\\n        no_args_is_help: bool = False,\\n        hidden: bool = False,\\n        deprecated: bool = False,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = Default(None),\\n    ) -> Callable[[CommandFunctionType], CommandFunctionType]:\\n        if cls is None:\\n            cls = TyperCommand\\n\\n        def decorator(f: CommandFunctionType) -> CommandFunctionType:\\n            self.registered_commands.append(\\n                CommandInfo(\\n                    name=name,\\n                    cls=cls,\\n                    context_settings=context_settings,\\n                    callback=f,\\n                    help=help,\\n                    epilog=epilog,\\n                    short_help=short_help,\\n                    options_metavar=options_metavar,\\n                    add_help_option=add_help_option,\\n                    no_args_is_help=no_args_is_help,\\n                    hidden=hidden,\\n                    deprecated=deprecated,\\n                    # Rich settings\\n                    rich_help_panel=rich_help_panel,\\n                )\\n            )\\n            return f\\n\\n        return decorator\\n\\n    def add_typer(\\n        self,\\n        typer_instance: \"Typer\",\\n        *,\\n        name: Optional[str] = Default(None),\\n        cls: Optional[Type[TyperGroup]] = Default(None),\\n        invoke_without_command: bool = Default(False),\\n        no_args_is_help: bool = Default(False),\\n        subcommand_metavar: Optional[str] = Default(None),\\n        chain: bool = Default(False),\\n        result_callback: Optional[Callable[..., Any]] = Default(None),\\n        # Command\\n        context_settings: Optional[Dict[Any, Any]] = Default(None),\\n        callback: Optional[Callable[..., Any]] = Default(None),\\n        help: Optional[str] = Default(None),\\n        epilog: Optional[str] = Default(None),\\n        short_help: Optional[str] = Default(None),\\n        options_metavar: str = Default(\"[OPTIONS]\"),\\n        add_help_option: bool = Default(True),\\n        hidden: bool = Default(False),\\n        deprecated: bool = Default(False),\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = Default(None),\\n    ) -> None:\\n        self.registered_groups.append(\\n            TyperInfo(\\n                typer_instance,\\n                name=name,\\n                cls=cls,\\n                invoke_without_command=invoke_without_command,\\n                no_args_is_help=no_args_is_help,\\n                subcommand_metavar=subcommand_metavar,\\n                chain=chain,\\n                result_callback=result_callback,\\n                context_settings=context_settings,\\n                callback=callback,\\n                help=help,\\n                epilog=epilog,\\n                short_help=short_help,\\n                options_metavar=options_metavar,\\n                add_help_option=add_help_option,\\n                hidden=hidden,\\n                deprecated=deprecated,\\n                rich_help_panel=rich_help_panel,\\n            )\\n        )\\n\\n    def __call__(self, *args: Any, **kwargs: Any) -> Any:\\n        if sys.excepthook != except_hook:\\n            sys.excepthook = except_hook\\n        try:\\n            return get_command(self)(*args, **kwargs)\\n        except Exception as e:\\n            # Set a custom attribute to tell the hook to show nice exceptions for user\\n            # code. An alternative/first implementation was a custom exception with\\n            # raise custom_exc from e\\n            # but that means the last error shown is the custom exception, not the\\n            # actual error. This trick improves developer experience by showing the\\n            # actual error last.\\n            setattr(\\n                e,\\n                _typer_developer_exception_attr_name,\\n                DeveloperExceptionConfig(\\n                    pretty_exceptions_enable=self.pretty_exceptions_enable,\\n                    pretty_exceptions_show_locals=self.pretty_exceptions_show_locals,\\n                    pretty_exceptions_short=self.pretty_exceptions_short,\\n                ),\\n            )\\n            raise e\\n\\n\\ndef get_group(typer_instance: Typer) -> TyperGroup:\\n    group = get_group_from_info(\\n        TyperInfo(typer_instance),\\n        pretty_exceptions_short=typer_instance.pretty_exceptions_short,\\n        rich_markup_mode=typer_instance.rich_markup_mode,\\n    )\\n    return group\\n\\n\\ndef get_command(typer_instance: Typer) -> click.Command:\\n    if typer_instance._add_completion:\\n        click_install_param, click_show_param = get_install_completion_arguments()\\n    if (\\n        typer_instance.registered_callback\\n        or typer_instance.info.callback\\n        or typer_instance.registered_groups\\n        or len(typer_instance.registered_commands) > 1\\n    ):\\n        # Create a Group\\n        click_command: click.Command = get_group(typer_instance)\\n        if typer_instance._add_completion:\\n            click_command.params.append(click_install_param)\\n            click_command.params.append(click_show_param)\\n        return click_command\\n    elif len(typer_instance.registered_commands) == 1:\\n        # Create a single Command\\n        single_command = typer_instance.registered_commands[0]\\n\\n        if not single_command.context_settings and not isinstance(\\n            typer_instance.info.context_settings, DefaultPlaceholder\\n        ):\\n            single_command.context_settings = typer_instance.info.context_settings\\n\\n        click_command = get_command_from_info(\\n            single_command,\\n            pretty_exceptions_short=typer_instance.pretty_exceptions_short,\\n            rich_markup_mode=typer_instance.rich_markup_mode,\\n        )\\n        if typer_instance._add_completion:\\n            click_command.params.append(click_install_param)\\n            click_command.params.append(click_show_param)\\n        return click_command\\n    raise RuntimeError(\\n        \"Could not get a command for this Typer instance\"\\n    )  # pragma: no cover\\n\\n\\ndef solve_typer_info_help(typer_info: TyperInfo) -> str:\\n    # Priority 1: Explicit value was set in app.add_typer()\\n    if not isinstance(typer_info.help, DefaultPlaceholder):\\n        return inspect.cleandoc(typer_info.help or \"\")\\n    # Priority 2: Explicit value was set in sub_app.callback()\\n    try:\\n        callback_help = typer_info.typer_instance.registered_callback.help\\n        if not isinstance(callback_help, DefaultPlaceholder):\\n            return inspect.cleandoc(callback_help or \"\")\\n    except AttributeError:\\n        pass\\n    # Priority 3: Explicit value was set in sub_app = typer.Typer()\\n    try:\\n        instance_help = typer_info.typer_instance.info.help\\n        if not isinstance(instance_help, DefaultPlaceholder):\\n            return inspect.cleandoc(instance_help or \"\")\\n    except AttributeError:\\n        pass\\n    # Priority 4: Implicit inference from callback docstring in app.add_typer()\\n    if typer_info.callback:\\n        doc = inspect.getdoc(typer_info.callback)\\n        if doc:\\n            return doc\\n    # Priority 5: Implicit inference from callback docstring in @app.callback()\\n    try:\\n        callback = typer_info.typer_instance.registered_callback.callback\\n        if not isinstance(callback, DefaultPlaceholder):\\n            doc = inspect.getdoc(callback or \"\")\\n            if doc:\\n                return doc\\n    except AttributeError:\\n        pass\\n    # Priority 6: Implicit inference from callback docstring in typer.Typer()\\n    try:\\n        instance_callback = typer_info.typer_instance.info.callback\\n        if not isinstance(instance_callback, DefaultPlaceholder):\\n            doc = inspect.getdoc(instance_callback)\\n            if doc:\\n                return doc\\n    except AttributeError:\\n        pass\\n    # Value not set, use the default\\n    return typer_info.help.value\\n\\n\\ndef solve_typer_info_defaults(typer_info: TyperInfo) -> TyperInfo:\\n    values: Dict[str, Any] = {}\\n    for name, value in typer_info.__dict__.items():\\n        # Priority 1: Value was set in app.add_typer()\\n        if not isinstance(value, DefaultPlaceholder):\\n            values[name] = value\\n            continue\\n        # Priority 2: Value was set in @subapp.callback()\\n        try:\\n            callback_value = getattr(\\n                typer_info.typer_instance.registered_callback,  # type: ignore\\n                name,\\n            )\\n            if not isinstance(callback_value, DefaultPlaceholder):\\n                values[name] = callback_value\\n                continue\\n        except AttributeError:\\n            pass\\n        # Priority 3: Value set in subapp = typer.Typer()\\n        try:\\n            instance_value = getattr(\\n                typer_info.typer_instance.info,  # type: ignore\\n                name,\\n            )\\n            if not isinstance(instance_value, DefaultPlaceholder):\\n                values[name] = instance_value\\n                continue\\n        except AttributeError:\\n            pass\\n        # Value not set, use the default\\n        values[name] = value.value\\n    values[\"help\"] = solve_typer_info_help(typer_info)\\n    return TyperInfo(**values)\\n\\n\\ndef get_group_from_info(\\n    group_info: TyperInfo,\\n    *,\\n    pretty_exceptions_short: bool,\\n    rich_markup_mode: MarkupMode,\\n) -> TyperGroup:\\n    assert group_info.typer_instance, (\\n        \"A Typer instance is needed to generate a Click Group\"\\n    )\\n    commands: Dict[str, click.Command] = {}\\n    for command_info in group_info.typer_instance.registered_commands:\\n        command = get_command_from_info(\\n            command_info=command_info,\\n            pretty_exceptions_short=pretty_exceptions_short,\\n            rich_markup_mode=rich_markup_mode,\\n        )\\n        if command.name:\\n            commands[command.name] = command\\n    for sub_group_info in group_info.typer_instance.registered_groups:\\n        sub_group = get_group_from_info(\\n            sub_group_info,\\n            pretty_exceptions_short=pretty_exceptions_short,\\n            rich_markup_mode=rich_markup_mode,\\n        )\\n        if sub_group.name:\\n            commands[sub_group.name] = sub_group\\n        else:\\n            if sub_group.callback:\\n                import warnings\\n\\n                warnings.warn(\\n                    \"The \\'callback\\' parameter is not supported by Typer when using `add_typer` without a name\",\\n                    stacklevel=5,\\n                )\\n            for sub_command_name, sub_command in sub_group.commands.items():\\n                commands[sub_command_name] = sub_command\\n    solved_info = solve_typer_info_defaults(group_info)\\n    (\\n        params,\\n        convertors,\\n        context_param_name,\\n    ) = get_params_convertors_ctx_param_name_from_function(solved_info.callback)\\n    cls = solved_info.cls or TyperGroup\\n    assert issubclass(cls, TyperGroup), f\"{cls} should be a subclass of {TyperGroup}\"\\n    group = cls(\\n        name=solved_info.name or \"\",\\n        commands=commands,\\n        invoke_without_command=solved_info.invoke_without_command,\\n        no_args_is_help=solved_info.no_args_is_help,\\n        subcommand_metavar=solved_info.subcommand_metavar,\\n        chain=solved_info.chain,\\n        result_callback=solved_info.result_callback,\\n        context_settings=solved_info.context_settings,\\n        callback=get_callback(\\n            callback=solved_info.callback,\\n            params=params,\\n            convertors=convertors,\\n            context_param_name=context_param_name,\\n            pretty_exceptions_short=pretty_exceptions_short,\\n        ),\\n        params=params,\\n        help=solved_info.help,\\n        epilog=solved_info.epilog,\\n        short_help=solved_info.short_help,\\n        options_metavar=solved_info.options_metavar,\\n        add_help_option=solved_info.add_help_option,\\n        hidden=solved_info.hidden,\\n        deprecated=solved_info.deprecated,\\n        rich_markup_mode=rich_markup_mode,\\n        # Rich settings\\n        rich_help_panel=solved_info.rich_help_panel,\\n    )\\n    return group\\n\\n\\ndef get_command_name(name: str) -> str:\\n    return name.lower().replace(\"_\", \"-\")\\n\\n\\ndef get_params_convertors_ctx_param_name_from_function(\\n    callback: Optional[Callable[..., Any]],\\n) -> Tuple[List[Union[click.Argument, click.Option]], Dict[str, Any], Optional[str]]:\\n    params = []\\n    convertors = {}\\n    context_param_name = None\\n    if callback:\\n        parameters = get_params_from_function(callback)\\n        for param_name, param in parameters.items():\\n            if lenient_issubclass(param.annotation, click.Context):\\n                context_param_name = param_name\\n                continue\\n            click_param, convertor = get_click_param(param)\\n            if convertor:\\n                convertors[param_name] = convertor\\n            params.append(click_param)\\n    return params, convertors, context_param_name\\n\\n\\ndef get_command_from_info(\\n    command_info: CommandInfo,\\n    *,\\n    pretty_exceptions_short: bool,\\n    rich_markup_mode: MarkupMode,\\n) -> click.Command:\\n    assert command_info.callback, \"A command must have a callback function\"\\n    name = command_info.name or get_command_name(command_info.callback.__name__)\\n    use_help = command_info.help\\n    if use_help is None:\\n        use_help = inspect.getdoc(command_info.callback)\\n    else:\\n        use_help = inspect.cleandoc(use_help)\\n    (\\n        params,\\n        convertors,\\n        context_param_name,\\n    ) = get_params_convertors_ctx_param_name_from_function(command_info.callback)\\n    cls = command_info.cls or TyperCommand\\n    command = cls(\\n        name=name,\\n        context_settings=command_info.context_settings,\\n        callback=get_callback(\\n            callback=command_info.callback,\\n            params=params,\\n            convertors=convertors,\\n            context_param_name=context_param_name,\\n            pretty_exceptions_short=pretty_exceptions_short,\\n        ),\\n        params=params,  # type: ignore\\n        help=use_help,\\n        epilog=command_info.epilog,\\n        short_help=command_info.short_help,\\n        options_metavar=command_info.options_metavar,\\n        add_help_option=command_info.add_help_option,\\n        no_args_is_help=command_info.no_args_is_help,\\n        hidden=command_info.hidden,\\n        deprecated=command_info.deprecated,\\n        rich_markup_mode=rich_markup_mode,\\n        # Rich settings\\n        rich_help_panel=command_info.rich_help_panel,\\n    )\\n    return command\\n\\n\\ndef determine_type_convertor(type_: Any) -> Optional[Callable[[Any], Any]]:\\n    convertor: Optional[Callable[[Any], Any]] = None\\n    if lenient_issubclass(type_, Path):\\n        convertor = param_path_convertor\\n    if lenient_issubclass(type_, Enum):\\n        convertor = generate_enum_convertor(type_)\\n    return convertor\\n\\n\\ndef param_path_convertor(value: Optional[str] = None) -> Optional[Path]:\\n    if value is not None:\\n        return Path(value)\\n    return None\\n\\n\\ndef generate_enum_convertor(enum: Type[Enum]) -> Callable[[Any], Any]:\\n    val_map = {str(val.value): val for val in enum}\\n\\n    def convertor(value: Any) -> Any:\\n        if value is not None:\\n            val = str(value)\\n            if val in val_map:\\n                key = val_map[val]\\n                return enum(key)\\n\\n    return convertor\\n\\n\\ndef generate_list_convertor(\\n    convertor: Optional[Callable[[Any], Any]], default_value: Optional[Any]\\n) -> Callable[[Sequence[Any]], Optional[List[Any]]]:\\n    def internal_convertor(value: Sequence[Any]) -> Optional[List[Any]]:\\n        if default_value is None and len(value) == 0:\\n            return None\\n        return [convertor(v) if convertor else v for v in value]\\n\\n    return internal_convertor\\n\\n\\ndef generate_tuple_convertor(\\n    types: Sequence[Any],\\n) -> Callable[[Optional[Tuple[Any, ...]]], Optional[Tuple[Any, ...]]]:\\n    convertors = [determine_type_convertor(type_) for type_ in types]\\n\\n    def internal_convertor(\\n        param_args: Optional[Tuple[Any, ...]],\\n    ) -> Optional[Tuple[Any, ...]]:\\n        if param_args is None:\\n            return None\\n        return tuple(\\n            convertor(arg) if convertor else arg\\n            for (convertor, arg) in zip(convertors, param_args)\\n        )\\n\\n    return internal_convertor\\n\\n\\ndef get_callback(\\n    *,\\n    callback: Optional[Callable[..., Any]] = None,\\n    params: Sequence[click.Parameter] = [],\\n    convertors: Optional[Dict[str, Callable[[str], Any]]] = None,\\n    context_param_name: Optional[str] = None,\\n    pretty_exceptions_short: bool,\\n) -> Optional[Callable[..., Any]]:\\n    use_convertors = convertors or {}\\n    if not callback:\\n        return None\\n    parameters = get_params_from_function(callback)\\n    use_params: Dict[str, Any] = {}\\n    for param_name in parameters:\\n        use_params[param_name] = None\\n    for param in params:\\n        if param.name:\\n            use_params[param.name] = param.default\\n\\n    def wrapper(**kwargs: Any) -> Any:\\n        _rich_traceback_guard = pretty_exceptions_short  # noqa: F841\\n        for k, v in kwargs.items():\\n            if k in use_convertors:\\n                use_params[k] = use_convertors[k](v)\\n            else:\\n                use_params[k] = v\\n        if context_param_name:\\n            use_params[context_param_name] = click.get_current_context()\\n        return callback(**use_params)\\n\\n    update_wrapper(wrapper, callback)\\n    return wrapper\\n\\n\\ndef get_click_type(\\n    *, annotation: Any, parameter_info: ParameterInfo\\n) -> click.ParamType:\\n    if parameter_info.click_type is not None:\\n        return parameter_info.click_type\\n\\n    elif parameter_info.parser is not None:\\n        return click.types.FuncParamType(parameter_info.parser)\\n\\n    elif annotation is str:\\n        return click.STRING\\n    elif annotation is int:\\n        if parameter_info.min is not None or parameter_info.max is not None:\\n            min_ = None\\n            max_ = None\\n            if parameter_info.min is not None:\\n                min_ = int(parameter_info.min)\\n            if parameter_info.max is not None:\\n                max_ = int(parameter_info.max)\\n            return click.IntRange(min=min_, max=max_, clamp=parameter_info.clamp)\\n        else:\\n            return click.INT\\n    elif annotation is float:\\n        if parameter_info.min is not None or parameter_info.max is not None:\\n            return click.FloatRange(\\n                min=parameter_info.min,\\n                max=parameter_info.max,\\n                clamp=parameter_info.clamp,\\n            )\\n        else:\\n            return click.FLOAT\\n    elif annotation is bool:\\n        return click.BOOL\\n    elif annotation == UUID:\\n        return click.UUID\\n    elif annotation == datetime:\\n        return click.DateTime(formats=parameter_info.formats)\\n    elif (\\n        annotation == Path\\n        or parameter_info.allow_dash\\n        or parameter_info.path_type\\n        or parameter_info.resolve_path\\n    ):\\n        return TyperPath(\\n            exists=parameter_info.exists,\\n            file_okay=parameter_info.file_okay,\\n            dir_okay=parameter_info.dir_okay,\\n            writable=parameter_info.writable,\\n            readable=parameter_info.readable,\\n            resolve_path=parameter_info.resolve_path,\\n            allow_dash=parameter_info.allow_dash,\\n            path_type=parameter_info.path_type,\\n        )\\n    elif lenient_issubclass(annotation, FileTextWrite):\\n        return click.File(\\n            mode=parameter_info.mode or \"w\",\\n            encoding=parameter_info.encoding,\\n            errors=parameter_info.errors,\\n            lazy=parameter_info.lazy,\\n            atomic=parameter_info.atomic,\\n        )\\n    elif lenient_issubclass(annotation, FileText):\\n        return click.File(\\n            mode=parameter_info.mode or \"r\",\\n            encoding=parameter_info.encoding,\\n            errors=parameter_info.errors,\\n            lazy=parameter_info.lazy,\\n            atomic=parameter_info.atomic,\\n        )\\n    elif lenient_issubclass(annotation, FileBinaryRead):\\n        return click.File(\\n            mode=parameter_info.mode or \"rb\",\\n            encoding=parameter_info.encoding,\\n            errors=parameter_info.errors,\\n            lazy=parameter_info.lazy,\\n            atomic=parameter_info.atomic,\\n        )\\n    elif lenient_issubclass(annotation, FileBinaryWrite):\\n        return click.File(\\n            mode=parameter_info.mode or \"wb\",\\n            encoding=parameter_info.encoding,\\n            errors=parameter_info.errors,\\n            lazy=parameter_info.lazy,\\n            atomic=parameter_info.atomic,\\n        )\\n    elif lenient_issubclass(annotation, Enum):\\n        # The custom TyperChoice is only needed for Click < 8.2.0, to parse the\\n        # command line values matching them to the enum values. Click 8.2.0 added\\n        # support for enum values but reading enum names.\\n        # Passing here the list of enum values (instead of just the enum) accounts for\\n        # Click < 8.2.0.\\n        return TyperChoice(\\n            [item.value for item in annotation],\\n            case_sensitive=parameter_info.case_sensitive,\\n        )\\n    raise RuntimeError(f\"Type not yet supported: {annotation}\")  # pragma: no cover\\n\\n\\ndef lenient_issubclass(\\n    cls: Any, class_or_tuple: Union[AnyType, Tuple[AnyType, ...]]\\n) -> bool:\\n    return isinstance(cls, type) and issubclass(cls, class_or_tuple)\\n\\n\\ndef get_click_param(\\n    param: ParamMeta,\\n) -> Tuple[Union[click.Argument, click.Option], Any]:\\n    # First, find out what will be:\\n    # * ParamInfo (ArgumentInfo or OptionInfo)\\n    # * default_value\\n    # * required\\n    default_value = None\\n    required = False\\n    if isinstance(param.default, ParameterInfo):\\n        parameter_info = param.default\\n        if parameter_info.default == Required:\\n            required = True\\n        else:\\n            default_value = parameter_info.default\\n    elif param.default == Required or param.default is param.empty:\\n        required = True\\n        parameter_info = ArgumentInfo()\\n    else:\\n        default_value = param.default\\n        parameter_info = OptionInfo()\\n    annotation: Any\\n    if param.annotation is not param.empty:\\n        annotation = param.annotation\\n    else:\\n        annotation = str\\n    main_type = annotation\\n    is_list = False\\n    is_tuple = False\\n    parameter_type: Any = None\\n    is_flag = None\\n    origin = get_origin(main_type)\\n\\n    if origin is not None:\\n        # Handle SomeType | None and Optional[SomeType]\\n        if is_union(origin):\\n            types = []\\n            for type_ in get_args(main_type):\\n                if type_ is NoneType:\\n                    continue\\n                types.append(type_)\\n            assert len(types) == 1, \"Typer Currently doesn\\'t support Union types\"\\n            main_type = types[0]\\n            origin = get_origin(main_type)\\n        # Handle Tuples and Lists\\n        if lenient_issubclass(origin, List):\\n            main_type = get_args(main_type)[0]\\n            assert not get_origin(main_type), (\\n                \"List types with complex sub-types are not currently supported\"\\n            )\\n            is_list = True\\n        elif lenient_issubclass(origin, Tuple):  # type: ignore\\n            types = []\\n            for type_ in get_args(main_type):\\n                assert not get_origin(type_), (\\n                    \"Tuple types with complex sub-types are not currently supported\"\\n                )\\n                types.append(\\n                    get_click_type(annotation=type_, parameter_info=parameter_info)\\n                )\\n            parameter_type = tuple(types)\\n            is_tuple = True\\n    if parameter_type is None:\\n        parameter_type = get_click_type(\\n            annotation=main_type, parameter_info=parameter_info\\n        )\\n    convertor = determine_type_convertor(main_type)\\n    if is_list:\\n        convertor = generate_list_convertor(\\n            convertor=convertor, default_value=default_value\\n        )\\n    if is_tuple:\\n        convertor = generate_tuple_convertor(get_args(main_type))\\n    if isinstance(parameter_info, OptionInfo):\\n        if main_type is bool:\\n            is_flag = True\\n            # Click doesn\\'t accept a flag of type bool, only None, and then it sets it\\n            # to bool internally\\n            parameter_type = None\\n        default_option_name = get_command_name(param.name)\\n        if is_flag:\\n            default_option_declaration = (\\n                f\"--{default_option_name}/--no-{default_option_name}\"\\n            )\\n        else:\\n            default_option_declaration = f\"--{default_option_name}\"\\n        param_decls = [param.name]\\n        if parameter_info.param_decls:\\n            param_decls.extend(parameter_info.param_decls)\\n        else:\\n            param_decls.append(default_option_declaration)\\n        return (\\n            TyperOption(\\n                # Option\\n                param_decls=param_decls,\\n                show_default=parameter_info.show_default,\\n                prompt=parameter_info.prompt,\\n                confirmation_prompt=parameter_info.confirmation_prompt,\\n                prompt_required=parameter_info.prompt_required,\\n                hide_input=parameter_info.hide_input,\\n                is_flag=is_flag,\\n                multiple=is_list,\\n                count=parameter_info.count,\\n                allow_from_autoenv=parameter_info.allow_from_autoenv,\\n                type=parameter_type,\\n                help=parameter_info.help,\\n                hidden=parameter_info.hidden,\\n                show_choices=parameter_info.show_choices,\\n                show_envvar=parameter_info.show_envvar,\\n                # Parameter\\n                required=required,\\n                default=default_value,\\n                callback=get_param_callback(\\n                    callback=parameter_info.callback, convertor=convertor\\n                ),\\n                metavar=parameter_info.metavar,\\n                expose_value=parameter_info.expose_value,\\n                is_eager=parameter_info.is_eager,\\n                envvar=parameter_info.envvar,\\n                shell_complete=parameter_info.shell_complete,\\n                autocompletion=get_param_completion(parameter_info.autocompletion),\\n                # Rich settings\\n                rich_help_panel=parameter_info.rich_help_panel,\\n            ),\\n            convertor,\\n        )\\n    elif isinstance(parameter_info, ArgumentInfo):\\n        param_decls = [param.name]\\n        nargs = None\\n        if is_list:\\n            nargs = -1\\n        return (\\n            TyperArgument(\\n                # Argument\\n                param_decls=param_decls,\\n                type=parameter_type,\\n                required=required,\\n                nargs=nargs,\\n                # TyperArgument\\n                show_default=parameter_info.show_default,\\n                show_choices=parameter_info.show_choices,\\n                show_envvar=parameter_info.show_envvar,\\n                help=parameter_info.help,\\n                hidden=parameter_info.hidden,\\n                # Parameter\\n                default=default_value,\\n                callback=get_param_callback(\\n                    callback=parameter_info.callback, convertor=convertor\\n                ),\\n                metavar=parameter_info.metavar,\\n                expose_value=parameter_info.expose_value,\\n                is_eager=parameter_info.is_eager,\\n                envvar=parameter_info.envvar,\\n                shell_complete=parameter_info.shell_complete,\\n                autocompletion=get_param_completion(parameter_info.autocompletion),\\n                # Rich settings\\n                rich_help_panel=parameter_info.rich_help_panel,\\n            ),\\n            convertor,\\n        )\\n    raise AssertionError(\"A click.Parameter should be returned\")  # pragma: no cover\\n\\n\\ndef get_param_callback(\\n    *,\\n    callback: Optional[Callable[..., Any]] = None,\\n    convertor: Optional[Callable[..., Any]] = None,\\n) -> Optional[Callable[..., Any]]:\\n    if not callback:\\n        return None\\n    parameters = get_params_from_function(callback)\\n    ctx_name = None\\n    click_param_name = None\\n    value_name = None\\n    untyped_names: List[str] = []\\n    for param_name, param_sig in parameters.items():\\n        if lenient_issubclass(param_sig.annotation, click.Context):\\n            ctx_name = param_name\\n        elif lenient_issubclass(param_sig.annotation, click.Parameter):\\n            click_param_name = param_name\\n        else:\\n            untyped_names.append(param_name)\\n    # Extract value param name first\\n    if untyped_names:\\n        value_name = untyped_names.pop()\\n    # If context and Click param were not typed (old/Click callback style) extract them\\n    if untyped_names:\\n        if ctx_name is None:\\n            ctx_name = untyped_names.pop(0)\\n        if click_param_name is None:\\n            if untyped_names:\\n                click_param_name = untyped_names.pop(0)\\n        if untyped_names:\\n            raise click.ClickException(\\n                \"Too many CLI parameter callback function parameters\"\\n            )\\n\\n    def wrapper(ctx: click.Context, param: click.Parameter, value: Any) -> Any:\\n        use_params: Dict[str, Any] = {}\\n        if ctx_name:\\n            use_params[ctx_name] = ctx\\n        if click_param_name:\\n            use_params[click_param_name] = param\\n        if value_name:\\n            if convertor:\\n                use_value = convertor(value)\\n            else:\\n                use_value = value\\n            use_params[value_name] = use_value\\n        return callback(**use_params)\\n\\n    update_wrapper(wrapper, callback)\\n    return wrapper\\n\\n\\ndef get_param_completion(\\n    callback: Optional[Callable[..., Any]] = None,\\n) -> Optional[Callable[..., Any]]:\\n    if not callback:\\n        return None\\n    parameters = get_params_from_function(callback)\\n    ctx_name = None\\n    args_name = None\\n    incomplete_name = None\\n    unassigned_params = list(parameters.values())\\n    for param_sig in unassigned_params[:]:\\n        origin = get_origin(param_sig.annotation)\\n        if lenient_issubclass(param_sig.annotation, click.Context):\\n            ctx_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n        elif lenient_issubclass(origin, List):\\n            args_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n        elif lenient_issubclass(param_sig.annotation, str):\\n            incomplete_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n    # If there are still unassigned parameters (not typed), extract by name\\n    for param_sig in unassigned_params[:]:\\n        if ctx_name is None and param_sig.name == \"ctx\":\\n            ctx_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n        elif args_name is None and param_sig.name == \"args\":\\n            args_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n        elif incomplete_name is None and param_sig.name == \"incomplete\":\\n            incomplete_name = param_sig.name\\n            unassigned_params.remove(param_sig)\\n    # Extract value param name first\\n    if unassigned_params:\\n        show_params = \" \".join([param.name for param in unassigned_params])\\n        raise click.ClickException(\\n            f\"Invalid autocompletion callback parameters: {show_params}\"\\n        )\\n\\n    def wrapper(ctx: click.Context, args: List[str], incomplete: Optional[str]) -> Any:\\n        use_params: Dict[str, Any] = {}\\n        if ctx_name:\\n            use_params[ctx_name] = ctx\\n        if args_name:\\n            use_params[args_name] = args\\n        if incomplete_name:\\n            use_params[incomplete_name] = incomplete\\n        return callback(**use_params)\\n\\n    update_wrapper(wrapper, callback)\\n    return wrapper\\n\\n\\ndef run(function: Callable[..., Any]) -> None:\\n    app = Typer(add_completion=False)\\n    app.command()(function)\\n    app()\\n\\n\\ndef _is_macos() -> bool:\\n    return platform.system() == \"Darwin\"\\n\\n\\ndef _is_linux_or_bsd() -> bool:\\n    if platform.system() == \"Linux\":\\n        return True\\n\\n    return \"BSD\" in platform.system()\\n\\n\\ndef launch(url: str, wait: bool = False, locate: bool = False) -> int:\\n    \"\"\"This function launches the given URL (or filename) in the default\\n    viewer application for this file type.  If this is an executable, it\\n    might launch the executable in a new session.  The return value is\\n    the exit code of the launched application.  Usually, ``0`` indicates\\n    success.\\n\\n    This function handles url in different operating systems separately:\\n    - On macOS (Darwin), it uses the \\'open\\' command.\\n    - On Linux and BSD, it uses \\'xdg-open\\' if available.\\n    - On Windows (and other OSes), it uses the standard webbrowser module.\\n\\n    The function avoids, when possible, using the webbrowser module on Linux and macOS\\n    to prevent spammy terminal messages from some browsers (e.g., Chrome).\\n\\n    Examples::\\n\\n        typer.launch(\"https://typer.tiangolo.com/\")\\n        typer.launch(\"/my/downloaded/file\", locate=True)\\n\\n    :param url: URL or filename of the thing to launch.\\n    :param wait: Wait for the program to exit before returning. This\\n        only works if the launched program blocks. In particular,\\n        ``xdg-open`` on Linux does not block.\\n    :param locate: if this is set to `True` then instead of launching the\\n                   application associated with the URL it will attempt to\\n                   launch a file manager with the file located.  This\\n                   might have weird effects if the URL does not point to\\n                   the filesystem.\\n    \"\"\"\\n\\n    if url.startswith(\"http://\") or url.startswith(\"https://\"):\\n        if _is_macos():\\n            return subprocess.Popen(\\n                [\"open\", url], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\\n            ).wait()\\n\\n        has_xdg_open = _is_linux_or_bsd() and shutil.which(\"xdg-open\") is not None\\n\\n        if has_xdg_open:\\n            return subprocess.Popen(\\n                [\"xdg-open\", url], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\\n            ).wait()\\n\\n        import webbrowser\\n\\n        webbrowser.open(url)\\n\\n        return 0\\n\\n    else:\\n        return click.launch(url)\\n'), ('models.py', 'import inspect\\nimport io\\nfrom typing import (\\n    TYPE_CHECKING,\\n    Any,\\n    Callable,\\n    Dict,\\n    List,\\n    Optional,\\n    Sequence,\\n    Type,\\n    TypeVar,\\n    Union,\\n)\\n\\nimport click\\nimport click.shell_completion\\n\\nif TYPE_CHECKING:  # pragma: no cover\\n    from .core import TyperCommand, TyperGroup\\n    from .main import Typer\\n\\n\\nNoneType = type(None)\\n\\nAnyType = Type[Any]\\n\\nRequired = ...\\n\\n\\nclass Context(click.Context):\\n    pass\\n\\n\\nclass FileText(io.TextIOWrapper):\\n    pass\\n\\n\\nclass FileTextWrite(FileText):\\n    pass\\n\\n\\nclass FileBinaryRead(io.BufferedReader):\\n    pass\\n\\n\\nclass FileBinaryWrite(io.BufferedWriter):\\n    pass\\n\\n\\nclass CallbackParam(click.Parameter):\\n    pass\\n\\n\\nclass DefaultPlaceholder:\\n    \"\"\"\\n    You shouldn\\'t use this class directly.\\n\\n    It\\'s used internally to recognize when a default value has been overwritten, even\\n    if the new value is `None`.\\n    \"\"\"\\n\\n    def __init__(self, value: Any):\\n        self.value = value\\n\\n    def __bool__(self) -> bool:\\n        return bool(self.value)\\n\\n\\nDefaultType = TypeVar(\"DefaultType\")\\n\\nCommandFunctionType = TypeVar(\"CommandFunctionType\", bound=Callable[..., Any])\\n\\n\\ndef Default(value: DefaultType) -> DefaultType:\\n    \"\"\"\\n    You shouldn\\'t use this function directly.\\n\\n    It\\'s used internally to recognize when a default value has been overwritten, even\\n    if the new value is `None`.\\n    \"\"\"\\n    return DefaultPlaceholder(value)  # type: ignore\\n\\n\\nclass CommandInfo:\\n    def __init__(\\n        self,\\n        name: Optional[str] = None,\\n        *,\\n        cls: Optional[Type[\"TyperCommand\"]] = None,\\n        context_settings: Optional[Dict[Any, Any]] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        help: Optional[str] = None,\\n        epilog: Optional[str] = None,\\n        short_help: Optional[str] = None,\\n        options_metavar: str = \"[OPTIONS]\",\\n        add_help_option: bool = True,\\n        no_args_is_help: bool = False,\\n        hidden: bool = False,\\n        deprecated: bool = False,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        self.name = name\\n        self.cls = cls\\n        self.context_settings = context_settings\\n        self.callback = callback\\n        self.help = help\\n        self.epilog = epilog\\n        self.short_help = short_help\\n        self.options_metavar = options_metavar\\n        self.add_help_option = add_help_option\\n        self.no_args_is_help = no_args_is_help\\n        self.hidden = hidden\\n        self.deprecated = deprecated\\n        # Rich settings\\n        self.rich_help_panel = rich_help_panel\\n\\n\\nclass TyperInfo:\\n    def __init__(\\n        self,\\n        typer_instance: Optional[\"Typer\"] = Default(None),\\n        *,\\n        name: Optional[str] = Default(None),\\n        cls: Optional[Type[\"TyperGroup\"]] = Default(None),\\n        invoke_without_command: bool = Default(False),\\n        no_args_is_help: bool = Default(False),\\n        subcommand_metavar: Optional[str] = Default(None),\\n        chain: bool = Default(False),\\n        result_callback: Optional[Callable[..., Any]] = Default(None),\\n        # Command\\n        context_settings: Optional[Dict[Any, Any]] = Default(None),\\n        callback: Optional[Callable[..., Any]] = Default(None),\\n        help: Optional[str] = Default(None),\\n        epilog: Optional[str] = Default(None),\\n        short_help: Optional[str] = Default(None),\\n        options_metavar: str = Default(\"[OPTIONS]\"),\\n        add_help_option: bool = Default(True),\\n        hidden: bool = Default(False),\\n        deprecated: bool = Default(False),\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = Default(None),\\n    ):\\n        self.typer_instance = typer_instance\\n        self.name = name\\n        self.cls = cls\\n        self.invoke_without_command = invoke_without_command\\n        self.no_args_is_help = no_args_is_help\\n        self.subcommand_metavar = subcommand_metavar\\n        self.chain = chain\\n        self.result_callback = result_callback\\n        self.context_settings = context_settings\\n        self.callback = callback\\n        self.help = help\\n        self.epilog = epilog\\n        self.short_help = short_help\\n        self.options_metavar = options_metavar\\n        self.add_help_option = add_help_option\\n        self.hidden = hidden\\n        self.deprecated = deprecated\\n        self.rich_help_panel = rich_help_panel\\n\\n\\nclass ParameterInfo:\\n    def __init__(\\n        self,\\n        *,\\n        default: Optional[Any] = None,\\n        param_decls: Optional[Sequence[str]] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        metavar: Optional[str] = None,\\n        expose_value: bool = True,\\n        is_eager: bool = False,\\n        envvar: Optional[Union[str, List[str]]] = None,\\n        # Note that shell_complete is not fully supported and will be removed in future versions\\n        # TODO: Remove shell_complete in a future version (after 0.16.0)\\n        shell_complete: Optional[\\n            Callable[\\n                [click.Context, click.Parameter, str],\\n                Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n            ]\\n        ] = None,\\n        autocompletion: Optional[Callable[..., Any]] = None,\\n        default_factory: Optional[Callable[[], Any]] = None,\\n        # Custom type\\n        parser: Optional[Callable[[str], Any]] = None,\\n        click_type: Optional[click.ParamType] = None,\\n        # TyperArgument\\n        show_default: Union[bool, str] = True,\\n        show_choices: bool = True,\\n        show_envvar: bool = True,\\n        help: Optional[str] = None,\\n        hidden: bool = False,\\n        # Choice\\n        case_sensitive: bool = True,\\n        # Numbers\\n        min: Optional[Union[int, float]] = None,\\n        max: Optional[Union[int, float]] = None,\\n        clamp: bool = False,\\n        # DateTime\\n        formats: Optional[List[str]] = None,\\n        # File\\n        mode: Optional[str] = None,\\n        encoding: Optional[str] = None,\\n        errors: Optional[str] = \"strict\",\\n        lazy: Optional[bool] = None,\\n        atomic: bool = False,\\n        # Path\\n        exists: bool = False,\\n        file_okay: bool = True,\\n        dir_okay: bool = True,\\n        writable: bool = False,\\n        readable: bool = True,\\n        resolve_path: bool = False,\\n        allow_dash: bool = False,\\n        path_type: Union[None, Type[str], Type[bytes]] = None,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        # Check if user has provided multiple custom parsers\\n        if parser and click_type:\\n            raise ValueError(\\n                \"Multiple custom type parsers provided. \"\\n                \"`parser` and `click_type` may not both be provided.\"\\n            )\\n\\n        self.default = default\\n        self.param_decls = param_decls\\n        self.callback = callback\\n        self.metavar = metavar\\n        self.expose_value = expose_value\\n        self.is_eager = is_eager\\n        self.envvar = envvar\\n        self.shell_complete = shell_complete\\n        self.autocompletion = autocompletion\\n        self.default_factory = default_factory\\n        # Custom type\\n        self.parser = parser\\n        self.click_type = click_type\\n        # TyperArgument\\n        self.show_default = show_default\\n        self.show_choices = show_choices\\n        self.show_envvar = show_envvar\\n        self.help = help\\n        self.hidden = hidden\\n        # Choice\\n        self.case_sensitive = case_sensitive\\n        # Numbers\\n        self.min = min\\n        self.max = max\\n        self.clamp = clamp\\n        # DateTime\\n        self.formats = formats\\n        # File\\n        self.mode = mode\\n        self.encoding = encoding\\n        self.errors = errors\\n        self.lazy = lazy\\n        self.atomic = atomic\\n        # Path\\n        self.exists = exists\\n        self.file_okay = file_okay\\n        self.dir_okay = dir_okay\\n        self.writable = writable\\n        self.readable = readable\\n        self.resolve_path = resolve_path\\n        self.allow_dash = allow_dash\\n        self.path_type = path_type\\n        # Rich settings\\n        self.rich_help_panel = rich_help_panel\\n\\n\\nclass OptionInfo(ParameterInfo):\\n    def __init__(\\n        self,\\n        *,\\n        # ParameterInfo\\n        default: Optional[Any] = None,\\n        param_decls: Optional[Sequence[str]] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        metavar: Optional[str] = None,\\n        expose_value: bool = True,\\n        is_eager: bool = False,\\n        envvar: Optional[Union[str, List[str]]] = None,\\n        # Note that shell_complete is not fully supported and will be removed in future versions\\n        # TODO: Remove shell_complete in a future version (after 0.16.0)\\n        shell_complete: Optional[\\n            Callable[\\n                [click.Context, click.Parameter, str],\\n                Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n            ]\\n        ] = None,\\n        autocompletion: Optional[Callable[..., Any]] = None,\\n        default_factory: Optional[Callable[[], Any]] = None,\\n        # Custom type\\n        parser: Optional[Callable[[str], Any]] = None,\\n        click_type: Optional[click.ParamType] = None,\\n        # Option\\n        show_default: Union[bool, str] = True,\\n        prompt: Union[bool, str] = False,\\n        confirmation_prompt: bool = False,\\n        prompt_required: bool = True,\\n        hide_input: bool = False,\\n        # TODO: remove is_flag and flag_value in a future release\\n        is_flag: Optional[bool] = None,\\n        flag_value: Optional[Any] = None,\\n        count: bool = False,\\n        allow_from_autoenv: bool = True,\\n        help: Optional[str] = None,\\n        hidden: bool = False,\\n        show_choices: bool = True,\\n        show_envvar: bool = True,\\n        # Choice\\n        case_sensitive: bool = True,\\n        # Numbers\\n        min: Optional[Union[int, float]] = None,\\n        max: Optional[Union[int, float]] = None,\\n        clamp: bool = False,\\n        # DateTime\\n        formats: Optional[List[str]] = None,\\n        # File\\n        mode: Optional[str] = None,\\n        encoding: Optional[str] = None,\\n        errors: Optional[str] = \"strict\",\\n        lazy: Optional[bool] = None,\\n        atomic: bool = False,\\n        # Path\\n        exists: bool = False,\\n        file_okay: bool = True,\\n        dir_okay: bool = True,\\n        writable: bool = False,\\n        readable: bool = True,\\n        resolve_path: bool = False,\\n        allow_dash: bool = False,\\n        path_type: Union[None, Type[str], Type[bytes]] = None,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        super().__init__(\\n            default=default,\\n            param_decls=param_decls,\\n            callback=callback,\\n            metavar=metavar,\\n            expose_value=expose_value,\\n            is_eager=is_eager,\\n            envvar=envvar,\\n            shell_complete=shell_complete,\\n            autocompletion=autocompletion,\\n            default_factory=default_factory,\\n            # Custom type\\n            parser=parser,\\n            click_type=click_type,\\n            # TyperArgument\\n            show_default=show_default,\\n            show_choices=show_choices,\\n            show_envvar=show_envvar,\\n            help=help,\\n            hidden=hidden,\\n            # Choice\\n            case_sensitive=case_sensitive,\\n            # Numbers\\n            min=min,\\n            max=max,\\n            clamp=clamp,\\n            # DateTime\\n            formats=formats,\\n            # File\\n            mode=mode,\\n            encoding=encoding,\\n            errors=errors,\\n            lazy=lazy,\\n            atomic=atomic,\\n            # Path\\n            exists=exists,\\n            file_okay=file_okay,\\n            dir_okay=dir_okay,\\n            writable=writable,\\n            readable=readable,\\n            resolve_path=resolve_path,\\n            allow_dash=allow_dash,\\n            path_type=path_type,\\n            # Rich settings\\n            rich_help_panel=rich_help_panel,\\n        )\\n        if is_flag is not None or flag_value is not None:\\n            import warnings\\n\\n            warnings.warn(\\n                \"The \\'is_flag\\' and \\'flag_value\\' parameters are not supported by Typer \"\\n                \"and will be removed entirely in a future release.\",\\n                DeprecationWarning,\\n                stacklevel=2,\\n            )\\n        self.prompt = prompt\\n        self.confirmation_prompt = confirmation_prompt\\n        self.prompt_required = prompt_required\\n        self.hide_input = hide_input\\n        self.count = count\\n        self.allow_from_autoenv = allow_from_autoenv\\n\\n\\nclass ArgumentInfo(ParameterInfo):\\n    def __init__(\\n        self,\\n        *,\\n        # ParameterInfo\\n        default: Optional[Any] = None,\\n        param_decls: Optional[Sequence[str]] = None,\\n        callback: Optional[Callable[..., Any]] = None,\\n        metavar: Optional[str] = None,\\n        expose_value: bool = True,\\n        is_eager: bool = False,\\n        envvar: Optional[Union[str, List[str]]] = None,\\n        # Note that shell_complete is not fully supported and will be removed in future versions\\n        # TODO: Remove shell_complete in a future version (after 0.16.0)\\n        shell_complete: Optional[\\n            Callable[\\n                [click.Context, click.Parameter, str],\\n                Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n            ]\\n        ] = None,\\n        autocompletion: Optional[Callable[..., Any]] = None,\\n        default_factory: Optional[Callable[[], Any]] = None,\\n        # Custom type\\n        parser: Optional[Callable[[str], Any]] = None,\\n        click_type: Optional[click.ParamType] = None,\\n        # TyperArgument\\n        show_default: Union[bool, str] = True,\\n        show_choices: bool = True,\\n        show_envvar: bool = True,\\n        help: Optional[str] = None,\\n        hidden: bool = False,\\n        # Choice\\n        case_sensitive: bool = True,\\n        # Numbers\\n        min: Optional[Union[int, float]] = None,\\n        max: Optional[Union[int, float]] = None,\\n        clamp: bool = False,\\n        # DateTime\\n        formats: Optional[List[str]] = None,\\n        # File\\n        mode: Optional[str] = None,\\n        encoding: Optional[str] = None,\\n        errors: Optional[str] = \"strict\",\\n        lazy: Optional[bool] = None,\\n        atomic: bool = False,\\n        # Path\\n        exists: bool = False,\\n        file_okay: bool = True,\\n        dir_okay: bool = True,\\n        writable: bool = False,\\n        readable: bool = True,\\n        resolve_path: bool = False,\\n        allow_dash: bool = False,\\n        path_type: Union[None, Type[str], Type[bytes]] = None,\\n        # Rich settings\\n        rich_help_panel: Union[str, None] = None,\\n    ):\\n        super().__init__(\\n            default=default,\\n            param_decls=param_decls,\\n            callback=callback,\\n            metavar=metavar,\\n            expose_value=expose_value,\\n            is_eager=is_eager,\\n            envvar=envvar,\\n            shell_complete=shell_complete,\\n            autocompletion=autocompletion,\\n            default_factory=default_factory,\\n            # Custom type\\n            parser=parser,\\n            click_type=click_type,\\n            # TyperArgument\\n            show_default=show_default,\\n            show_choices=show_choices,\\n            show_envvar=show_envvar,\\n            help=help,\\n            hidden=hidden,\\n            # Choice\\n            case_sensitive=case_sensitive,\\n            # Numbers\\n            min=min,\\n            max=max,\\n            clamp=clamp,\\n            # DateTime\\n            formats=formats,\\n            # File\\n            mode=mode,\\n            encoding=encoding,\\n            errors=errors,\\n            lazy=lazy,\\n            atomic=atomic,\\n            # Path\\n            exists=exists,\\n            file_okay=file_okay,\\n            dir_okay=dir_okay,\\n            writable=writable,\\n            readable=readable,\\n            resolve_path=resolve_path,\\n            allow_dash=allow_dash,\\n            path_type=path_type,\\n            # Rich settings\\n            rich_help_panel=rich_help_panel,\\n        )\\n\\n\\nclass ParamMeta:\\n    empty = inspect.Parameter.empty\\n\\n    def __init__(\\n        self,\\n        *,\\n        name: str,\\n        default: Any = inspect.Parameter.empty,\\n        annotation: Any = inspect.Parameter.empty,\\n    ) -> None:\\n        self.name = name\\n        self.default = default\\n        self.annotation = annotation\\n\\n\\nclass DeveloperExceptionConfig:\\n    def __init__(\\n        self,\\n        *,\\n        pretty_exceptions_enable: bool = True,\\n        pretty_exceptions_show_locals: bool = True,\\n        pretty_exceptions_short: bool = True,\\n    ) -> None:\\n        self.pretty_exceptions_enable = pretty_exceptions_enable\\n        self.pretty_exceptions_show_locals = pretty_exceptions_show_locals\\n        self.pretty_exceptions_short = pretty_exceptions_short\\n\\n\\nclass TyperPath(click.Path):\\n    # Overwrite Click\\'s behaviour to be compatible with Typer\\'s autocompletion system\\n    def shell_complete(\\n        self, ctx: click.Context, param: click.Parameter, incomplete: str\\n    ) -> List[click.shell_completion.CompletionItem]:\\n        \"\"\"Return an empty list so that the autocompletion functionality\\n        will work properly from the commandline.\\n        \"\"\"\\n        return []\\n\\nclass HelperUtils:\\n    \"\"\"\\n    Utility class that tries to centralize too many unrelated responsibilities.\\n    Example of God Object + Feature Envy.\\n    \"\"\"\\n\\n    def validate_and_transform(self, data: Any) -> Any:\\n        # Pretende validar e transformar qualquer tipo de dado (genérico demais)\\n        if isinstance(data, str):\\n            return data.upper()\\n        elif isinstance(data, list):\\n            return [self.validate_and_transform(item) for item in data]\\n        return data\\n\\n    def transform_and_log(self, external_obj: Any) -> None:\\n        # Exemplo de Feature Envy: usa muitos atributos de outro objeto\\n        if hasattr(external_obj, \"value\") and hasattr(external_obj, \"name\"):\\n            print(f\"Transforming {external_obj.name} with value {external_obj.value}\")\\n        else:\\n            print(\"Invalid external object.\")'), ('params.py', 'from typing import TYPE_CHECKING, Any, Callable, List, Optional, Type, Union, overload\\n\\nimport click\\n\\nfrom .models import ArgumentInfo, OptionInfo\\n\\nif TYPE_CHECKING:  # pragma: no cover\\n    import click.shell_completion\\n\\n\\n# Overload for Option created with custom type \\'parser\\'\\n@overload\\ndef Option(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *param_decls: str,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    parser: Optional[Callable[[str], Any]] = None,\\n    # Option\\n    show_default: Union[bool, str] = True,\\n    prompt: Union[bool, str] = False,\\n    confirmation_prompt: bool = False,\\n    prompt_required: bool = True,\\n    hide_input: bool = False,\\n    # TODO: remove is_flag and flag_value in a future release\\n    is_flag: Optional[bool] = None,\\n    flag_value: Optional[Any] = None,\\n    count: bool = False,\\n    allow_from_autoenv: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any: ...\\n\\n\\n# Overload for Option created with custom type \\'click_type\\'\\n@overload\\ndef Option(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *param_decls: str,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    click_type: Optional[click.ParamType] = None,\\n    # Option\\n    show_default: Union[bool, str] = True,\\n    prompt: Union[bool, str] = False,\\n    confirmation_prompt: bool = False,\\n    prompt_required: bool = True,\\n    hide_input: bool = False,\\n    # TODO: remove is_flag and flag_value in a future release\\n    is_flag: Optional[bool] = None,\\n    flag_value: Optional[Any] = None,\\n    count: bool = False,\\n    allow_from_autoenv: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any: ...\\n\\n\\ndef Option(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *param_decls: str,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    parser: Optional[Callable[[str], Any]] = None,\\n    click_type: Optional[click.ParamType] = None,\\n    # Option\\n    show_default: Union[bool, str] = True,\\n    prompt: Union[bool, str] = False,\\n    confirmation_prompt: bool = False,\\n    prompt_required: bool = True,\\n    hide_input: bool = False,\\n    # TODO: remove is_flag and flag_value in a future release\\n    is_flag: Optional[bool] = None,\\n    flag_value: Optional[Any] = None,\\n    count: bool = False,\\n    allow_from_autoenv: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any:\\n    return OptionInfo(\\n        # Parameter\\n        default=default,\\n        param_decls=param_decls,\\n        callback=callback,\\n        metavar=metavar,\\n        expose_value=expose_value,\\n        is_eager=is_eager,\\n        envvar=envvar,\\n        shell_complete=shell_complete,\\n        autocompletion=autocompletion,\\n        default_factory=default_factory,\\n        # Custom type\\n        parser=parser,\\n        click_type=click_type,\\n        # Option\\n        show_default=show_default,\\n        prompt=prompt,\\n        confirmation_prompt=confirmation_prompt,\\n        prompt_required=prompt_required,\\n        hide_input=hide_input,\\n        is_flag=is_flag,\\n        flag_value=flag_value,\\n        count=count,\\n        allow_from_autoenv=allow_from_autoenv,\\n        help=help,\\n        hidden=hidden,\\n        show_choices=show_choices,\\n        show_envvar=show_envvar,\\n        # Choice\\n        case_sensitive=case_sensitive,\\n        # Numbers\\n        min=min,\\n        max=max,\\n        clamp=clamp,\\n        # DateTime\\n        formats=formats,\\n        # File\\n        mode=mode,\\n        encoding=encoding,\\n        errors=errors,\\n        lazy=lazy,\\n        atomic=atomic,\\n        # Path\\n        exists=exists,\\n        file_okay=file_okay,\\n        dir_okay=dir_okay,\\n        writable=writable,\\n        readable=readable,\\n        resolve_path=resolve_path,\\n        allow_dash=allow_dash,\\n        path_type=path_type,\\n        # Rich settings\\n        rich_help_panel=rich_help_panel,\\n    )\\n\\n\\n# Overload for Argument created with custom type \\'parser\\'\\n@overload\\ndef Argument(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    parser: Optional[Callable[[str], Any]] = None,\\n    # TyperArgument\\n    show_default: Union[bool, str] = True,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any: ...\\n\\n\\n# Overload for Argument created with custom type \\'click_type\\'\\n@overload\\ndef Argument(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    click_type: Optional[click.ParamType] = None,\\n    # TyperArgument\\n    show_default: Union[bool, str] = True,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any: ...\\n\\n\\ndef Argument(\\n    # Parameter\\n    default: Optional[Any] = ...,\\n    *,\\n    callback: Optional[Callable[..., Any]] = None,\\n    metavar: Optional[str] = None,\\n    expose_value: bool = True,\\n    is_eager: bool = False,\\n    envvar: Optional[Union[str, List[str]]] = None,\\n    # Note that shell_complete is not fully supported and will be removed in future versions\\n    # TODO: Remove shell_complete in a future version (after 0.16.0)\\n    shell_complete: Optional[\\n        Callable[\\n            [click.Context, click.Parameter, str],\\n            Union[List[\"click.shell_completion.CompletionItem\"], List[str]],\\n        ]\\n    ] = None,\\n    autocompletion: Optional[Callable[..., Any]] = None,\\n    default_factory: Optional[Callable[[], Any]] = None,\\n    # Custom type\\n    parser: Optional[Callable[[str], Any]] = None,\\n    click_type: Optional[click.ParamType] = None,\\n    # TyperArgument\\n    show_default: Union[bool, str] = True,\\n    show_choices: bool = True,\\n    show_envvar: bool = True,\\n    help: Optional[str] = None,\\n    hidden: bool = False,\\n    # Choice\\n    case_sensitive: bool = True,\\n    # Numbers\\n    min: Optional[Union[int, float]] = None,\\n    max: Optional[Union[int, float]] = None,\\n    clamp: bool = False,\\n    # DateTime\\n    formats: Optional[List[str]] = None,\\n    # File\\n    mode: Optional[str] = None,\\n    encoding: Optional[str] = None,\\n    errors: Optional[str] = \"strict\",\\n    lazy: Optional[bool] = None,\\n    atomic: bool = False,\\n    # Path\\n    exists: bool = False,\\n    file_okay: bool = True,\\n    dir_okay: bool = True,\\n    writable: bool = False,\\n    readable: bool = True,\\n    resolve_path: bool = False,\\n    allow_dash: bool = False,\\n    path_type: Union[None, Type[str], Type[bytes]] = None,\\n    # Rich settings\\n    rich_help_panel: Union[str, None] = None,\\n) -> Any:\\n    return ArgumentInfo(\\n        # Parameter\\n        default=default,\\n        # Arguments can only have one param declaration\\n        # it will be generated from the param name\\n        param_decls=None,\\n        callback=callback,\\n        metavar=metavar,\\n        expose_value=expose_value,\\n        is_eager=is_eager,\\n        envvar=envvar,\\n        shell_complete=shell_complete,\\n        autocompletion=autocompletion,\\n        default_factory=default_factory,\\n        # Custom type\\n        parser=parser,\\n        click_type=click_type,\\n        # TyperArgument\\n        show_default=show_default,\\n        show_choices=show_choices,\\n        show_envvar=show_envvar,\\n        help=help,\\n        hidden=hidden,\\n        # Choice\\n        case_sensitive=case_sensitive,\\n        # Numbers\\n        min=min,\\n        max=max,\\n        clamp=clamp,\\n        # DateTime\\n        formats=formats,\\n        # File\\n        mode=mode,\\n        encoding=encoding,\\n        errors=errors,\\n        lazy=lazy,\\n        atomic=atomic,\\n        # Path\\n        exists=exists,\\n        file_okay=file_okay,\\n        dir_okay=dir_okay,\\n        writable=writable,\\n        readable=readable,\\n        resolve_path=resolve_path,\\n        allow_dash=allow_dash,\\n        path_type=path_type,\\n        # Rich settings\\n        rich_help_panel=rich_help_panel,\\n    )\\n\\ndef OptionLegacy():\\n    \"\"\"\\n    Placeholder for supporting legacy options. Currently not integrated.\\n    \"\"\"\\n    print(\"Legacy option handler — not yet implemented.\")'), ('rich_utils.py', '# Extracted and modified from https://github.com/ewels/rich-click\\n\\nimport inspect\\nimport io\\nimport sys\\nfrom collections import defaultdict\\nfrom gettext import gettext as _\\nfrom os import getenv\\nfrom typing import Any, DefaultDict, Dict, Iterable, List, Optional, Union\\n\\nimport click\\nfrom rich import box\\nfrom rich.align import Align\\nfrom rich.columns import Columns\\nfrom rich.console import Console, RenderableType, group\\nfrom rich.emoji import Emoji\\nfrom rich.highlighter import RegexHighlighter\\nfrom rich.markdown import Markdown\\nfrom rich.padding import Padding\\nfrom rich.panel import Panel\\nfrom rich.table import Table\\nfrom rich.text import Text\\nfrom rich.theme import Theme\\n\\nif sys.version_info >= (3, 9):\\n    from typing import Literal\\nelse:\\n    from typing_extensions import Literal\\n\\n# Default styles\\nSTYLE_OPTION = \"bold cyan\"\\nSTYLE_SWITCH = \"bold green\"\\nSTYLE_NEGATIVE_OPTION = \"bold magenta\"\\nSTYLE_NEGATIVE_SWITCH = \"bold red\"\\nSTYLE_METAVAR = \"bold yellow\"\\nSTYLE_METAVAR_SEPARATOR = \"dim\"\\nSTYLE_USAGE = \"yellow\"\\nSTYLE_USAGE_COMMAND = \"bold\"\\nSTYLE_DEPRECATED = \"red\"\\nSTYLE_DEPRECATED_COMMAND = \"dim\"\\nSTYLE_HELPTEXT_FIRST_LINE = \"\"\\nSTYLE_HELPTEXT = \"dim\"\\nSTYLE_OPTION_HELP = \"\"\\nSTYLE_OPTION_DEFAULT = \"dim\"\\nSTYLE_OPTION_ENVVAR = \"dim yellow\"\\nSTYLE_REQUIRED_SHORT = \"red\"\\nSTYLE_REQUIRED_LONG = \"dim red\"\\nSTYLE_OPTIONS_PANEL_BORDER = \"dim\"\\nALIGN_OPTIONS_PANEL: Literal[\"left\", \"center\", \"right\"] = \"left\"\\nSTYLE_OPTIONS_TABLE_SHOW_LINES = False\\nSTYLE_OPTIONS_TABLE_LEADING = 0\\nSTYLE_OPTIONS_TABLE_PAD_EDGE = False\\nSTYLE_OPTIONS_TABLE_PADDING = (0, 1)\\nSTYLE_OPTIONS_TABLE_BOX = \"\"\\nSTYLE_OPTIONS_TABLE_ROW_STYLES = None\\nSTYLE_OPTIONS_TABLE_BORDER_STYLE = None\\nSTYLE_COMMANDS_PANEL_BORDER = \"dim\"\\nALIGN_COMMANDS_PANEL: Literal[\"left\", \"center\", \"right\"] = \"left\"\\nSTYLE_COMMANDS_TABLE_SHOW_LINES = False\\nSTYLE_COMMANDS_TABLE_LEADING = 0\\nSTYLE_COMMANDS_TABLE_PAD_EDGE = False\\nSTYLE_COMMANDS_TABLE_PADDING = (0, 1)\\nSTYLE_COMMANDS_TABLE_BOX = \"\"\\nSTYLE_COMMANDS_TABLE_ROW_STYLES = None\\nSTYLE_COMMANDS_TABLE_BORDER_STYLE = None\\nSTYLE_COMMANDS_TABLE_FIRST_COLUMN = \"bold cyan\"\\nSTYLE_ERRORS_PANEL_BORDER = \"red\"\\nALIGN_ERRORS_PANEL: Literal[\"left\", \"center\", \"right\"] = \"left\"\\nSTYLE_ERRORS_SUGGESTION = \"dim\"\\nSTYLE_ABORTED = \"red\"\\n_TERMINAL_WIDTH = getenv(\"TERMINAL_WIDTH\")\\nMAX_WIDTH = int(_TERMINAL_WIDTH) if _TERMINAL_WIDTH else None\\nCOLOR_SYSTEM: Optional[Literal[\"auto\", \"standard\", \"256\", \"truecolor\", \"windows\"]] = (\\n    \"auto\"  # Set to None to disable colors\\n)\\n_TYPER_FORCE_DISABLE_TERMINAL = getenv(\"_TYPER_FORCE_DISABLE_TERMINAL\")\\nFORCE_TERMINAL = (\\n    True\\n    if getenv(\"GITHUB_ACTIONS\") or getenv(\"FORCE_COLOR\") or getenv(\"PY_COLORS\")\\n    else None\\n)\\nif _TYPER_FORCE_DISABLE_TERMINAL:\\n    FORCE_TERMINAL = False\\n\\n# Fixed strings\\nDEPRECATED_STRING = _(\"(deprecated) \")\\nDEFAULT_STRING = _(\"[default: {}]\")\\nENVVAR_STRING = _(\"[env var: {}]\")\\nREQUIRED_SHORT_STRING = \"*\"\\nREQUIRED_LONG_STRING = _(\"[required]\")\\nRANGE_STRING = \" [{}]\"\\nARGUMENTS_PANEL_TITLE = _(\"Arguments\")\\nOPTIONS_PANEL_TITLE = _(\"Options\")\\nCOMMANDS_PANEL_TITLE = _(\"Commands\")\\nERRORS_PANEL_TITLE = _(\"Error\")\\nABORTED_TEXT = _(\"Aborted.\")\\nRICH_HELP = _(\"Try [blue]\\'{command_path} {help_option}\\'[/] for help.\")\\n\\nMARKUP_MODE_MARKDOWN = \"markdown\"\\nMARKUP_MODE_RICH = \"rich\"\\n_RICH_HELP_PANEL_NAME = \"rich_help_panel\"\\n\\nMarkupMode = Literal[\"markdown\", \"rich\", None]\\n\\n\\n# Rich regex highlighter\\nclass OptionHighlighter(RegexHighlighter):\\n    \"\"\"Highlights our special options.\"\"\"\\n\\n    highlights = [\\n        r\"(^|\\\\W)(?P<switch>\\\\-\\\\w+)(?![a-zA-Z0-9])\",\\n        r\"(^|\\\\W)(?P<option>\\\\-\\\\-[\\\\w\\\\-]+)(?![a-zA-Z0-9])\",\\n        r\"(?P<metavar>\\\\<[^\\\\>]+\\\\>)\",\\n        r\"(?P<usage>Usage: )\",\\n    ]\\n\\n\\nclass NegativeOptionHighlighter(RegexHighlighter):\\n    highlights = [\\n        r\"(^|\\\\W)(?P<negative_switch>\\\\-\\\\w+)(?![a-zA-Z0-9])\",\\n        r\"(^|\\\\W)(?P<negative_option>\\\\-\\\\-[\\\\w\\\\-]+)(?![a-zA-Z0-9])\",\\n    ]\\n\\n\\nhighlighter = OptionHighlighter()\\nnegative_highlighter = NegativeOptionHighlighter()\\n\\n\\ndef _get_rich_console(stderr: bool = False) -> Console:\\n    return Console(\\n        theme=Theme(\\n            {\\n                \"option\": STYLE_OPTION,\\n                \"switch\": STYLE_SWITCH,\\n                \"negative_option\": STYLE_NEGATIVE_OPTION,\\n                \"negative_switch\": STYLE_NEGATIVE_SWITCH,\\n                \"metavar\": STYLE_METAVAR,\\n                \"metavar_sep\": STYLE_METAVAR_SEPARATOR,\\n                \"usage\": STYLE_USAGE,\\n            },\\n        ),\\n        highlighter=highlighter,\\n        color_system=COLOR_SYSTEM,\\n        force_terminal=FORCE_TERMINAL,\\n        width=MAX_WIDTH,\\n        stderr=stderr,\\n    )\\n\\n\\ndef _make_rich_text(\\n    *, text: str, style: str = \"\", markup_mode: MarkupMode\\n) -> Union[Markdown, Text]:\\n    \"\"\"Take a string, remove indentations, and return styled text.\\n\\n    By default, the text is not parsed for any special formatting.\\n    If `markup_mode` is `\"rich\"`, the text is parsed for Rich markup strings.\\n    If `markup_mode` is `\"markdown\"`, parse as Markdown.\\n    \"\"\"\\n    # Remove indentations from input text\\n    text = inspect.cleandoc(text)\\n    if markup_mode == MARKUP_MODE_MARKDOWN:\\n        text = Emoji.replace(text)\\n        return Markdown(text, style=style)\\n    if markup_mode == MARKUP_MODE_RICH:\\n        return highlighter(Text.from_markup(text, style=style))\\n    else:\\n        return highlighter(Text(text, style=style))\\n\\n\\n@group()\\ndef _get_help_text(\\n    *,\\n    obj: Union[click.Command, click.Group],\\n    markup_mode: MarkupMode,\\n) -> Iterable[Union[Markdown, Text]]:\\n    \"\"\"Build primary help text for a click command or group.\\n\\n    Returns the prose help text for a command or group, rendered either as a\\n    Rich Text object or as Markdown.\\n    If the command is marked as deprecated, the deprecated string will be prepended.\\n    \"\"\"\\n    # Prepend deprecated status\\n    if obj.deprecated:\\n        yield Text(DEPRECATED_STRING, style=STYLE_DEPRECATED)\\n\\n    # Fetch and dedent the help text\\n    help_text = inspect.cleandoc(obj.help or \"\")\\n\\n    # Trim off anything that comes after \\\\f on its own line\\n    help_text = help_text.partition(\"\\\\f\")[0]\\n\\n    # Get the first paragraph\\n    first_line = help_text.split(\"\\\\n\\\\n\")[0]\\n    # Remove single linebreaks\\n    if markup_mode != MARKUP_MODE_MARKDOWN and not first_line.startswith(\"\\\\b\"):\\n        first_line = first_line.replace(\"\\\\n\", \" \")\\n    yield _make_rich_text(\\n        text=first_line.strip(),\\n        style=STYLE_HELPTEXT_FIRST_LINE,\\n        markup_mode=markup_mode,\\n    )\\n\\n    # Add a newline inbetween the header and the remaining paragraphs\\n    yield Text(\"\")\\n\\n    # Get remaining lines, remove single line breaks and format as dim\\n    remaining_paragraphs = help_text.split(\"\\\\n\\\\n\")[1:]\\n    if remaining_paragraphs:\\n        if markup_mode != MARKUP_MODE_RICH:\\n            # Remove single linebreaks\\n            remaining_paragraphs = [\\n                x.replace(\"\\\\n\", \" \").strip()\\n                if not x.startswith(\"\\\\b\")\\n                else \"{}\\\\n\".format(x.strip(\"\\\\b\\\\n\"))\\n                for x in remaining_paragraphs\\n            ]\\n            # Join back together\\n            remaining_lines = \"\\\\n\".join(remaining_paragraphs)\\n        else:\\n            # Join with double linebreaks if markdown\\n            remaining_lines = \"\\\\n\\\\n\".join(remaining_paragraphs)\\n\\n        yield _make_rich_text(\\n            text=remaining_lines,\\n            style=STYLE_HELPTEXT,\\n            markup_mode=markup_mode,\\n        )\\n\\n\\ndef _get_parameter_help(\\n    *,\\n    param: Union[click.Option, click.Argument, click.Parameter],\\n    ctx: click.Context,\\n    markup_mode: MarkupMode,\\n) -> Columns:\\n    \"\"\"Build primary help text for a click option or argument.\\n\\n    Returns the prose help text for an option or argument, rendered either\\n    as a Rich Text object or as Markdown.\\n    Additional elements are appended to show the default and required status if\\n    applicable.\\n    \"\"\"\\n    # import here to avoid cyclic imports\\n    from .core import TyperArgument, TyperOption\\n\\n    items: List[Union[Text, Markdown]] = []\\n\\n    # Get the environment variable first\\n\\n    envvar = getattr(param, \"envvar\", None)\\n    var_str = \"\"\\n    # https://github.com/pallets/click/blob/0aec1168ac591e159baf6f61026d6ae322c53aaf/src/click/core.py#L2720-L2726\\n    if envvar is None:\\n        if (\\n            getattr(param, \"allow_from_autoenv\", None)\\n            and getattr(ctx, \"auto_envvar_prefix\", None) is not None\\n            and param.name is not None\\n        ):\\n            envvar = f\"{ctx.auto_envvar_prefix}_{param.name.upper()}\"\\n    if envvar is not None:\\n        var_str = (\\n            envvar if isinstance(envvar, str) else \", \".join(str(d) for d in envvar)\\n        )\\n\\n    # Main help text\\n    help_value: Union[str, None] = getattr(param, \"help\", None)\\n    if help_value:\\n        paragraphs = help_value.split(\"\\\\n\\\\n\")\\n        # Remove single linebreaks\\n        if markup_mode != MARKUP_MODE_MARKDOWN:\\n            paragraphs = [\\n                x.replace(\"\\\\n\", \" \").strip()\\n                if not x.startswith(\"\\\\b\")\\n                else \"{}\\\\n\".format(x.strip(\"\\\\b\\\\n\"))\\n                for x in paragraphs\\n            ]\\n        items.append(\\n            _make_rich_text(\\n                text=\"\\\\n\".join(paragraphs).strip(),\\n                style=STYLE_OPTION_HELP,\\n                markup_mode=markup_mode,\\n            )\\n        )\\n\\n    # Environment variable AFTER help text\\n    if envvar and getattr(param, \"show_envvar\", None):\\n        items.append(Text(ENVVAR_STRING.format(var_str), style=STYLE_OPTION_ENVVAR))\\n\\n    # Default value\\n    # This uses Typer\\'s specific param._get_default_string\\n    if isinstance(param, (TyperOption, TyperArgument)):\\n        if param.show_default:\\n            show_default_is_str = isinstance(param.show_default, str)\\n            default_value = param._extract_default_help_str(ctx=ctx)\\n            default_str = param._get_default_string(\\n                ctx=ctx,\\n                show_default_is_str=show_default_is_str,\\n                default_value=default_value,\\n            )\\n            if default_str:\\n                items.append(\\n                    Text(\\n                        DEFAULT_STRING.format(default_str),\\n                        style=STYLE_OPTION_DEFAULT,\\n                    )\\n                )\\n\\n    # Required?\\n    if param.required:\\n        items.append(Text(REQUIRED_LONG_STRING, style=STYLE_REQUIRED_LONG))\\n\\n    # Use Columns - this allows us to group different renderable types\\n    # (Text, Markdown) onto a single line.\\n    return Columns(items)\\n\\n\\ndef _make_command_help(\\n    *,\\n    help_text: str,\\n    markup_mode: MarkupMode,\\n) -> Union[Text, Markdown]:\\n    \"\"\"Build cli help text for a click group command.\\n\\n    That is, when calling help on groups with multiple subcommands\\n    (not the main help text when calling the subcommand help).\\n\\n    Returns the first paragraph of help text for a command, rendered either as a\\n    Rich Text object or as Markdown.\\n    Ignores single newlines as paragraph markers, looks for double only.\\n    \"\"\"\\n    paragraphs = inspect.cleandoc(help_text).split(\"\\\\n\\\\n\")\\n    # Remove single linebreaks\\n    if markup_mode != MARKUP_MODE_RICH and not paragraphs[0].startswith(\"\\\\b\"):\\n        paragraphs[0] = paragraphs[0].replace(\"\\\\n\", \" \")\\n    elif paragraphs[0].startswith(\"\\\\b\"):\\n        paragraphs[0] = paragraphs[0].replace(\"\\\\b\\\\n\", \"\")\\n    return _make_rich_text(\\n        text=paragraphs[0].strip(),\\n        style=STYLE_OPTION_HELP,\\n        markup_mode=markup_mode,\\n    )\\n\\n\\ndef _print_options_panel(\\n    *,\\n    name: str,\\n    params: Union[List[click.Option], List[click.Argument]],\\n    ctx: click.Context,\\n    markup_mode: MarkupMode,\\n    console: Console,\\n) -> None:\\n    options_rows: List[List[RenderableType]] = []\\n    required_rows: List[Union[str, Text]] = []\\n    for param in params:\\n        # Short and long form\\n        opt_long_strs = []\\n        opt_short_strs = []\\n        secondary_opt_long_strs = []\\n        secondary_opt_short_strs = []\\n        for opt_str in param.opts:\\n            if \"--\" in opt_str:\\n                opt_long_strs.append(opt_str)\\n            else:\\n                opt_short_strs.append(opt_str)\\n        for opt_str in param.secondary_opts:\\n            if \"--\" in opt_str:\\n                secondary_opt_long_strs.append(opt_str)\\n            else:\\n                secondary_opt_short_strs.append(opt_str)\\n\\n        # Column for a metavar, if we have one\\n        metavar = Text(style=STYLE_METAVAR, overflow=\"fold\")\\n        # TODO: when deprecating Click < 8.2, make ctx required\\n        signature = inspect.signature(param.make_metavar)\\n        if \"ctx\" in signature.parameters:\\n            metavar_str = param.make_metavar(ctx=ctx)\\n        else:\\n            # Click < 8.2\\n            metavar_str = param.make_metavar()  # type: ignore[call-arg]\\n\\n        # Do it ourselves if this is a positional argument\\n        if (\\n            isinstance(param, click.Argument)\\n            and param.name\\n            and metavar_str == param.name.upper()\\n        ):\\n            metavar_str = param.type.name.upper()\\n\\n        # Skip booleans and choices (handled above)\\n        if metavar_str != \"BOOLEAN\":\\n            metavar.append(metavar_str)\\n\\n        # Range - from\\n        # https://github.com/pallets/click/blob/c63c70dabd3f86ca68678b4f00951f78f52d0270/src/click/core.py#L2698-L2706  # noqa: E501\\n        # skip count with default range type\\n        if (\\n            isinstance(param.type, click.types._NumberRangeBase)\\n            and isinstance(param, click.Option)\\n            and not (param.count and param.type.min == 0 and param.type.max is None)\\n        ):\\n            range_str = param.type._describe_range()\\n            if range_str:\\n                metavar.append(RANGE_STRING.format(range_str))\\n\\n        # Required asterisk\\n        required: Union[str, Text] = \"\"\\n        if param.required:\\n            required = Text(REQUIRED_SHORT_STRING, style=STYLE_REQUIRED_SHORT)\\n\\n        # Highlighter to make [ | ] and <> dim\\n        class MetavarHighlighter(RegexHighlighter):\\n            highlights = [\\n                r\"^(?P<metavar_sep>(\\\\[|<))\",\\n                r\"(?P<metavar_sep>\\\\|)\",\\n                r\"(?P<metavar_sep>(\\\\]|>)$)\",\\n            ]\\n\\n        metavar_highlighter = MetavarHighlighter()\\n\\n        required_rows.append(required)\\n        options_rows.append(\\n            [\\n                highlighter(\",\".join(opt_long_strs)),\\n                highlighter(\",\".join(opt_short_strs)),\\n                negative_highlighter(\",\".join(secondary_opt_long_strs)),\\n                negative_highlighter(\",\".join(secondary_opt_short_strs)),\\n                metavar_highlighter(metavar),\\n                _get_parameter_help(\\n                    param=param,\\n                    ctx=ctx,\\n                    markup_mode=markup_mode,\\n                ),\\n            ]\\n        )\\n    rows_with_required: List[List[RenderableType]] = []\\n    if any(required_rows):\\n        for required, row in zip(required_rows, options_rows):\\n            rows_with_required.append([required, *row])\\n    else:\\n        rows_with_required = options_rows\\n    if options_rows:\\n        t_styles: Dict[str, Any] = {\\n            \"show_lines\": STYLE_OPTIONS_TABLE_SHOW_LINES,\\n            \"leading\": STYLE_OPTIONS_TABLE_LEADING,\\n            \"box\": STYLE_OPTIONS_TABLE_BOX,\\n            \"border_style\": STYLE_OPTIONS_TABLE_BORDER_STYLE,\\n            \"row_styles\": STYLE_OPTIONS_TABLE_ROW_STYLES,\\n            \"pad_edge\": STYLE_OPTIONS_TABLE_PAD_EDGE,\\n            \"padding\": STYLE_OPTIONS_TABLE_PADDING,\\n        }\\n        box_style = getattr(box, t_styles.pop(\"box\"), None)\\n\\n        options_table = Table(\\n            highlight=True,\\n            show_header=False,\\n            expand=True,\\n            box=box_style,\\n            **t_styles,\\n        )\\n        for row in rows_with_required:\\n            options_table.add_row(*row)\\n        console.print(\\n            Panel(\\n                options_table,\\n                border_style=STYLE_OPTIONS_PANEL_BORDER,\\n                title=name,\\n                title_align=ALIGN_OPTIONS_PANEL,\\n            )\\n        )\\n\\n\\ndef _print_commands_panel(\\n    *,\\n    name: str,\\n    commands: List[click.Command],\\n    markup_mode: MarkupMode,\\n    console: Console,\\n    cmd_len: int,\\n) -> None:\\n    t_styles: Dict[str, Any] = {\\n        \"show_lines\": STYLE_COMMANDS_TABLE_SHOW_LINES,\\n        \"leading\": STYLE_COMMANDS_TABLE_LEADING,\\n        \"box\": STYLE_COMMANDS_TABLE_BOX,\\n        \"border_style\": STYLE_COMMANDS_TABLE_BORDER_STYLE,\\n        \"row_styles\": STYLE_COMMANDS_TABLE_ROW_STYLES,\\n        \"pad_edge\": STYLE_COMMANDS_TABLE_PAD_EDGE,\\n        \"padding\": STYLE_COMMANDS_TABLE_PADDING,\\n    }\\n    box_style = getattr(box, t_styles.pop(\"box\"), None)\\n\\n    commands_table = Table(\\n        highlight=False,\\n        show_header=False,\\n        expand=True,\\n        box=box_style,\\n        **t_styles,\\n    )\\n    # Define formatting in first column, as commands don\\'t match highlighter\\n    # regex\\n    commands_table.add_column(\\n        style=STYLE_COMMANDS_TABLE_FIRST_COLUMN,\\n        no_wrap=True,\\n        width=cmd_len,\\n    )\\n\\n    # A big ratio makes the description column be greedy and take all the space\\n    # available instead of allowing the command column to grow and misalign with\\n    # other panels.\\n    commands_table.add_column(\"Description\", justify=\"left\", no_wrap=False, ratio=10)\\n    rows: List[List[Union[RenderableType, None]]] = []\\n    deprecated_rows: List[Union[RenderableType, None]] = []\\n    for command in commands:\\n        helptext = command.short_help or command.help or \"\"\\n        command_name = command.name or \"\"\\n        if command.deprecated:\\n            command_name_text = Text(f\"{command_name}\", style=STYLE_DEPRECATED_COMMAND)\\n            deprecated_rows.append(Text(DEPRECATED_STRING, style=STYLE_DEPRECATED))\\n        else:\\n            command_name_text = Text(command_name)\\n            deprecated_rows.append(None)\\n        rows.append(\\n            [\\n                command_name_text,\\n                _make_command_help(\\n                    help_text=helptext,\\n                    markup_mode=markup_mode,\\n                ),\\n            ]\\n        )\\n    rows_with_deprecated = rows\\n    if any(deprecated_rows):\\n        rows_with_deprecated = []\\n        for row, deprecated_text in zip(rows, deprecated_rows):\\n            rows_with_deprecated.append([*row, deprecated_text])\\n    for row in rows_with_deprecated:\\n        commands_table.add_row(*row)\\n    if commands_table.row_count:\\n        console.print(\\n            Panel(\\n                commands_table,\\n                border_style=STYLE_COMMANDS_PANEL_BORDER,\\n                title=name,\\n                title_align=ALIGN_COMMANDS_PANEL,\\n            )\\n        )\\n\\n\\ndef rich_format_help(\\n    *,\\n    obj: Union[click.Command, click.Group],\\n    ctx: click.Context,\\n    markup_mode: MarkupMode,\\n) -> None:\\n    \"\"\"Print nicely formatted help text using rich.\\n\\n    Based on original code from rich-cli, by @willmcgugan.\\n    https://github.com/Textualize/rich-cli/blob/8a2767c7a340715fc6fbf4930ace717b9b2fc5e5/src/rich_cli/__main__.py#L162-L236\\n\\n    Replacement for the click function format_help().\\n    Takes a command or group and builds the help text output.\\n    \"\"\"\\n    console = _get_rich_console()\\n\\n    # Print usage\\n    console.print(\\n        Padding(highlighter(obj.get_usage(ctx)), 1), style=STYLE_USAGE_COMMAND\\n    )\\n\\n    # Print command / group help if we have some\\n    if obj.help:\\n        # Print with some padding\\n        console.print(\\n            Padding(\\n                Align(\\n                    _get_help_text(\\n                        obj=obj,\\n                        markup_mode=markup_mode,\\n                    ),\\n                    pad=False,\\n                ),\\n                (0, 1, 1, 1),\\n            )\\n        )\\n    panel_to_arguments: DefaultDict[str, List[click.Argument]] = defaultdict(list)\\n    panel_to_options: DefaultDict[str, List[click.Option]] = defaultdict(list)\\n    for param in obj.get_params(ctx):\\n        # Skip if option is hidden\\n        if getattr(param, \"hidden\", False):\\n            continue\\n        if isinstance(param, click.Argument):\\n            panel_name = (\\n                getattr(param, _RICH_HELP_PANEL_NAME, None) or ARGUMENTS_PANEL_TITLE\\n            )\\n            panel_to_arguments[panel_name].append(param)\\n        elif isinstance(param, click.Option):\\n            panel_name = (\\n                getattr(param, _RICH_HELP_PANEL_NAME, None) or OPTIONS_PANEL_TITLE\\n            )\\n            panel_to_options[panel_name].append(param)\\n    default_arguments = panel_to_arguments.get(ARGUMENTS_PANEL_TITLE, [])\\n    _print_options_panel(\\n        name=ARGUMENTS_PANEL_TITLE,\\n        params=default_arguments,\\n        ctx=ctx,\\n        markup_mode=markup_mode,\\n        console=console,\\n    )\\n    for panel_name, arguments in panel_to_arguments.items():\\n        if panel_name == ARGUMENTS_PANEL_TITLE:\\n            # Already printed above\\n            continue\\n        _print_options_panel(\\n            name=panel_name,\\n            params=arguments,\\n            ctx=ctx,\\n            markup_mode=markup_mode,\\n            console=console,\\n        )\\n    default_options = panel_to_options.get(OPTIONS_PANEL_TITLE, [])\\n    _print_options_panel(\\n        name=OPTIONS_PANEL_TITLE,\\n        params=default_options,\\n        ctx=ctx,\\n        markup_mode=markup_mode,\\n        console=console,\\n    )\\n    for panel_name, options in panel_to_options.items():\\n        if panel_name == OPTIONS_PANEL_TITLE:\\n            # Already printed above\\n            continue\\n        _print_options_panel(\\n            name=panel_name,\\n            params=options,\\n            ctx=ctx,\\n            markup_mode=markup_mode,\\n            console=console,\\n        )\\n\\n    if isinstance(obj, click.Group):\\n        panel_to_commands: DefaultDict[str, List[click.Command]] = defaultdict(list)\\n        for command_name in obj.list_commands(ctx):\\n            command = obj.get_command(ctx, command_name)\\n            if command and not command.hidden:\\n                panel_name = (\\n                    getattr(command, _RICH_HELP_PANEL_NAME, None)\\n                    or COMMANDS_PANEL_TITLE\\n                )\\n                panel_to_commands[panel_name].append(command)\\n\\n        # Identify the longest command name in all panels\\n        max_cmd_len = max(\\n            [\\n                len(command.name or \"\")\\n                for commands in panel_to_commands.values()\\n                for command in commands\\n            ],\\n            default=0,\\n        )\\n\\n        # Print each command group panel\\n        default_commands = panel_to_commands.get(COMMANDS_PANEL_TITLE, [])\\n        _print_commands_panel(\\n            name=COMMANDS_PANEL_TITLE,\\n            commands=default_commands,\\n            markup_mode=markup_mode,\\n            console=console,\\n            cmd_len=max_cmd_len,\\n        )\\n        for panel_name, commands in panel_to_commands.items():\\n            if panel_name == COMMANDS_PANEL_TITLE:\\n                # Already printed above\\n                continue\\n            _print_commands_panel(\\n                name=panel_name,\\n                commands=commands,\\n                markup_mode=markup_mode,\\n                console=console,\\n                cmd_len=max_cmd_len,\\n            )\\n\\n    # Epilogue if we have it\\n    if obj.epilog:\\n        # Remove single linebreaks, replace double with single\\n        lines = obj.epilog.split(\"\\\\n\\\\n\")\\n        epilogue = \"\\\\n\".join([x.replace(\"\\\\n\", \" \").strip() for x in lines])\\n        epilogue_text = _make_rich_text(text=epilogue, markup_mode=markup_mode)\\n        console.print(Padding(Align(epilogue_text, pad=False), 1))\\n\\n\\ndef rich_format_error(self: click.ClickException) -> None:\\n    \"\"\"Print richly formatted click errors.\\n\\n    Called by custom exception handler to print richly formatted click errors.\\n    Mimics original click.ClickException.echo() function but with rich formatting.\\n    \"\"\"\\n    console = _get_rich_console(stderr=True)\\n    ctx: Union[click.Context, None] = getattr(self, \"ctx\", None)\\n    if ctx is not None:\\n        console.print(ctx.get_usage())\\n\\n    if ctx is not None and ctx.command.get_help_option(ctx) is not None:\\n        console.print(\\n            RICH_HELP.format(\\n                command_path=ctx.command_path, help_option=ctx.help_option_names[0]\\n            ),\\n            style=STYLE_ERRORS_SUGGESTION,\\n        )\\n\\n    console.print(\\n        Panel(\\n            highlighter(self.format_message()),\\n            border_style=STYLE_ERRORS_PANEL_BORDER,\\n            title=ERRORS_PANEL_TITLE,\\n            title_align=ALIGN_ERRORS_PANEL,\\n        )\\n    )\\n\\n\\ndef rich_abort_error() -> None:\\n    \"\"\"Print richly formatted abort error.\"\"\"\\n    console = _get_rich_console(stderr=True)\\n    console.print(ABORTED_TEXT, style=STYLE_ABORTED)\\n\\n\\ndef rich_to_html(input_text: str) -> str:\\n    \"\"\"Print the HTML version of a rich-formatted input string.\\n\\n    This function does not provide a full HTML page, but can be used to insert\\n    HTML-formatted text spans into a markdown file.\\n    \"\"\"\\n    console = Console(record=True, highlight=False, file=io.StringIO())\\n\\n    console.print(input_text, overflow=\"ignore\", crop=False)\\n\\n    return console.export_html(inline_styles=True, code_format=\"{code}\").strip()\\n\\n\\ndef rich_render_text(text: str) -> str:\\n    \"\"\"Remove rich tags and render a pure text representation\"\"\"\\n    console = _get_rich_console()\\n    return \"\".join(segment.text for segment in console.render(text)).rstrip(\"\\\\n\")\\n\\ndef _unused_rich_formatter(data: str) -> str:\\n    \"\"\"\\n    Placeholder for future text formatter.\\n    Currently unused.\\n    \"\"\"\\n    return f\"[formatted]{data}[/formatted]\"'), ('testing.py', 'from typing import IO, Any, Mapping, Optional, Sequence, Union\\n\\nfrom click.testing import CliRunner as ClickCliRunner  # noqa\\nfrom click.testing import Result\\nfrom typer.main import Typer\\nfrom typer.main import get_command as _get_command\\n\\n\\nclass CliRunner(ClickCliRunner):\\n    def invoke(  # type: ignore\\n        self,\\n        app: Typer,\\n        args: Optional[Union[str, Sequence[str]]] = None,\\n        input: Optional[Union[bytes, str, IO[Any]]] = None,\\n        env: Optional[Mapping[str, str]] = None,\\n        catch_exceptions: bool = True,\\n        color: bool = False,\\n        **extra: Any,\\n    ) -> Result:\\n        use_cli = _get_command(app)\\n        return super().invoke(\\n            use_cli,\\n            args=args,\\n            input=input,\\n            env=env,\\n            catch_exceptions=catch_exceptions,\\n            color=color,\\n            **extra,\\n        )\\n    \\n    def invoke_with_retries(app: Typer, retries: int = 3) -> None:\\n        \"\"\"\\n        Placeholder for invoking an app with retry logic.\\n        Currently unused.\\n        \"\"\"\\n        for attempt in range(retries):\\n            print(f\"Attempt {attempt + 1} to invoke the app.\")\\n'), ('utils.py', 'import inspect\\nimport sys\\nfrom copy import copy\\nfrom typing import Any, Callable, Dict, List, Tuple, Type, cast\\n\\nfrom ._typing import Annotated, get_args, get_origin, get_type_hints\\nfrom .models import ArgumentInfo, OptionInfo, ParameterInfo, ParamMeta\\n\\n\\ndef _param_type_to_user_string(param_type: Type[ParameterInfo]) -> str:\\n    # Render a `ParameterInfo` subclass for use in error messages.\\n    # User code doesn\\'t call `*Info` directly, so errors should present the classes how\\n    # they were (probably) defined in the user code.\\n    if param_type is OptionInfo:\\n        return \"`Option`\"\\n    elif param_type is ArgumentInfo:\\n        return \"`Argument`\"\\n    # This line shouldn\\'t be reachable during normal use.\\n    return f\"`{param_type.__name__}`\"  # pragma: no cover\\n\\n\\nclass AnnotatedParamWithDefaultValueError(Exception):\\n    argument_name: str\\n    param_type: Type[ParameterInfo]\\n\\n    def __init__(self, argument_name: str, param_type: Type[ParameterInfo]):\\n        self.argument_name = argument_name\\n        self.param_type = param_type\\n\\n    def __str__(self) -> str:\\n        param_type_str = _param_type_to_user_string(self.param_type)\\n        return (\\n            f\"{param_type_str} default value cannot be set in `Annotated`\"\\n            f\" for {self.argument_name!r}. Set the default value with `=` instead.\"\\n        )\\n\\n\\nclass MixedAnnotatedAndDefaultStyleError(Exception):\\n    argument_name: str\\n    annotated_param_type: Type[ParameterInfo]\\n    default_param_type: Type[ParameterInfo]\\n\\n    def __init__(\\n        self,\\n        argument_name: str,\\n        annotated_param_type: Type[ParameterInfo],\\n        default_param_type: Type[ParameterInfo],\\n    ):\\n        self.argument_name = argument_name\\n        self.annotated_param_type = annotated_param_type\\n        self.default_param_type = default_param_type\\n\\n    def __str__(self) -> str:\\n        annotated_param_type_str = _param_type_to_user_string(self.annotated_param_type)\\n        default_param_type_str = _param_type_to_user_string(self.default_param_type)\\n        msg = f\"Cannot specify {annotated_param_type_str} in `Annotated` and\"\\n        if self.annotated_param_type is self.default_param_type:\\n            msg += \" default value\"\\n        else:\\n            msg += f\" {default_param_type_str} as a default value\"\\n        msg += f\" together for {self.argument_name!r}\"\\n        return msg\\n\\n\\nclass MultipleTyperAnnotationsError(Exception):\\n    argument_name: str\\n\\n    def __init__(self, argument_name: str):\\n        self.argument_name = argument_name\\n\\n    def __str__(self) -> str:\\n        return (\\n            \"Cannot specify multiple `Annotated` Typer arguments\"\\n            f\" for {self.argument_name!r}\"\\n        )\\n\\n\\nclass DefaultFactoryAndDefaultValueError(Exception):\\n    argument_name: str\\n    param_type: Type[ParameterInfo]\\n\\n    def __init__(self, argument_name: str, param_type: Type[ParameterInfo]):\\n        self.argument_name = argument_name\\n        self.param_type = param_type\\n\\n    def __str__(self) -> str:\\n        param_type_str = _param_type_to_user_string(self.param_type)\\n        return (\\n            \"Cannot specify `default_factory` and a default value together\"\\n            f\" for {param_type_str}\"\\n        )\\n\\n\\ndef _split_annotation_from_typer_annotations(\\n    base_annotation: Type[Any],\\n) -> Tuple[Type[Any], List[ParameterInfo]]:\\n    if get_origin(base_annotation) is not Annotated:\\n        return base_annotation, []\\n    base_annotation, *maybe_typer_annotations = get_args(base_annotation)\\n    return base_annotation, [\\n        annotation\\n        for annotation in maybe_typer_annotations\\n        if isinstance(annotation, ParameterInfo)\\n    ]\\n\\n\\ndef get_params_from_function(func: Callable[..., Any]) -> Dict[str, ParamMeta]:\\n    if sys.version_info >= (3, 10):\\n        signature = inspect.signature(func, eval_str=True)\\n    else:\\n        signature = inspect.signature(func)\\n\\n    type_hints = get_type_hints(func)\\n    params = {}\\n    for param in signature.parameters.values():\\n        annotation, typer_annotations = _split_annotation_from_typer_annotations(\\n            param.annotation,\\n        )\\n        if len(typer_annotations) > 1:\\n            raise MultipleTyperAnnotationsError(param.name)\\n\\n        default = param.default\\n        if typer_annotations:\\n            # It\\'s something like `my_param: Annotated[str, Argument()]`\\n            [parameter_info] = typer_annotations\\n\\n            # Forbid `my_param: Annotated[str, Argument()] = Argument(\"...\")`\\n            if isinstance(param.default, ParameterInfo):\\n                raise MixedAnnotatedAndDefaultStyleError(\\n                    argument_name=param.name,\\n                    annotated_param_type=type(parameter_info),\\n                    default_param_type=type(param.default),\\n                )\\n\\n            parameter_info = copy(parameter_info)\\n\\n            # When used as a default, `Option` takes a default value and option names\\n            # as positional arguments:\\n            #   `Option(some_value, \"--some-argument\", \"-s\")`\\n            # When used in `Annotated` (ie, what this is handling), `Option` just takes\\n            # option names as positional arguments:\\n            #   `Option(\"--some-argument\", \"-s\")`\\n            # In this case, the `default` attribute of `parameter_info` is actually\\n            # meant to be the first item of `param_decls`.\\n            if (\\n                isinstance(parameter_info, OptionInfo)\\n                and parameter_info.default is not ...\\n            ):\\n                parameter_info.param_decls = (\\n                    cast(str, parameter_info.default),\\n                    *(parameter_info.param_decls or ()),\\n                )\\n                parameter_info.default = ...\\n\\n            # Forbid `my_param: Annotated[str, Argument(\\'some-default\\')]`\\n            if parameter_info.default is not ...:\\n                raise AnnotatedParamWithDefaultValueError(\\n                    param_type=type(parameter_info),\\n                    argument_name=param.name,\\n                )\\n            if param.default is not param.empty:\\n                # Put the parameter\\'s default (set by `=`) into `parameter_info`, where\\n                # typer can find it.\\n                parameter_info.default = param.default\\n\\n            default = parameter_info\\n        elif param.name in type_hints:\\n            # Resolve forward references.\\n            annotation = type_hints[param.name]\\n\\n        if isinstance(default, ParameterInfo):\\n            parameter_info = copy(default)\\n            # Click supports `default` as either\\n            # - an actual value; or\\n            # - a factory function (returning a default value.)\\n            # The two are not interchangeable for static typing, so typer allows\\n            # specifying `default_factory`. Move the `default_factory` into `default`\\n            # so click can find it.\\n            if parameter_info.default is ... and parameter_info.default_factory:\\n                parameter_info.default = parameter_info.default_factory\\n            elif parameter_info.default_factory:\\n                raise DefaultFactoryAndDefaultValueError(\\n                    argument_name=param.name, param_type=type(parameter_info)\\n                )\\n            default = parameter_info\\n\\n        params[param.name] = ParamMeta(\\n            name=param.name, default=default, annotation=annotation\\n        )\\n    return params\\n')]\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/__init__.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/__main__.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/_completion_classes.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/_completion_shared.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/_types.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/_typing.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/cli.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/colors.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/completion.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/core.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/main.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/models.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/params.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/rich_utils.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/testing.py.md'\n",
      "Response status code: 200\n",
      "Successfully saved content to 'responses/typer/utils.py.md'\n"
     ]
    }
   ],
   "source": [
    "# # de codesmells adicionados: 20\n",
    "# Arquivos: __main.py__, _completion_classes.py, cli.py, colors.py, completion.py, core.py, models.py,\n",
    "#           params.py, rich_utils.py, testing.py\n",
    "\n",
    "snippets_folder = \"../typer/typer\"\n",
    "snippets = load_snippets(snippets_folder)\n",
    "request = RQ\n",
    "\n",
    "process_snippets(\"typer\", request=request, snippets=snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29fc4f-83d4-4f6d-86a9-5a55afdcbb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
